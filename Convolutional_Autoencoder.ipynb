{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder 卷积自编码器\n",
    "\n",
    "Sticking with the MNIST dataset, let's improve our autoencoder's performance using convolutional layers. Again, loading modules and the data.\n",
    "\n",
    "使用MNIST数据集，让我们使用卷积层来提高自动编码器的性能。 再次，加载模块和数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24be41b0da0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24be1fb4c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture 网络架构\n",
    "\n",
    "The encoder part of the network will be a typical convolutional pyramid. Each convolutional layer will be followed by a max-pooling layer to reduce the dimensions of the layers. The decoder though might be something new to you. The decoder needs to convert from a narrow representation to a wide reconstructed image. For example, the representation could be a 4x4x8 max-pool layer. This is the output of the encoder, but also the input to the decoder. We want to get a 28x28x1 image out from the decoder so we need to work our way back up from the narrow decoder input layer. A schematic of the network is shown below.\n",
    "\n",
    "网络的编码器部分将是典型的卷积金字塔。 每个卷积层后面都会有一个最大池层，以减小层的尺寸。 解码器可能对您而言是新鲜事物。 解码器需要从窄表示转换为宽重建图像。 例如，该表示可以是4×4×8的最大池层。 这是编码器的输出，也是解码器的输入。 我们想从解码器中获取一个28x28x1的图像，所以我们需要从窄的解码器输入层中恢复出来。 网络原理图如下所示。\n",
    "\n",
    "![Convolutional Autoencoder](assets/convolutional_autoencoder.png)\n",
    "\n",
    "Here our final encoder layer has size 4x4x8 = 128. The original images have size 28x28 = 784, so the encoded vector is roughly 16% the size of the original image. These are just suggested sizes for each of the layers. Feel free to change the depths and sizes, but remember our goal here is to find a small representation of the input data.\n",
    "\n",
    "这里我们的最终编码器层的大小为4x4x8 = 128.原始图像的大小为28x28 = 784，因此编码矢量大约为原始图像的大小的16％。 这些只是每个图层的建议尺寸。 随意更改深度和大小，但请记住，我们的目标是找到输入数据的小表示。\n",
    "\n",
    "### What's going on with the decoder 解码器发生了什么\n",
    "\n",
    "Okay, so the decoder has these \"Upsample\" layers that you might not have seen before. First off, I'll discuss a bit what these layers *aren't*. Usually, you'll see **deconvolutional** layers used to increase the width and height of the layers. They work almost exactly the same as convolutional layers, but it reverse. A stride in the input layer results in a larger stride in the deconvolutional layer. For example, if you have a 3x3 kernel, a 3x3 patch in the input layer will be reduced to one unit in a convolutional layer. Comparatively, one unit in the input layer will be expanded to a 3x3 path in a deconvolutional layer. Deconvolution is often called \"transpose convolution\" which is what you'll find with the TensorFlow API, with [`tf.nn.conv2d_transpose`](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose). \n",
    "\n",
    "好的，所以解码器有这些你可能以前看不到的“Upsample”层。 首先，我会讨论一下这些层 *aren't* 。 通常，您将看到**deconvolutional**层用于增加图层的宽度和高度。 它们与卷积层几乎完全相同，但却相反。 在输入层中的步幅在解卷积层中产生更大的步幅。 例如，如果您有3x3内核，输入层中的3x3补丁将在卷积层中减少到一个单位。 相比之下，输入层中的一个单元将在解卷积层中扩展到3x3路径。 解卷积通常被称为“转置卷积”，这是您可以使用TensorFlow API找到的，[`tf.nn.conv2d_transpose`](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose)。\n",
    "\n",
    "However, deconvolutional layers can lead to artifacts in the final images, such as checkerboard patterns. This is due to overlap in the kernels which can be avoided by setting the stride and kernel size equal. In [this Distill article](http://distill.pub/2016/deconv-checkerboard/) from Augustus Odena, *et al*, the authors show that these checkerboard artifacts can be avoided by resizing the layers using nearest neighbor or bilinear interpolation (upsampling) followed by a convolutional layer. In TensorFlow, this is easily done with [`tf.image.resize_images`](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/image/resize_images), followed by a convolution. Be sure to read the Distill article to get a better understanding of deconvolutional layers and why we're using upsampling.\n",
    "\n",
    "然而，解卷积层可能导致最终图像中的伪像，例如棋盘图案。 这是由于内核中的重叠，可以通过将步长和内核大小设置为相等来避免。 在这篇文章中，来自Augustus Odena，*等人的[这篇文章](http://distill.pub/2016/deconv-checkerboard/)中，作者表明，通过使用最近邻或双线性调整图层可以避免这些棋盘工件 内插（上采样），然后是卷积层。 在TensorFlow中，这很容易用[`tf.image.resize_images`](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/image/resize_images)完成，然后是卷积。 请务必阅读Distill文章，以更好地了解解卷积层，以及为什么我们使用上采样。\n",
    "\n",
    "> **Exercise:** Build the network shown above. Remember that a convolutional layer with strides of 1 and 'same' padding won't reduce the height and width. That is, if the input is 28x28 and the convolution layer has stride = 1 and 'same' padding, the convolutional layer will also be 28x28. The max-pool layers are used the reduce the width and height. A stride of 2 will reduce the size by 2. Odena *et al* claim that nearest neighbor interpolation works best for the upsampling, so make sure to include that as a parameter in `tf.image.resize_images` or use [`tf.image.resize_nearest_neighbor`]( https://www.tensorflow.org/api_docs/python/tf/image/resize_nearest_neighbor).\n",
    "\n",
    "> **练习：**构建上面显示的网络。 记住，具有1和“相同”填充的步长的卷积层不会降低高度和宽度。 也就是说，如果输入是28×28，并且卷积层具有步幅= 1和'相同'填充，则卷积层也将是28×28。 使用最大池层减少宽度和高度。 2的大小将减小大小2. Odena *等人*声称最近邻插值对于上采样最有效，因此请确保将其作为参数在`tf.image.resize_images'中使用或使用[`tf.image.resize_nearest_neighbor`](https://www.tensorflow.org/api_docs/python/tf/image/resize_nearest_neighbor)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name=\"input\")\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name=\"targets\")\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 16, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now 28x28x16\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding=\"same\")\n",
    "# Now 14x14x16\n",
    "conv2 = tf.layers.conv2d(maxpool1, 8, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now 14x14x8\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding=\"same\")\n",
    "# Now 7x7x8\n",
    "conv3 = tf.layers.conv2d(maxpool2, 8, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now 7x7x8\n",
    "encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding=\"same\")\n",
    "# Now 4x4x8\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "# Now 7x7x8\n",
    "conv4 = tf.layers.conv2d(upsample1, 8, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now 7x7x8\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "# Now 14x14x8\n",
    "conv5 =  tf.layers.conv2d(upsample2, 8, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now 14x14x8\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "# Now 28x28x8\n",
    "conv6 = tf.layers.conv2d(upsample3, 16, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now 28x28x16\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding=\"same\", activation=None)\n",
    "#Now 28x28x1\n",
    "\n",
    "# Pass logits through sigmoid to get reconstructed image\n",
    "decoded = tf.nn.sigmoid(logits, name=\"decoded\")\n",
    "\n",
    "# Pass logits through sigmoid and calculate the cross-entropy loss\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "\n",
    "# Get cost and define the optimizer\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 训练\n",
    "\n",
    "As before, here wi'll train the network. Instead of flattening the images though, we can pass them in as 28x28x1 arrays.\n",
    "\n",
    "像以前一样，这里将会训练网络。 我们可以将它们作为28x28x1阵列传递，而不是使图像平坦化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.7018\n",
      "Epoch: 1/20... Training loss: 0.6965\n",
      "Epoch: 1/20... Training loss: 0.6921\n",
      "Epoch: 1/20... Training loss: 0.6888\n",
      "Epoch: 1/20... Training loss: 0.6860\n",
      "Epoch: 1/20... Training loss: 0.6832\n",
      "Epoch: 1/20... Training loss: 0.6815\n",
      "Epoch: 1/20... Training loss: 0.6768\n",
      "Epoch: 1/20... Training loss: 0.6725\n",
      "Epoch: 1/20... Training loss: 0.6687\n",
      "Epoch: 1/20... Training loss: 0.6635\n",
      "Epoch: 1/20... Training loss: 0.6558\n",
      "Epoch: 1/20... Training loss: 0.6481\n",
      "Epoch: 1/20... Training loss: 0.6376\n",
      "Epoch: 1/20... Training loss: 0.6263\n",
      "Epoch: 1/20... Training loss: 0.6092\n",
      "Epoch: 1/20... Training loss: 0.5955\n",
      "Epoch: 1/20... Training loss: 0.5766\n",
      "Epoch: 1/20... Training loss: 0.5662\n",
      "Epoch: 1/20... Training loss: 0.5409\n",
      "Epoch: 1/20... Training loss: 0.5299\n",
      "Epoch: 1/20... Training loss: 0.5240\n",
      "Epoch: 1/20... Training loss: 0.5373\n",
      "Epoch: 1/20... Training loss: 0.5732\n",
      "Epoch: 1/20... Training loss: 0.5454\n",
      "Epoch: 1/20... Training loss: 0.5505\n",
      "Epoch: 1/20... Training loss: 0.5481\n",
      "Epoch: 1/20... Training loss: 0.5343\n",
      "Epoch: 1/20... Training loss: 0.5076\n",
      "Epoch: 1/20... Training loss: 0.5067\n",
      "Epoch: 1/20... Training loss: 0.5331\n",
      "Epoch: 1/20... Training loss: 0.5097\n",
      "Epoch: 1/20... Training loss: 0.4879\n",
      "Epoch: 1/20... Training loss: 0.4705\n",
      "Epoch: 1/20... Training loss: 0.4811\n",
      "Epoch: 1/20... Training loss: 0.4633\n",
      "Epoch: 1/20... Training loss: 0.4425\n",
      "Epoch: 1/20... Training loss: 0.4402\n",
      "Epoch: 1/20... Training loss: 0.4408\n",
      "Epoch: 1/20... Training loss: 0.4672\n",
      "Epoch: 1/20... Training loss: 0.4423\n",
      "Epoch: 1/20... Training loss: 0.4352\n",
      "Epoch: 1/20... Training loss: 0.4606\n",
      "Epoch: 1/20... Training loss: 0.4381\n",
      "Epoch: 1/20... Training loss: 0.4033\n",
      "Epoch: 1/20... Training loss: 0.3923\n",
      "Epoch: 1/20... Training loss: 0.3884\n",
      "Epoch: 1/20... Training loss: 0.3934\n",
      "Epoch: 1/20... Training loss: 0.3861\n",
      "Epoch: 1/20... Training loss: 0.3673\n",
      "Epoch: 1/20... Training loss: 0.3531\n",
      "Epoch: 1/20... Training loss: 0.3983\n",
      "Epoch: 1/20... Training loss: 0.3565\n",
      "Epoch: 1/20... Training loss: 0.3218\n",
      "Epoch: 1/20... Training loss: 0.3334\n",
      "Epoch: 1/20... Training loss: 0.3243\n",
      "Epoch: 1/20... Training loss: 0.3077\n",
      "Epoch: 1/20... Training loss: 0.2952\n",
      "Epoch: 1/20... Training loss: 0.2847\n",
      "Epoch: 1/20... Training loss: 0.2796\n",
      "Epoch: 1/20... Training loss: 0.2838\n",
      "Epoch: 1/20... Training loss: 0.2796\n",
      "Epoch: 1/20... Training loss: 0.2801\n",
      "Epoch: 1/20... Training loss: 0.2710\n",
      "Epoch: 1/20... Training loss: 0.2623\n",
      "Epoch: 1/20... Training loss: 0.2686\n",
      "Epoch: 1/20... Training loss: 0.2590\n",
      "Epoch: 1/20... Training loss: 0.2653\n",
      "Epoch: 1/20... Training loss: 0.2324\n",
      "Epoch: 1/20... Training loss: 0.2429\n",
      "Epoch: 1/20... Training loss: 0.2567\n",
      "Epoch: 1/20... Training loss: 0.2462\n",
      "Epoch: 1/20... Training loss: 0.2305\n",
      "Epoch: 1/20... Training loss: 0.2332\n",
      "Epoch: 1/20... Training loss: 0.2258\n",
      "Epoch: 1/20... Training loss: 0.2254\n",
      "Epoch: 1/20... Training loss: 0.2214\n",
      "Epoch: 1/20... Training loss: 0.2218\n",
      "Epoch: 1/20... Training loss: 0.2279\n",
      "Epoch: 1/20... Training loss: 0.2211\n",
      "Epoch: 1/20... Training loss: 0.2265\n",
      "Epoch: 1/20... Training loss: 0.2192\n",
      "Epoch: 1/20... Training loss: 0.2209\n",
      "Epoch: 1/20... Training loss: 0.2168\n",
      "Epoch: 1/20... Training loss: 0.2145\n",
      "Epoch: 1/20... Training loss: 0.2228\n",
      "Epoch: 1/20... Training loss: 0.2295\n",
      "Epoch: 1/20... Training loss: 0.2186\n",
      "Epoch: 1/20... Training loss: 0.2074\n",
      "Epoch: 1/20... Training loss: 0.2047\n",
      "Epoch: 1/20... Training loss: 0.2070\n",
      "Epoch: 1/20... Training loss: 0.2055\n",
      "Epoch: 1/20... Training loss: 0.2100\n",
      "Epoch: 1/20... Training loss: 0.2156\n",
      "Epoch: 1/20... Training loss: 0.2103\n",
      "Epoch: 1/20... Training loss: 0.2049\n",
      "Epoch: 1/20... Training loss: 0.2310\n",
      "Epoch: 1/20... Training loss: 0.2204\n",
      "Epoch: 1/20... Training loss: 0.2217\n",
      "Epoch: 1/20... Training loss: 0.2261\n",
      "Epoch: 1/20... Training loss: 0.2165\n",
      "Epoch: 1/20... Training loss: 0.2100\n",
      "Epoch: 1/20... Training loss: 0.2119\n",
      "Epoch: 1/20... Training loss: 0.2094\n",
      "Epoch: 1/20... Training loss: 0.2072\n",
      "Epoch: 1/20... Training loss: 0.2040\n",
      "Epoch: 1/20... Training loss: 0.2167\n",
      "Epoch: 1/20... Training loss: 0.2110\n",
      "Epoch: 1/20... Training loss: 0.1998\n",
      "Epoch: 1/20... Training loss: 0.2174\n",
      "Epoch: 1/20... Training loss: 0.2154\n",
      "Epoch: 1/20... Training loss: 0.2049\n",
      "Epoch: 1/20... Training loss: 0.2015\n",
      "Epoch: 1/20... Training loss: 0.2125\n",
      "Epoch: 1/20... Training loss: 0.2098\n",
      "Epoch: 1/20... Training loss: 0.2136\n",
      "Epoch: 1/20... Training loss: 0.2034\n",
      "Epoch: 1/20... Training loss: 0.1983\n",
      "Epoch: 1/20... Training loss: 0.2021\n",
      "Epoch: 1/20... Training loss: 0.2090\n",
      "Epoch: 1/20... Training loss: 0.1919\n",
      "Epoch: 1/20... Training loss: 0.1924\n",
      "Epoch: 1/20... Training loss: 0.2067\n",
      "Epoch: 1/20... Training loss: 0.1951\n",
      "Epoch: 1/20... Training loss: 0.1835\n",
      "Epoch: 1/20... Training loss: 0.1985\n",
      "Epoch: 1/20... Training loss: 0.2072\n",
      "Epoch: 1/20... Training loss: 0.1959\n",
      "Epoch: 1/20... Training loss: 0.1968\n",
      "Epoch: 1/20... Training loss: 0.1844\n",
      "Epoch: 1/20... Training loss: 0.1911\n",
      "Epoch: 1/20... Training loss: 0.1883\n",
      "Epoch: 1/20... Training loss: 0.1866\n",
      "Epoch: 1/20... Training loss: 0.1952\n",
      "Epoch: 1/20... Training loss: 0.1875\n",
      "Epoch: 1/20... Training loss: 0.2045\n",
      "Epoch: 1/20... Training loss: 0.1998\n",
      "Epoch: 1/20... Training loss: 0.1953\n",
      "Epoch: 1/20... Training loss: 0.1926\n",
      "Epoch: 1/20... Training loss: 0.1937\n",
      "Epoch: 1/20... Training loss: 0.1903\n",
      "Epoch: 1/20... Training loss: 0.1935\n",
      "Epoch: 1/20... Training loss: 0.1894\n",
      "Epoch: 1/20... Training loss: 0.1858\n",
      "Epoch: 1/20... Training loss: 0.1967\n",
      "Epoch: 1/20... Training loss: 0.1972\n",
      "Epoch: 1/20... Training loss: 0.1902\n",
      "Epoch: 1/20... Training loss: 0.1834\n",
      "Epoch: 1/20... Training loss: 0.1827\n",
      "Epoch: 1/20... Training loss: 0.1727\n",
      "Epoch: 1/20... Training loss: 0.1835\n",
      "Epoch: 1/20... Training loss: 0.1891\n",
      "Epoch: 1/20... Training loss: 0.1861\n",
      "Epoch: 1/20... Training loss: 0.1804\n",
      "Epoch: 1/20... Training loss: 0.1786\n",
      "Epoch: 1/20... Training loss: 0.1839\n",
      "Epoch: 1/20... Training loss: 0.1775\n",
      "Epoch: 1/20... Training loss: 0.1827\n",
      "Epoch: 1/20... Training loss: 0.1828\n",
      "Epoch: 1/20... Training loss: 0.1813\n",
      "Epoch: 1/20... Training loss: 0.1812\n",
      "Epoch: 1/20... Training loss: 0.1785\n",
      "Epoch: 1/20... Training loss: 0.1789\n",
      "Epoch: 1/20... Training loss: 0.1871\n",
      "Epoch: 1/20... Training loss: 0.1810\n",
      "Epoch: 1/20... Training loss: 0.1789\n",
      "Epoch: 1/20... Training loss: 0.1840\n",
      "Epoch: 1/20... Training loss: 0.1766\n",
      "Epoch: 1/20... Training loss: 0.1691\n",
      "Epoch: 1/20... Training loss: 0.1706\n",
      "Epoch: 1/20... Training loss: 0.1763\n",
      "Epoch: 1/20... Training loss: 0.1767\n",
      "Epoch: 1/20... Training loss: 0.1823\n",
      "Epoch: 1/20... Training loss: 0.1771\n",
      "Epoch: 1/20... Training loss: 0.1721\n",
      "Epoch: 1/20... Training loss: 0.1776\n",
      "Epoch: 1/20... Training loss: 0.1706\n",
      "Epoch: 1/20... Training loss: 0.1794\n",
      "Epoch: 1/20... Training loss: 0.1784\n",
      "Epoch: 1/20... Training loss: 0.1787\n",
      "Epoch: 1/20... Training loss: 0.1782\n",
      "Epoch: 1/20... Training loss: 0.1819\n",
      "Epoch: 1/20... Training loss: 0.1786\n",
      "Epoch: 1/20... Training loss: 0.1780\n",
      "Epoch: 1/20... Training loss: 0.1747\n",
      "Epoch: 1/20... Training loss: 0.1634\n",
      "Epoch: 1/20... Training loss: 0.1713\n",
      "Epoch: 1/20... Training loss: 0.1765\n",
      "Epoch: 1/20... Training loss: 0.1805\n",
      "Epoch: 1/20... Training loss: 0.1720\n",
      "Epoch: 1/20... Training loss: 0.1717\n",
      "Epoch: 1/20... Training loss: 0.1697\n",
      "Epoch: 1/20... Training loss: 0.1650\n",
      "Epoch: 1/20... Training loss: 0.1778\n",
      "Epoch: 1/20... Training loss: 0.1709\n",
      "Epoch: 1/20... Training loss: 0.1665\n",
      "Epoch: 1/20... Training loss: 0.1676\n",
      "Epoch: 1/20... Training loss: 0.1564\n",
      "Epoch: 1/20... Training loss: 0.1681\n",
      "Epoch: 1/20... Training loss: 0.1763\n",
      "Epoch: 1/20... Training loss: 0.1686\n",
      "Epoch: 1/20... Training loss: 0.1674\n",
      "Epoch: 1/20... Training loss: 0.1711\n",
      "Epoch: 1/20... Training loss: 0.1687\n",
      "Epoch: 1/20... Training loss: 0.1663\n",
      "Epoch: 1/20... Training loss: 0.1710\n",
      "Epoch: 1/20... Training loss: 0.1729\n",
      "Epoch: 1/20... Training loss: 0.1634\n",
      "Epoch: 1/20... Training loss: 0.1607\n",
      "Epoch: 1/20... Training loss: 0.1622\n",
      "Epoch: 1/20... Training loss: 0.1586\n",
      "Epoch: 1/20... Training loss: 0.1657\n",
      "Epoch: 1/20... Training loss: 0.1682\n",
      "Epoch: 1/20... Training loss: 0.1695\n",
      "Epoch: 1/20... Training loss: 0.1678\n",
      "Epoch: 1/20... Training loss: 0.1566\n",
      "Epoch: 1/20... Training loss: 0.1663\n",
      "Epoch: 1/20... Training loss: 0.1699\n",
      "Epoch: 1/20... Training loss: 0.1605\n",
      "Epoch: 1/20... Training loss: 0.1623\n",
      "Epoch: 1/20... Training loss: 0.1736\n",
      "Epoch: 1/20... Training loss: 0.1665\n",
      "Epoch: 1/20... Training loss: 0.1664\n",
      "Epoch: 1/20... Training loss: 0.1658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.1646\n",
      "Epoch: 1/20... Training loss: 0.1638\n",
      "Epoch: 1/20... Training loss: 0.1713\n",
      "Epoch: 1/20... Training loss: 0.1670\n",
      "Epoch: 1/20... Training loss: 0.1657\n",
      "Epoch: 1/20... Training loss: 0.1659\n",
      "Epoch: 1/20... Training loss: 0.1633\n",
      "Epoch: 1/20... Training loss: 0.1670\n",
      "Epoch: 1/20... Training loss: 0.1651\n",
      "Epoch: 1/20... Training loss: 0.1674\n",
      "Epoch: 1/20... Training loss: 0.1673\n",
      "Epoch: 1/20... Training loss: 0.1608\n",
      "Epoch: 1/20... Training loss: 0.1573\n",
      "Epoch: 1/20... Training loss: 0.1652\n",
      "Epoch: 1/20... Training loss: 0.1658\n",
      "Epoch: 1/20... Training loss: 0.1586\n",
      "Epoch: 1/20... Training loss: 0.1582\n",
      "Epoch: 1/20... Training loss: 0.1612\n",
      "Epoch: 1/20... Training loss: 0.1634\n",
      "Epoch: 1/20... Training loss: 0.1656\n",
      "Epoch: 1/20... Training loss: 0.1558\n",
      "Epoch: 1/20... Training loss: 0.1697\n",
      "Epoch: 1/20... Training loss: 0.1616\n",
      "Epoch: 1/20... Training loss: 0.1667\n",
      "Epoch: 1/20... Training loss: 0.1668\n",
      "Epoch: 1/20... Training loss: 0.1588\n",
      "Epoch: 1/20... Training loss: 0.1548\n",
      "Epoch: 1/20... Training loss: 0.1628\n",
      "Epoch: 1/20... Training loss: 0.1619\n",
      "Epoch: 1/20... Training loss: 0.1579\n",
      "Epoch: 1/20... Training loss: 0.1534\n",
      "Epoch: 1/20... Training loss: 0.1571\n",
      "Epoch: 1/20... Training loss: 0.1597\n",
      "Epoch: 1/20... Training loss: 0.1639\n",
      "Epoch: 1/20... Training loss: 0.1635\n",
      "Epoch: 1/20... Training loss: 0.1622\n",
      "Epoch: 1/20... Training loss: 0.1561\n",
      "Epoch: 1/20... Training loss: 0.1491\n",
      "Epoch: 1/20... Training loss: 0.1620\n",
      "Epoch: 1/20... Training loss: 0.1540\n",
      "Epoch: 1/20... Training loss: 0.1576\n",
      "Epoch: 1/20... Training loss: 0.1579\n",
      "Epoch: 1/20... Training loss: 0.1606\n",
      "Epoch: 1/20... Training loss: 0.1526\n",
      "Epoch: 1/20... Training loss: 0.1601\n",
      "Epoch: 1/20... Training loss: 0.1632\n",
      "Epoch: 1/20... Training loss: 0.1629\n",
      "Epoch: 1/20... Training loss: 0.1551\n",
      "Epoch: 1/20... Training loss: 0.1570\n",
      "Epoch: 1/20... Training loss: 0.1500\n",
      "Epoch: 1/20... Training loss: 0.1564\n",
      "Epoch: 1/20... Training loss: 0.1565\n",
      "Epoch: 1/20... Training loss: 0.1522\n",
      "Epoch: 1/20... Training loss: 0.1533\n",
      "Epoch: 1/20... Training loss: 0.1592\n",
      "Epoch: 1/20... Training loss: 0.1593\n",
      "Epoch: 1/20... Training loss: 0.1553\n",
      "Epoch: 1/20... Training loss: 0.1532\n",
      "Epoch: 1/20... Training loss: 0.1557\n",
      "Epoch: 1/20... Training loss: 0.1515\n",
      "Epoch: 1/20... Training loss: 0.1530\n",
      "Epoch: 1/20... Training loss: 0.1532\n",
      "Epoch: 1/20... Training loss: 0.1604\n",
      "Epoch: 1/20... Training loss: 0.1600\n",
      "Epoch: 1/20... Training loss: 0.1507\n",
      "Epoch: 1/20... Training loss: 0.1547\n",
      "Epoch: 1/20... Training loss: 0.1536\n",
      "Epoch: 1/20... Training loss: 0.1633\n",
      "Epoch: 1/20... Training loss: 0.1586\n",
      "Epoch: 1/20... Training loss: 0.1495\n",
      "Epoch: 1/20... Training loss: 0.1664\n",
      "Epoch: 1/20... Training loss: 0.1566\n",
      "Epoch: 1/20... Training loss: 0.1648\n",
      "Epoch: 1/20... Training loss: 0.1595\n",
      "Epoch: 1/20... Training loss: 0.1553\n",
      "Epoch: 1/20... Training loss: 0.1541\n",
      "Epoch: 2/20... Training loss: 0.1505\n",
      "Epoch: 2/20... Training loss: 0.1582\n",
      "Epoch: 2/20... Training loss: 0.1514\n",
      "Epoch: 2/20... Training loss: 0.1576\n",
      "Epoch: 2/20... Training loss: 0.1515\n",
      "Epoch: 2/20... Training loss: 0.1537\n",
      "Epoch: 2/20... Training loss: 0.1558\n",
      "Epoch: 2/20... Training loss: 0.1562\n",
      "Epoch: 2/20... Training loss: 0.1558\n",
      "Epoch: 2/20... Training loss: 0.1543\n",
      "Epoch: 2/20... Training loss: 0.1481\n",
      "Epoch: 2/20... Training loss: 0.1503\n",
      "Epoch: 2/20... Training loss: 0.1472\n",
      "Epoch: 2/20... Training loss: 0.1491\n",
      "Epoch: 2/20... Training loss: 0.1506\n",
      "Epoch: 2/20... Training loss: 0.1467\n",
      "Epoch: 2/20... Training loss: 0.1518\n",
      "Epoch: 2/20... Training loss: 0.1514\n",
      "Epoch: 2/20... Training loss: 0.1539\n",
      "Epoch: 2/20... Training loss: 0.1459\n",
      "Epoch: 2/20... Training loss: 0.1520\n",
      "Epoch: 2/20... Training loss: 0.1452\n",
      "Epoch: 2/20... Training loss: 0.1502\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1474\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1490\n",
      "Epoch: 2/20... Training loss: 0.1492\n",
      "Epoch: 2/20... Training loss: 0.1449\n",
      "Epoch: 2/20... Training loss: 0.1530\n",
      "Epoch: 2/20... Training loss: 0.1499\n",
      "Epoch: 2/20... Training loss: 0.1523\n",
      "Epoch: 2/20... Training loss: 0.1475\n",
      "Epoch: 2/20... Training loss: 0.1523\n",
      "Epoch: 2/20... Training loss: 0.1504\n",
      "Epoch: 2/20... Training loss: 0.1529\n",
      "Epoch: 2/20... Training loss: 0.1506\n",
      "Epoch: 2/20... Training loss: 0.1496\n",
      "Epoch: 2/20... Training loss: 0.1510\n",
      "Epoch: 2/20... Training loss: 0.1464\n",
      "Epoch: 2/20... Training loss: 0.1491\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1447\n",
      "Epoch: 2/20... Training loss: 0.1492\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1487\n",
      "Epoch: 2/20... Training loss: 0.1492\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1471\n",
      "Epoch: 2/20... Training loss: 0.1466\n",
      "Epoch: 2/20... Training loss: 0.1469\n",
      "Epoch: 2/20... Training loss: 0.1460\n",
      "Epoch: 2/20... Training loss: 0.1427\n",
      "Epoch: 2/20... Training loss: 0.1452\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1500\n",
      "Epoch: 2/20... Training loss: 0.1485\n",
      "Epoch: 2/20... Training loss: 0.1439\n",
      "Epoch: 2/20... Training loss: 0.1413\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1405\n",
      "Epoch: 2/20... Training loss: 0.1503\n",
      "Epoch: 2/20... Training loss: 0.1447\n",
      "Epoch: 2/20... Training loss: 0.1476\n",
      "Epoch: 2/20... Training loss: 0.1432\n",
      "Epoch: 2/20... Training loss: 0.1434\n",
      "Epoch: 2/20... Training loss: 0.1458\n",
      "Epoch: 2/20... Training loss: 0.1460\n",
      "Epoch: 2/20... Training loss: 0.1408\n",
      "Epoch: 2/20... Training loss: 0.1499\n",
      "Epoch: 2/20... Training loss: 0.1447\n",
      "Epoch: 2/20... Training loss: 0.1406\n",
      "Epoch: 2/20... Training loss: 0.1462\n",
      "Epoch: 2/20... Training loss: 0.1449\n",
      "Epoch: 2/20... Training loss: 0.1410\n",
      "Epoch: 2/20... Training loss: 0.1449\n",
      "Epoch: 2/20... Training loss: 0.1491\n",
      "Epoch: 2/20... Training loss: 0.1445\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1434\n",
      "Epoch: 2/20... Training loss: 0.1419\n",
      "Epoch: 2/20... Training loss: 0.1372\n",
      "Epoch: 2/20... Training loss: 0.1492\n",
      "Epoch: 2/20... Training loss: 0.1432\n",
      "Epoch: 2/20... Training loss: 0.1417\n",
      "Epoch: 2/20... Training loss: 0.1455\n",
      "Epoch: 2/20... Training loss: 0.1390\n",
      "Epoch: 2/20... Training loss: 0.1466\n",
      "Epoch: 2/20... Training loss: 0.1442\n",
      "Epoch: 2/20... Training loss: 0.1382\n",
      "Epoch: 2/20... Training loss: 0.1402\n",
      "Epoch: 2/20... Training loss: 0.1460\n",
      "Epoch: 2/20... Training loss: 0.1414\n",
      "Epoch: 2/20... Training loss: 0.1481\n",
      "Epoch: 2/20... Training loss: 0.1397\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1430\n",
      "Epoch: 2/20... Training loss: 0.1440\n",
      "Epoch: 2/20... Training loss: 0.1427\n",
      "Epoch: 2/20... Training loss: 0.1413\n",
      "Epoch: 2/20... Training loss: 0.1421\n",
      "Epoch: 2/20... Training loss: 0.1387\n",
      "Epoch: 2/20... Training loss: 0.1444\n",
      "Epoch: 2/20... Training loss: 0.1362\n",
      "Epoch: 2/20... Training loss: 0.1455\n",
      "Epoch: 2/20... Training loss: 0.1397\n",
      "Epoch: 2/20... Training loss: 0.1394\n",
      "Epoch: 2/20... Training loss: 0.1383\n",
      "Epoch: 2/20... Training loss: 0.1434\n",
      "Epoch: 2/20... Training loss: 0.1405\n",
      "Epoch: 2/20... Training loss: 0.1449\n",
      "Epoch: 2/20... Training loss: 0.1340\n",
      "Epoch: 2/20... Training loss: 0.1415\n",
      "Epoch: 2/20... Training loss: 0.1361\n",
      "Epoch: 2/20... Training loss: 0.1364\n",
      "Epoch: 2/20... Training loss: 0.1419\n",
      "Epoch: 2/20... Training loss: 0.1440\n",
      "Epoch: 2/20... Training loss: 0.1348\n",
      "Epoch: 2/20... Training loss: 0.1417\n",
      "Epoch: 2/20... Training loss: 0.1452\n",
      "Epoch: 2/20... Training loss: 0.1413\n",
      "Epoch: 2/20... Training loss: 0.1398\n",
      "Epoch: 2/20... Training loss: 0.1383\n",
      "Epoch: 2/20... Training loss: 0.1372\n",
      "Epoch: 2/20... Training loss: 0.1371\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1404\n",
      "Epoch: 2/20... Training loss: 0.1377\n",
      "Epoch: 2/20... Training loss: 0.1414\n",
      "Epoch: 2/20... Training loss: 0.1428\n",
      "Epoch: 2/20... Training loss: 0.1441\n",
      "Epoch: 2/20... Training loss: 0.1378\n",
      "Epoch: 2/20... Training loss: 0.1387\n",
      "Epoch: 2/20... Training loss: 0.1385\n",
      "Epoch: 2/20... Training loss: 0.1375\n",
      "Epoch: 2/20... Training loss: 0.1416\n",
      "Epoch: 2/20... Training loss: 0.1420\n",
      "Epoch: 2/20... Training loss: 0.1424\n",
      "Epoch: 2/20... Training loss: 0.1355\n",
      "Epoch: 2/20... Training loss: 0.1438\n",
      "Epoch: 2/20... Training loss: 0.1413\n",
      "Epoch: 2/20... Training loss: 0.1420\n",
      "Epoch: 2/20... Training loss: 0.1360\n",
      "Epoch: 2/20... Training loss: 0.1408\n",
      "Epoch: 2/20... Training loss: 0.1423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20... Training loss: 0.1420\n",
      "Epoch: 2/20... Training loss: 0.1386\n",
      "Epoch: 2/20... Training loss: 0.1345\n",
      "Epoch: 2/20... Training loss: 0.1404\n",
      "Epoch: 2/20... Training loss: 0.1341\n",
      "Epoch: 2/20... Training loss: 0.1353\n",
      "Epoch: 2/20... Training loss: 0.1429\n",
      "Epoch: 2/20... Training loss: 0.1386\n",
      "Epoch: 2/20... Training loss: 0.1349\n",
      "Epoch: 2/20... Training loss: 0.1400\n",
      "Epoch: 2/20... Training loss: 0.1426\n",
      "Epoch: 2/20... Training loss: 0.1395\n",
      "Epoch: 2/20... Training loss: 0.1372\n",
      "Epoch: 2/20... Training loss: 0.1426\n",
      "Epoch: 2/20... Training loss: 0.1349\n",
      "Epoch: 2/20... Training loss: 0.1345\n",
      "Epoch: 2/20... Training loss: 0.1412\n",
      "Epoch: 2/20... Training loss: 0.1346\n",
      "Epoch: 2/20... Training loss: 0.1396\n",
      "Epoch: 2/20... Training loss: 0.1432\n",
      "Epoch: 2/20... Training loss: 0.1392\n",
      "Epoch: 2/20... Training loss: 0.1330\n",
      "Epoch: 2/20... Training loss: 0.1378\n",
      "Epoch: 2/20... Training loss: 0.1382\n",
      "Epoch: 2/20... Training loss: 0.1343\n",
      "Epoch: 2/20... Training loss: 0.1367\n",
      "Epoch: 2/20... Training loss: 0.1399\n",
      "Epoch: 2/20... Training loss: 0.1352\n",
      "Epoch: 2/20... Training loss: 0.1394\n",
      "Epoch: 2/20... Training loss: 0.1356\n",
      "Epoch: 2/20... Training loss: 0.1376\n",
      "Epoch: 2/20... Training loss: 0.1412\n",
      "Epoch: 2/20... Training loss: 0.1306\n",
      "Epoch: 2/20... Training loss: 0.1359\n",
      "Epoch: 2/20... Training loss: 0.1349\n",
      "Epoch: 2/20... Training loss: 0.1387\n",
      "Epoch: 2/20... Training loss: 0.1355\n",
      "Epoch: 2/20... Training loss: 0.1362\n",
      "Epoch: 2/20... Training loss: 0.1364\n",
      "Epoch: 2/20... Training loss: 0.1382\n",
      "Epoch: 2/20... Training loss: 0.1339\n",
      "Epoch: 2/20... Training loss: 0.1353\n",
      "Epoch: 2/20... Training loss: 0.1345\n",
      "Epoch: 2/20... Training loss: 0.1344\n",
      "Epoch: 2/20... Training loss: 0.1384\n",
      "Epoch: 2/20... Training loss: 0.1343\n",
      "Epoch: 2/20... Training loss: 0.1384\n",
      "Epoch: 2/20... Training loss: 0.1363\n",
      "Epoch: 2/20... Training loss: 0.1396\n",
      "Epoch: 2/20... Training loss: 0.1401\n",
      "Epoch: 2/20... Training loss: 0.1376\n",
      "Epoch: 2/20... Training loss: 0.1362\n",
      "Epoch: 2/20... Training loss: 0.1313\n",
      "Epoch: 2/20... Training loss: 0.1356\n",
      "Epoch: 2/20... Training loss: 0.1340\n",
      "Epoch: 2/20... Training loss: 0.1341\n",
      "Epoch: 2/20... Training loss: 0.1357\n",
      "Epoch: 2/20... Training loss: 0.1402\n",
      "Epoch: 2/20... Training loss: 0.1373\n",
      "Epoch: 2/20... Training loss: 0.1343\n",
      "Epoch: 2/20... Training loss: 0.1353\n",
      "Epoch: 2/20... Training loss: 0.1306\n",
      "Epoch: 2/20... Training loss: 0.1375\n",
      "Epoch: 2/20... Training loss: 0.1327\n",
      "Epoch: 2/20... Training loss: 0.1325\n",
      "Epoch: 2/20... Training loss: 0.1370\n",
      "Epoch: 2/20... Training loss: 0.1377\n",
      "Epoch: 2/20... Training loss: 0.1324\n",
      "Epoch: 2/20... Training loss: 0.1369\n",
      "Epoch: 2/20... Training loss: 0.1357\n",
      "Epoch: 2/20... Training loss: 0.1341\n",
      "Epoch: 2/20... Training loss: 0.1365\n",
      "Epoch: 2/20... Training loss: 0.1278\n",
      "Epoch: 2/20... Training loss: 0.1332\n",
      "Epoch: 2/20... Training loss: 0.1330\n",
      "Epoch: 2/20... Training loss: 0.1282\n",
      "Epoch: 2/20... Training loss: 0.1333\n",
      "Epoch: 2/20... Training loss: 0.1347\n",
      "Epoch: 2/20... Training loss: 0.1329\n",
      "Epoch: 2/20... Training loss: 0.1332\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1313\n",
      "Epoch: 2/20... Training loss: 0.1330\n",
      "Epoch: 2/20... Training loss: 0.1371\n",
      "Epoch: 2/20... Training loss: 0.1378\n",
      "Epoch: 2/20... Training loss: 0.1300\n",
      "Epoch: 2/20... Training loss: 0.1356\n",
      "Epoch: 2/20... Training loss: 0.1381\n",
      "Epoch: 2/20... Training loss: 0.1396\n",
      "Epoch: 2/20... Training loss: 0.1355\n",
      "Epoch: 2/20... Training loss: 0.1341\n",
      "Epoch: 2/20... Training loss: 0.1320\n",
      "Epoch: 2/20... Training loss: 0.1384\n",
      "Epoch: 2/20... Training loss: 0.1355\n",
      "Epoch: 2/20... Training loss: 0.1401\n",
      "Epoch: 2/20... Training loss: 0.1264\n",
      "Epoch: 2/20... Training loss: 0.1365\n",
      "Epoch: 2/20... Training loss: 0.1362\n",
      "Epoch: 2/20... Training loss: 0.1370\n",
      "Epoch: 2/20... Training loss: 0.1351\n",
      "Epoch: 2/20... Training loss: 0.1322\n",
      "Epoch: 2/20... Training loss: 0.1341\n",
      "Epoch: 2/20... Training loss: 0.1339\n",
      "Epoch: 2/20... Training loss: 0.1339\n",
      "Epoch: 2/20... Training loss: 0.1249\n",
      "Epoch: 2/20... Training loss: 0.1351\n",
      "Epoch: 2/20... Training loss: 0.1336\n",
      "Epoch: 2/20... Training loss: 0.1312\n",
      "Epoch: 2/20... Training loss: 0.1320\n",
      "Epoch: 2/20... Training loss: 0.1283\n",
      "Epoch: 2/20... Training loss: 0.1327\n",
      "Epoch: 2/20... Training loss: 0.1302\n",
      "Epoch: 2/20... Training loss: 0.1370\n",
      "Epoch: 2/20... Training loss: 0.1310\n",
      "Epoch: 2/20... Training loss: 0.1323\n",
      "Epoch: 2/20... Training loss: 0.1363\n",
      "Epoch: 2/20... Training loss: 0.1312\n",
      "Epoch: 2/20... Training loss: 0.1236\n",
      "Epoch: 2/20... Training loss: 0.1352\n",
      "Epoch: 2/20... Training loss: 0.1347\n",
      "Epoch: 2/20... Training loss: 0.1341\n",
      "Epoch: 2/20... Training loss: 0.1362\n",
      "Epoch: 2/20... Training loss: 0.1360\n",
      "Epoch: 2/20... Training loss: 0.1374\n",
      "Epoch: 2/20... Training loss: 0.1279\n",
      "Epoch: 2/20... Training loss: 0.1301\n",
      "Epoch: 2/20... Training loss: 0.1360\n",
      "Epoch: 2/20... Training loss: 0.1317\n",
      "Epoch: 2/20... Training loss: 0.1355\n",
      "Epoch: 2/20... Training loss: 0.1291\n",
      "Epoch: 2/20... Training loss: 0.1323\n",
      "Epoch: 2/20... Training loss: 0.1281\n",
      "Epoch: 2/20... Training loss: 0.1315\n",
      "Epoch: 2/20... Training loss: 0.1334\n",
      "Epoch: 2/20... Training loss: 0.1343\n",
      "Epoch: 2/20... Training loss: 0.1352\n",
      "Epoch: 2/20... Training loss: 0.1330\n",
      "Epoch: 2/20... Training loss: 0.1308\n",
      "Epoch: 2/20... Training loss: 0.1327\n",
      "Epoch: 2/20... Training loss: 0.1305\n",
      "Epoch: 2/20... Training loss: 0.1289\n",
      "Epoch: 2/20... Training loss: 0.1320\n",
      "Epoch: 2/20... Training loss: 0.1324\n",
      "Epoch: 2/20... Training loss: 0.1309\n",
      "Epoch: 2/20... Training loss: 0.1257\n",
      "Epoch: 2/20... Training loss: 0.1302\n",
      "Epoch: 2/20... Training loss: 0.1342\n",
      "Epoch: 2/20... Training loss: 0.1287\n",
      "Epoch: 2/20... Training loss: 0.1292\n",
      "Epoch: 2/20... Training loss: 0.1346\n",
      "Epoch: 2/20... Training loss: 0.1343\n",
      "Epoch: 2/20... Training loss: 0.1297\n",
      "Epoch: 2/20... Training loss: 0.1319\n",
      "Epoch: 2/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1342\n",
      "Epoch: 3/20... Training loss: 0.1296\n",
      "Epoch: 3/20... Training loss: 0.1304\n",
      "Epoch: 3/20... Training loss: 0.1329\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1340\n",
      "Epoch: 3/20... Training loss: 0.1317\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1296\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1296\n",
      "Epoch: 3/20... Training loss: 0.1299\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1278\n",
      "Epoch: 3/20... Training loss: 0.1311\n",
      "Epoch: 3/20... Training loss: 0.1290\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1313\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1304\n",
      "Epoch: 3/20... Training loss: 0.1310\n",
      "Epoch: 3/20... Training loss: 0.1292\n",
      "Epoch: 3/20... Training loss: 0.1340\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1265\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1343\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1278\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1266\n",
      "Epoch: 3/20... Training loss: 0.1328\n",
      "Epoch: 3/20... Training loss: 0.1327\n",
      "Epoch: 3/20... Training loss: 0.1299\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1273\n",
      "Epoch: 3/20... Training loss: 0.1292\n",
      "Epoch: 3/20... Training loss: 0.1361\n",
      "Epoch: 3/20... Training loss: 0.1292\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1273\n",
      "Epoch: 3/20... Training loss: 0.1275\n",
      "Epoch: 3/20... Training loss: 0.1310\n",
      "Epoch: 3/20... Training loss: 0.1278\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1255\n",
      "Epoch: 3/20... Training loss: 0.1284\n",
      "Epoch: 3/20... Training loss: 0.1308\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1284\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1334\n",
      "Epoch: 3/20... Training loss: 0.1304\n",
      "Epoch: 3/20... Training loss: 0.1252\n",
      "Epoch: 3/20... Training loss: 0.1245\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1256\n",
      "Epoch: 3/20... Training loss: 0.1327\n",
      "Epoch: 3/20... Training loss: 0.1203\n",
      "Epoch: 3/20... Training loss: 0.1228\n",
      "Epoch: 3/20... Training loss: 0.1246\n",
      "Epoch: 3/20... Training loss: 0.1292\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1250\n",
      "Epoch: 3/20... Training loss: 0.1225\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1267\n",
      "Epoch: 3/20... Training loss: 0.1263\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1262\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1236\n",
      "Epoch: 3/20... Training loss: 0.1282\n",
      "Epoch: 3/20... Training loss: 0.1255\n",
      "Epoch: 3/20... Training loss: 0.1262\n",
      "Epoch: 3/20... Training loss: 0.1236\n",
      "Epoch: 3/20... Training loss: 0.1238\n",
      "Epoch: 3/20... Training loss: 0.1294\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1280\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1242\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1255\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1243\n",
      "Epoch: 3/20... Training loss: 0.1239\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1267\n",
      "Epoch: 3/20... Training loss: 0.1249\n",
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1217\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1246\n",
      "Epoch: 3/20... Training loss: 0.1233\n",
      "Epoch: 3/20... Training loss: 0.1304\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1249\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1299\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1279\n",
      "Epoch: 3/20... Training loss: 0.1273\n",
      "Epoch: 3/20... Training loss: 0.1263\n",
      "Epoch: 3/20... Training loss: 0.1193\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1233\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1241\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1241\n",
      "Epoch: 3/20... Training loss: 0.1232\n",
      "Epoch: 3/20... Training loss: 0.1248\n",
      "Epoch: 3/20... Training loss: 0.1222\n",
      "Epoch: 3/20... Training loss: 0.1227\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1209\n",
      "Epoch: 3/20... Training loss: 0.1268\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1229\n",
      "Epoch: 3/20... Training loss: 0.1239\n",
      "Epoch: 3/20... Training loss: 0.1282\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1235\n",
      "Epoch: 3/20... Training loss: 0.1296\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1266\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1282\n",
      "Epoch: 3/20... Training loss: 0.1242\n",
      "Epoch: 3/20... Training loss: 0.1255\n",
      "Epoch: 3/20... Training loss: 0.1262\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1234\n",
      "Epoch: 3/20... Training loss: 0.1256\n",
      "Epoch: 3/20... Training loss: 0.1294\n",
      "Epoch: 3/20... Training loss: 0.1223\n",
      "Epoch: 3/20... Training loss: 0.1245\n",
      "Epoch: 3/20... Training loss: 0.1231\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1248\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1282\n",
      "Epoch: 3/20... Training loss: 0.1255\n",
      "Epoch: 3/20... Training loss: 0.1277\n",
      "Epoch: 3/20... Training loss: 0.1254\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1205\n",
      "Epoch: 3/20... Training loss: 0.1235\n",
      "Epoch: 3/20... Training loss: 0.1212\n",
      "Epoch: 3/20... Training loss: 0.1199\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1229\n",
      "Epoch: 3/20... Training loss: 0.1217\n",
      "Epoch: 3/20... Training loss: 0.1245\n",
      "Epoch: 3/20... Training loss: 0.1237\n",
      "Epoch: 3/20... Training loss: 0.1235\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1253\n",
      "Epoch: 3/20... Training loss: 0.1235\n",
      "Epoch: 3/20... Training loss: 0.1251\n",
      "Epoch: 3/20... Training loss: 0.1219\n",
      "Epoch: 3/20... Training loss: 0.1249\n",
      "Epoch: 3/20... Training loss: 0.1240\n",
      "Epoch: 3/20... Training loss: 0.1191\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1224\n",
      "Epoch: 3/20... Training loss: 0.1267\n",
      "Epoch: 3/20... Training loss: 0.1287\n",
      "Epoch: 3/20... Training loss: 0.1226\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1211\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1209\n",
      "Epoch: 3/20... Training loss: 0.1183\n",
      "Epoch: 3/20... Training loss: 0.1203\n",
      "Epoch: 3/20... Training loss: 0.1246\n",
      "Epoch: 3/20... Training loss: 0.1262\n",
      "Epoch: 3/20... Training loss: 0.1239\n",
      "Epoch: 3/20... Training loss: 0.1217\n",
      "Epoch: 3/20... Training loss: 0.1247\n",
      "Epoch: 3/20... Training loss: 0.1256\n",
      "Epoch: 3/20... Training loss: 0.1234\n",
      "Epoch: 3/20... Training loss: 0.1263\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1185\n",
      "Epoch: 3/20... Training loss: 0.1254\n",
      "Epoch: 3/20... Training loss: 0.1232\n",
      "Epoch: 3/20... Training loss: 0.1195\n",
      "Epoch: 3/20... Training loss: 0.1228\n",
      "Epoch: 3/20... Training loss: 0.1248\n",
      "Epoch: 3/20... Training loss: 0.1238\n",
      "Epoch: 3/20... Training loss: 0.1172\n",
      "Epoch: 3/20... Training loss: 0.1218\n",
      "Epoch: 3/20... Training loss: 0.1195\n",
      "Epoch: 3/20... Training loss: 0.1242\n",
      "Epoch: 3/20... Training loss: 0.1205\n",
      "Epoch: 3/20... Training loss: 0.1255\n",
      "Epoch: 3/20... Training loss: 0.1206\n",
      "Epoch: 3/20... Training loss: 0.1209\n",
      "Epoch: 3/20... Training loss: 0.1168\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1191\n",
      "Epoch: 3/20... Training loss: 0.1249\n",
      "Epoch: 3/20... Training loss: 0.1242\n",
      "Epoch: 3/20... Training loss: 0.1193\n",
      "Epoch: 3/20... Training loss: 0.1257\n",
      "Epoch: 3/20... Training loss: 0.1226\n",
      "Epoch: 3/20... Training loss: 0.1233\n",
      "Epoch: 3/20... Training loss: 0.1187\n",
      "Epoch: 3/20... Training loss: 0.1197\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1211\n",
      "Epoch: 3/20... Training loss: 0.1240\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1209\n",
      "Epoch: 3/20... Training loss: 0.1267\n",
      "Epoch: 3/20... Training loss: 0.1211\n",
      "Epoch: 3/20... Training loss: 0.1236\n",
      "Epoch: 3/20... Training loss: 0.1218\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1229\n",
      "Epoch: 3/20... Training loss: 0.1224\n",
      "Epoch: 3/20... Training loss: 0.1247\n",
      "Epoch: 3/20... Training loss: 0.1235\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1225\n",
      "Epoch: 3/20... Training loss: 0.1256\n",
      "Epoch: 3/20... Training loss: 0.1227\n",
      "Epoch: 3/20... Training loss: 0.1218\n",
      "Epoch: 3/20... Training loss: 0.1179\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1200\n",
      "Epoch: 3/20... Training loss: 0.1188\n",
      "Epoch: 3/20... Training loss: 0.1229\n",
      "Epoch: 3/20... Training loss: 0.1215\n",
      "Epoch: 3/20... Training loss: 0.1234\n",
      "Epoch: 3/20... Training loss: 0.1242\n",
      "Epoch: 3/20... Training loss: 0.1221\n",
      "Epoch: 3/20... Training loss: 0.1209\n",
      "Epoch: 3/20... Training loss: 0.1249\n",
      "Epoch: 3/20... Training loss: 0.1257\n",
      "Epoch: 3/20... Training loss: 0.1246\n",
      "Epoch: 3/20... Training loss: 0.1225\n",
      "Epoch: 3/20... Training loss: 0.1201\n",
      "Epoch: 3/20... Training loss: 0.1241\n",
      "Epoch: 3/20... Training loss: 0.1191\n",
      "Epoch: 3/20... Training loss: 0.1204\n",
      "Epoch: 3/20... Training loss: 0.1225\n",
      "Epoch: 3/20... Training loss: 0.1199\n",
      "Epoch: 3/20... Training loss: 0.1218\n",
      "Epoch: 3/20... Training loss: 0.1161\n",
      "Epoch: 3/20... Training loss: 0.1216\n",
      "Epoch: 3/20... Training loss: 0.1219\n",
      "Epoch: 3/20... Training loss: 0.1202\n",
      "Epoch: 3/20... Training loss: 0.1221\n",
      "Epoch: 3/20... Training loss: 0.1240\n",
      "Epoch: 3/20... Training loss: 0.1201\n",
      "Epoch: 3/20... Training loss: 0.1204\n",
      "Epoch: 3/20... Training loss: 0.1245\n",
      "Epoch: 3/20... Training loss: 0.1188\n",
      "Epoch: 3/20... Training loss: 0.1188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20... Training loss: 0.1206\n",
      "Epoch: 3/20... Training loss: 0.1216\n",
      "Epoch: 3/20... Training loss: 0.1184\n",
      "Epoch: 3/20... Training loss: 0.1206\n",
      "Epoch: 3/20... Training loss: 0.1247\n",
      "Epoch: 3/20... Training loss: 0.1185\n",
      "Epoch: 3/20... Training loss: 0.1192\n",
      "Epoch: 3/20... Training loss: 0.1205\n",
      "Epoch: 3/20... Training loss: 0.1188\n",
      "Epoch: 3/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1274\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1171\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1170\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1223\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1230\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1189\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1178\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1159\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1254\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1172\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1208\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1248\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1175\n",
      "Epoch: 4/20... Training loss: 0.1198\n",
      "Epoch: 4/20... Training loss: 0.1185\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1175\n",
      "Epoch: 4/20... Training loss: 0.1141\n",
      "Epoch: 4/20... Training loss: 0.1200\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1183\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1200\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1220\n",
      "Epoch: 4/20... Training loss: 0.1173\n",
      "Epoch: 4/20... Training loss: 0.1172\n",
      "Epoch: 4/20... Training loss: 0.1176\n",
      "Epoch: 4/20... Training loss: 0.1223\n",
      "Epoch: 4/20... Training loss: 0.1152\n",
      "Epoch: 4/20... Training loss: 0.1198\n",
      "Epoch: 4/20... Training loss: 0.1176\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1168\n",
      "Epoch: 4/20... Training loss: 0.1182\n",
      "Epoch: 4/20... Training loss: 0.1151\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1172\n",
      "Epoch: 4/20... Training loss: 0.1233\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1169\n",
      "Epoch: 4/20... Training loss: 0.1169\n",
      "Epoch: 4/20... Training loss: 0.1208\n",
      "Epoch: 4/20... Training loss: 0.1163\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1176\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1175\n",
      "Epoch: 4/20... Training loss: 0.1223\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1220\n",
      "Epoch: 4/20... Training loss: 0.1248\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1147\n",
      "Epoch: 4/20... Training loss: 0.1247\n",
      "Epoch: 4/20... Training loss: 0.1241\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1171\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1146\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1176\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1192\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1188\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1161\n",
      "Epoch: 4/20... Training loss: 0.1165\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1200\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1250\n",
      "Epoch: 4/20... Training loss: 0.1146\n",
      "Epoch: 4/20... Training loss: 0.1172\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1167\n",
      "Epoch: 4/20... Training loss: 0.1155\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1143\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1175\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1200\n",
      "Epoch: 4/20... Training loss: 0.1173\n",
      "Epoch: 4/20... Training loss: 0.1158\n",
      "Epoch: 4/20... Training loss: 0.1170\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1213\n",
      "Epoch: 4/20... Training loss: 0.1154\n",
      "Epoch: 4/20... Training loss: 0.1182\n",
      "Epoch: 4/20... Training loss: 0.1181\n",
      "Epoch: 4/20... Training loss: 0.1150\n",
      "Epoch: 4/20... Training loss: 0.1175\n",
      "Epoch: 4/20... Training loss: 0.1182\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1163\n",
      "Epoch: 4/20... Training loss: 0.1107\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1172\n",
      "Epoch: 4/20... Training loss: 0.1126\n",
      "Epoch: 4/20... Training loss: 0.1142\n",
      "Epoch: 4/20... Training loss: 0.1220\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1176\n",
      "Epoch: 4/20... Training loss: 0.1140\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1169\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1175\n",
      "Epoch: 4/20... Training loss: 0.1223\n",
      "Epoch: 4/20... Training loss: 0.1152\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1225\n",
      "Epoch: 4/20... Training loss: 0.1157\n",
      "Epoch: 4/20... Training loss: 0.1155\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1124\n",
      "Epoch: 4/20... Training loss: 0.1181\n",
      "Epoch: 4/20... Training loss: 0.1147\n",
      "Epoch: 4/20... Training loss: 0.1146\n",
      "Epoch: 4/20... Training loss: 0.1172\n",
      "Epoch: 4/20... Training loss: 0.1139\n",
      "Epoch: 4/20... Training loss: 0.1177\n",
      "Epoch: 4/20... Training loss: 0.1182\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1158\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1178\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1146\n",
      "Epoch: 4/20... Training loss: 0.1150\n",
      "Epoch: 4/20... Training loss: 0.1168\n",
      "Epoch: 4/20... Training loss: 0.1182\n",
      "Epoch: 4/20... Training loss: 0.1164\n",
      "Epoch: 4/20... Training loss: 0.1180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20... Training loss: 0.1182\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1159\n",
      "Epoch: 4/20... Training loss: 0.1173\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1165\n",
      "Epoch: 4/20... Training loss: 0.1189\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1208\n",
      "Epoch: 4/20... Training loss: 0.1151\n",
      "Epoch: 4/20... Training loss: 0.1124\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1181\n",
      "Epoch: 4/20... Training loss: 0.1116\n",
      "Epoch: 4/20... Training loss: 0.1158\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1121\n",
      "Epoch: 4/20... Training loss: 0.1178\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1170\n",
      "Epoch: 4/20... Training loss: 0.1150\n",
      "Epoch: 4/20... Training loss: 0.1171\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1166\n",
      "Epoch: 4/20... Training loss: 0.1122\n",
      "Epoch: 4/20... Training loss: 0.1169\n",
      "Epoch: 4/20... Training loss: 0.1154\n",
      "Epoch: 4/20... Training loss: 0.1164\n",
      "Epoch: 4/20... Training loss: 0.1156\n",
      "Epoch: 4/20... Training loss: 0.1151\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1171\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1161\n",
      "Epoch: 4/20... Training loss: 0.1135\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1139\n",
      "Epoch: 4/20... Training loss: 0.1129\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1183\n",
      "Epoch: 4/20... Training loss: 0.1110\n",
      "Epoch: 4/20... Training loss: 0.1244\n",
      "Epoch: 4/20... Training loss: 0.1158\n",
      "Epoch: 4/20... Training loss: 0.1151\n",
      "Epoch: 4/20... Training loss: 0.1156\n",
      "Epoch: 4/20... Training loss: 0.1170\n",
      "Epoch: 4/20... Training loss: 0.1082\n",
      "Epoch: 4/20... Training loss: 0.1119\n",
      "Epoch: 4/20... Training loss: 0.1129\n",
      "Epoch: 4/20... Training loss: 0.1172\n",
      "Epoch: 4/20... Training loss: 0.1135\n",
      "Epoch: 4/20... Training loss: 0.1189\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1154\n",
      "Epoch: 4/20... Training loss: 0.1182\n",
      "Epoch: 4/20... Training loss: 0.1192\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1171\n",
      "Epoch: 4/20... Training loss: 0.1102\n",
      "Epoch: 4/20... Training loss: 0.1156\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1170\n",
      "Epoch: 4/20... Training loss: 0.1131\n",
      "Epoch: 4/20... Training loss: 0.1164\n",
      "Epoch: 4/20... Training loss: 0.1138\n",
      "Epoch: 4/20... Training loss: 0.1133\n",
      "Epoch: 4/20... Training loss: 0.1139\n",
      "Epoch: 4/20... Training loss: 0.1145\n",
      "Epoch: 4/20... Training loss: 0.1192\n",
      "Epoch: 4/20... Training loss: 0.1153\n",
      "Epoch: 4/20... Training loss: 0.1142\n",
      "Epoch: 4/20... Training loss: 0.1230\n",
      "Epoch: 4/20... Training loss: 0.1139\n",
      "Epoch: 4/20... Training loss: 0.1157\n",
      "Epoch: 4/20... Training loss: 0.1113\n",
      "Epoch: 4/20... Training loss: 0.1150\n",
      "Epoch: 4/20... Training loss: 0.1135\n",
      "Epoch: 4/20... Training loss: 0.1100\n",
      "Epoch: 4/20... Training loss: 0.1142\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1188\n",
      "Epoch: 5/20... Training loss: 0.1233\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1109\n",
      "Epoch: 5/20... Training loss: 0.1161\n",
      "Epoch: 5/20... Training loss: 0.1188\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1128\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1193\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1127\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1114\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1146\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1120\n",
      "Epoch: 5/20... Training loss: 0.1176\n",
      "Epoch: 5/20... Training loss: 0.1181\n",
      "Epoch: 5/20... Training loss: 0.1191\n",
      "Epoch: 5/20... Training loss: 0.1098\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1106\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1148\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1146\n",
      "Epoch: 5/20... Training loss: 0.1182\n",
      "Epoch: 5/20... Training loss: 0.1106\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1188\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1118\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1100\n",
      "Epoch: 5/20... Training loss: 0.1169\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1117\n",
      "Epoch: 5/20... Training loss: 0.1194\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1125\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1168\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1118\n",
      "Epoch: 5/20... Training loss: 0.1119\n",
      "Epoch: 5/20... Training loss: 0.1111\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1161\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1122\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1132\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1127\n",
      "Epoch: 5/20... Training loss: 0.1115\n",
      "Epoch: 5/20... Training loss: 0.1126\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1170\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1161\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1152\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1128\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1152\n",
      "Epoch: 5/20... Training loss: 0.1131\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1131\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1087\n",
      "Epoch: 5/20... Training loss: 0.1119\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1166\n",
      "Epoch: 5/20... Training loss: 0.1168\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1108\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1118\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1136\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1194\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1166\n",
      "Epoch: 5/20... Training loss: 0.1089\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1128\n",
      "Epoch: 5/20... Training loss: 0.1118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20... Training loss: 0.1095\n",
      "Epoch: 5/20... Training loss: 0.1125\n",
      "Epoch: 5/20... Training loss: 0.1105\n",
      "Epoch: 5/20... Training loss: 0.1148\n",
      "Epoch: 5/20... Training loss: 0.1166\n",
      "Epoch: 5/20... Training loss: 0.1120\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1098\n",
      "Epoch: 5/20... Training loss: 0.1132\n",
      "Epoch: 5/20... Training loss: 0.1146\n",
      "Epoch: 5/20... Training loss: 0.1107\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1131\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1107\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1131\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1086\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1125\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1129\n",
      "Epoch: 5/20... Training loss: 0.1190\n",
      "Epoch: 5/20... Training loss: 0.1088\n",
      "Epoch: 5/20... Training loss: 0.1128\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1103\n",
      "Epoch: 5/20... Training loss: 0.1098\n",
      "Epoch: 5/20... Training loss: 0.1124\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1113\n",
      "Epoch: 5/20... Training loss: 0.1113\n",
      "Epoch: 5/20... Training loss: 0.1178\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1146\n",
      "Epoch: 5/20... Training loss: 0.1162\n",
      "Epoch: 5/20... Training loss: 0.1127\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1125\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1095\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1111\n",
      "Epoch: 5/20... Training loss: 0.1093\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1146\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1112\n",
      "Epoch: 5/20... Training loss: 0.1112\n",
      "Epoch: 5/20... Training loss: 0.1128\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1128\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1117\n",
      "Epoch: 5/20... Training loss: 0.1132\n",
      "Epoch: 5/20... Training loss: 0.1088\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1126\n",
      "Epoch: 5/20... Training loss: 0.1128\n",
      "Epoch: 5/20... Training loss: 0.1101\n",
      "Epoch: 5/20... Training loss: 0.1176\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1110\n",
      "Epoch: 5/20... Training loss: 0.1080\n",
      "Epoch: 5/20... Training loss: 0.1077\n",
      "Epoch: 5/20... Training loss: 0.1096\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1109\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1182\n",
      "Epoch: 5/20... Training loss: 0.1146\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1169\n",
      "Epoch: 5/20... Training loss: 0.1106\n",
      "Epoch: 5/20... Training loss: 0.1118\n",
      "Epoch: 5/20... Training loss: 0.1116\n",
      "Epoch: 5/20... Training loss: 0.1118\n",
      "Epoch: 5/20... Training loss: 0.1126\n",
      "Epoch: 5/20... Training loss: 0.1102\n",
      "Epoch: 5/20... Training loss: 0.1125\n",
      "Epoch: 5/20... Training loss: 0.1091\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1095\n",
      "Epoch: 5/20... Training loss: 0.1103\n",
      "Epoch: 5/20... Training loss: 0.1103\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1119\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1129\n",
      "Epoch: 5/20... Training loss: 0.1131\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1118\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1124\n",
      "Epoch: 5/20... Training loss: 0.1122\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1100\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1110\n",
      "Epoch: 5/20... Training loss: 0.1101\n",
      "Epoch: 5/20... Training loss: 0.1148\n",
      "Epoch: 5/20... Training loss: 0.1084\n",
      "Epoch: 5/20... Training loss: 0.1116\n",
      "Epoch: 5/20... Training loss: 0.1115\n",
      "Epoch: 5/20... Training loss: 0.1131\n",
      "Epoch: 5/20... Training loss: 0.1129\n",
      "Epoch: 5/20... Training loss: 0.1093\n",
      "Epoch: 5/20... Training loss: 0.1112\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1126\n",
      "Epoch: 5/20... Training loss: 0.1129\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1114\n",
      "Epoch: 5/20... Training loss: 0.1152\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1123\n",
      "Epoch: 5/20... Training loss: 0.1182\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1099\n",
      "Epoch: 5/20... Training loss: 0.1111\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1119\n",
      "Epoch: 5/20... Training loss: 0.1106\n",
      "Epoch: 5/20... Training loss: 0.1115\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1097\n",
      "Epoch: 5/20... Training loss: 0.1088\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1161\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1118\n",
      "Epoch: 5/20... Training loss: 0.1119\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1128\n",
      "Epoch: 5/20... Training loss: 0.1066\n",
      "Epoch: 5/20... Training loss: 0.1094\n",
      "Epoch: 5/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1104\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1116\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1090\n",
      "Epoch: 6/20... Training loss: 0.1078\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1115\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1130\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1077\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1096\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1095\n",
      "Epoch: 6/20... Training loss: 0.1109\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1084\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1112\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1088\n",
      "Epoch: 6/20... Training loss: 0.1118\n",
      "Epoch: 6/20... Training loss: 0.1100\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1088\n",
      "Epoch: 6/20... Training loss: 0.1071\n",
      "Epoch: 6/20... Training loss: 0.1130\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1101\n",
      "Epoch: 6/20... Training loss: 0.1077\n",
      "Epoch: 6/20... Training loss: 0.1074\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1131\n",
      "Epoch: 6/20... Training loss: 0.1136\n",
      "Epoch: 6/20... Training loss: 0.1039\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1095\n",
      "Epoch: 6/20... Training loss: 0.1105\n",
      "Epoch: 6/20... Training loss: 0.1104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20... Training loss: 0.1124\n",
      "Epoch: 6/20... Training loss: 0.1106\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1128\n",
      "Epoch: 6/20... Training loss: 0.1097\n",
      "Epoch: 6/20... Training loss: 0.1124\n",
      "Epoch: 6/20... Training loss: 0.1104\n",
      "Epoch: 6/20... Training loss: 0.1091\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1103\n",
      "Epoch: 6/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1154\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1117\n",
      "Epoch: 6/20... Training loss: 0.1115\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1050\n",
      "Epoch: 6/20... Training loss: 0.1080\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1116\n",
      "Epoch: 6/20... Training loss: 0.1090\n",
      "Epoch: 6/20... Training loss: 0.1116\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1103\n",
      "Epoch: 6/20... Training loss: 0.1097\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1107\n",
      "Epoch: 6/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1118\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1150\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1069\n",
      "Epoch: 6/20... Training loss: 0.1075\n",
      "Epoch: 6/20... Training loss: 0.1104\n",
      "Epoch: 6/20... Training loss: 0.1074\n",
      "Epoch: 6/20... Training loss: 0.1098\n",
      "Epoch: 6/20... Training loss: 0.1106\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1154\n",
      "Epoch: 6/20... Training loss: 0.1103\n",
      "Epoch: 6/20... Training loss: 0.1134\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1087\n",
      "Epoch: 6/20... Training loss: 0.1052\n",
      "Epoch: 6/20... Training loss: 0.1104\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1122\n",
      "Epoch: 6/20... Training loss: 0.1097\n",
      "Epoch: 6/20... Training loss: 0.1109\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1081\n",
      "Epoch: 6/20... Training loss: 0.1058\n",
      "Epoch: 6/20... Training loss: 0.1095\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1077\n",
      "Epoch: 6/20... Training loss: 0.1033\n",
      "Epoch: 6/20... Training loss: 0.1134\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1079\n",
      "Epoch: 6/20... Training loss: 0.1087\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1064\n",
      "Epoch: 6/20... Training loss: 0.1088\n",
      "Epoch: 6/20... Training loss: 0.1096\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1124\n",
      "Epoch: 6/20... Training loss: 0.1102\n",
      "Epoch: 6/20... Training loss: 0.1058\n",
      "Epoch: 6/20... Training loss: 0.1079\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1112\n",
      "Epoch: 6/20... Training loss: 0.1055\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1067\n",
      "Epoch: 6/20... Training loss: 0.1087\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1107\n",
      "Epoch: 6/20... Training loss: 0.1084\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1081\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1076\n",
      "Epoch: 6/20... Training loss: 0.1121\n",
      "Epoch: 6/20... Training loss: 0.1052\n",
      "Epoch: 6/20... Training loss: 0.1070\n",
      "Epoch: 6/20... Training loss: 0.1134\n",
      "Epoch: 6/20... Training loss: 0.1118\n",
      "Epoch: 6/20... Training loss: 0.1155\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1046\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1084\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1128\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1121\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1065\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1076\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1073\n",
      "Epoch: 6/20... Training loss: 0.1091\n",
      "Epoch: 6/20... Training loss: 0.1089\n",
      "Epoch: 6/20... Training loss: 0.1041\n",
      "Epoch: 6/20... Training loss: 0.1096\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1115\n",
      "Epoch: 6/20... Training loss: 0.1171\n",
      "Epoch: 6/20... Training loss: 0.1073\n",
      "Epoch: 6/20... Training loss: 0.1109\n",
      "Epoch: 6/20... Training loss: 0.1101\n",
      "Epoch: 6/20... Training loss: 0.1080\n",
      "Epoch: 6/20... Training loss: 0.1073\n",
      "Epoch: 6/20... Training loss: 0.1105\n",
      "Epoch: 6/20... Training loss: 0.1103\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1076\n",
      "Epoch: 6/20... Training loss: 0.1093\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1106\n",
      "Epoch: 6/20... Training loss: 0.1073\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1099\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1107\n",
      "Epoch: 6/20... Training loss: 0.1100\n",
      "Epoch: 6/20... Training loss: 0.1067\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1053\n",
      "Epoch: 6/20... Training loss: 0.1079\n",
      "Epoch: 6/20... Training loss: 0.1124\n",
      "Epoch: 6/20... Training loss: 0.1130\n",
      "Epoch: 6/20... Training loss: 0.1101\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1107\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1103\n",
      "Epoch: 6/20... Training loss: 0.1115\n",
      "Epoch: 6/20... Training loss: 0.1051\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1091\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1084\n",
      "Epoch: 6/20... Training loss: 0.1039\n",
      "Epoch: 6/20... Training loss: 0.1072\n",
      "Epoch: 6/20... Training loss: 0.1088\n",
      "Epoch: 6/20... Training loss: 0.1100\n",
      "Epoch: 6/20... Training loss: 0.1075\n",
      "Epoch: 6/20... Training loss: 0.1090\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1105\n",
      "Epoch: 6/20... Training loss: 0.1071\n",
      "Epoch: 6/20... Training loss: 0.1071\n",
      "Epoch: 6/20... Training loss: 0.1020\n",
      "Epoch: 6/20... Training loss: 0.1093\n",
      "Epoch: 6/20... Training loss: 0.1070\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1075\n",
      "Epoch: 6/20... Training loss: 0.1063\n",
      "Epoch: 6/20... Training loss: 0.1116\n",
      "Epoch: 6/20... Training loss: 0.1106\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1109\n",
      "Epoch: 6/20... Training loss: 0.1099\n",
      "Epoch: 6/20... Training loss: 0.1054\n",
      "Epoch: 6/20... Training loss: 0.1066\n",
      "Epoch: 6/20... Training loss: 0.1056\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1051\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1084\n",
      "Epoch: 6/20... Training loss: 0.1063\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1057\n",
      "Epoch: 6/20... Training loss: 0.1069\n",
      "Epoch: 6/20... Training loss: 0.1103\n",
      "Epoch: 6/20... Training loss: 0.1085\n",
      "Epoch: 6/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1099\n",
      "Epoch: 6/20... Training loss: 0.1060\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1069\n",
      "Epoch: 6/20... Training loss: 0.1079\n",
      "Epoch: 6/20... Training loss: 0.1063\n",
      "Epoch: 6/20... Training loss: 0.1102\n",
      "Epoch: 6/20... Training loss: 0.1067\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1064\n",
      "Epoch: 6/20... Training loss: 0.1078\n",
      "Epoch: 6/20... Training loss: 0.1040\n",
      "Epoch: 6/20... Training loss: 0.1100\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1107\n",
      "Epoch: 6/20... Training loss: 0.1050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1075\n",
      "Epoch: 6/20... Training loss: 0.1091\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1079\n",
      "Epoch: 6/20... Training loss: 0.1045\n",
      "Epoch: 6/20... Training loss: 0.1106\n",
      "Epoch: 6/20... Training loss: 0.1098\n",
      "Epoch: 6/20... Training loss: 0.1097\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1041\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1099\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1098\n",
      "Epoch: 6/20... Training loss: 0.1075\n",
      "Epoch: 6/20... Training loss: 0.1088\n",
      "Epoch: 6/20... Training loss: 0.1071\n",
      "Epoch: 7/20... Training loss: 0.1101\n",
      "Epoch: 7/20... Training loss: 0.1083\n",
      "Epoch: 7/20... Training loss: 0.1087\n",
      "Epoch: 7/20... Training loss: 0.1083\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1058\n",
      "Epoch: 7/20... Training loss: 0.1115\n",
      "Epoch: 7/20... Training loss: 0.1078\n",
      "Epoch: 7/20... Training loss: 0.1053\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1130\n",
      "Epoch: 7/20... Training loss: 0.1075\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1073\n",
      "Epoch: 7/20... Training loss: 0.1083\n",
      "Epoch: 7/20... Training loss: 0.1050\n",
      "Epoch: 7/20... Training loss: 0.1073\n",
      "Epoch: 7/20... Training loss: 0.1067\n",
      "Epoch: 7/20... Training loss: 0.1075\n",
      "Epoch: 7/20... Training loss: 0.1076\n",
      "Epoch: 7/20... Training loss: 0.1053\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1082\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1064\n",
      "Epoch: 7/20... Training loss: 0.1116\n",
      "Epoch: 7/20... Training loss: 0.1091\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1071\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1081\n",
      "Epoch: 7/20... Training loss: 0.1069\n",
      "Epoch: 7/20... Training loss: 0.1087\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1099\n",
      "Epoch: 7/20... Training loss: 0.1054\n",
      "Epoch: 7/20... Training loss: 0.1076\n",
      "Epoch: 7/20... Training loss: 0.1075\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1083\n",
      "Epoch: 7/20... Training loss: 0.1060\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1061\n",
      "Epoch: 7/20... Training loss: 0.1065\n",
      "Epoch: 7/20... Training loss: 0.1056\n",
      "Epoch: 7/20... Training loss: 0.1066\n",
      "Epoch: 7/20... Training loss: 0.1080\n",
      "Epoch: 7/20... Training loss: 0.1080\n",
      "Epoch: 7/20... Training loss: 0.1088\n",
      "Epoch: 7/20... Training loss: 0.1070\n",
      "Epoch: 7/20... Training loss: 0.1084\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1049\n",
      "Epoch: 7/20... Training loss: 0.1069\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1099\n",
      "Epoch: 7/20... Training loss: 0.1064\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1071\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1065\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1080\n",
      "Epoch: 7/20... Training loss: 0.1088\n",
      "Epoch: 7/20... Training loss: 0.1071\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1048\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1063\n",
      "Epoch: 7/20... Training loss: 0.1065\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1060\n",
      "Epoch: 7/20... Training loss: 0.1075\n",
      "Epoch: 7/20... Training loss: 0.1082\n",
      "Epoch: 7/20... Training loss: 0.1079\n",
      "Epoch: 7/20... Training loss: 0.1063\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1038\n",
      "Epoch: 7/20... Training loss: 0.1057\n",
      "Epoch: 7/20... Training loss: 0.1089\n",
      "Epoch: 7/20... Training loss: 0.1084\n",
      "Epoch: 7/20... Training loss: 0.1061\n",
      "Epoch: 7/20... Training loss: 0.1071\n",
      "Epoch: 7/20... Training loss: 0.1064\n",
      "Epoch: 7/20... Training loss: 0.1082\n",
      "Epoch: 7/20... Training loss: 0.1092\n",
      "Epoch: 7/20... Training loss: 0.1139\n",
      "Epoch: 7/20... Training loss: 0.1076\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1068\n",
      "Epoch: 7/20... Training loss: 0.1058\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1077\n",
      "Epoch: 7/20... Training loss: 0.1059\n",
      "Epoch: 7/20... Training loss: 0.1082\n",
      "Epoch: 7/20... Training loss: 0.1063\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1083\n",
      "Epoch: 7/20... Training loss: 0.1054\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1085\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1071\n",
      "Epoch: 7/20... Training loss: 0.1069\n",
      "Epoch: 7/20... Training loss: 0.1076\n",
      "Epoch: 7/20... Training loss: 0.1077\n",
      "Epoch: 7/20... Training loss: 0.1053\n",
      "Epoch: 7/20... Training loss: 0.1066\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1103\n",
      "Epoch: 7/20... Training loss: 0.1081\n",
      "Epoch: 7/20... Training loss: 0.1069\n",
      "Epoch: 7/20... Training loss: 0.1077\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1091\n",
      "Epoch: 7/20... Training loss: 0.1061\n",
      "Epoch: 7/20... Training loss: 0.1073\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1071\n",
      "Epoch: 7/20... Training loss: 0.1066\n",
      "Epoch: 7/20... Training loss: 0.1070\n",
      "Epoch: 7/20... Training loss: 0.1001\n",
      "Epoch: 7/20... Training loss: 0.1083\n",
      "Epoch: 7/20... Training loss: 0.1054\n",
      "Epoch: 7/20... Training loss: 0.1059\n",
      "Epoch: 7/20... Training loss: 0.1048\n",
      "Epoch: 7/20... Training loss: 0.1069\n",
      "Epoch: 7/20... Training loss: 0.1072\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1087\n",
      "Epoch: 7/20... Training loss: 0.1063\n",
      "Epoch: 7/20... Training loss: 0.1074\n",
      "Epoch: 7/20... Training loss: 0.1077\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1083\n",
      "Epoch: 7/20... Training loss: 0.1070\n",
      "Epoch: 7/20... Training loss: 0.1069\n",
      "Epoch: 7/20... Training loss: 0.1088\n",
      "Epoch: 7/20... Training loss: 0.1073\n",
      "Epoch: 7/20... Training loss: 0.1084\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1053\n",
      "Epoch: 7/20... Training loss: 0.1084\n",
      "Epoch: 7/20... Training loss: 0.1050\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1036\n",
      "Epoch: 7/20... Training loss: 0.1068\n",
      "Epoch: 7/20... Training loss: 0.1055\n",
      "Epoch: 7/20... Training loss: 0.1056\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1070\n",
      "Epoch: 7/20... Training loss: 0.1077\n",
      "Epoch: 7/20... Training loss: 0.1111\n",
      "Epoch: 7/20... Training loss: 0.1050\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1025\n",
      "Epoch: 7/20... Training loss: 0.1074\n",
      "Epoch: 7/20... Training loss: 0.1088\n",
      "Epoch: 7/20... Training loss: 0.1059\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1024\n",
      "Epoch: 7/20... Training loss: 0.1057\n",
      "Epoch: 7/20... Training loss: 0.1069\n",
      "Epoch: 7/20... Training loss: 0.1073\n",
      "Epoch: 7/20... Training loss: 0.1080\n",
      "Epoch: 7/20... Training loss: 0.1069\n",
      "Epoch: 7/20... Training loss: 0.1046\n",
      "Epoch: 7/20... Training loss: 0.1084\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1074\n",
      "Epoch: 7/20... Training loss: 0.1104\n",
      "Epoch: 7/20... Training loss: 0.1087\n",
      "Epoch: 7/20... Training loss: 0.1108\n",
      "Epoch: 7/20... Training loss: 0.1088\n",
      "Epoch: 7/20... Training loss: 0.1076\n",
      "Epoch: 7/20... Training loss: 0.1054\n",
      "Epoch: 7/20... Training loss: 0.1082\n",
      "Epoch: 7/20... Training loss: 0.1079\n",
      "Epoch: 7/20... Training loss: 0.1048\n",
      "Epoch: 7/20... Training loss: 0.1055\n",
      "Epoch: 7/20... Training loss: 0.1070\n",
      "Epoch: 7/20... Training loss: 0.1043\n",
      "Epoch: 7/20... Training loss: 0.1078\n",
      "Epoch: 7/20... Training loss: 0.1104\n",
      "Epoch: 7/20... Training loss: 0.1067\n",
      "Epoch: 7/20... Training loss: 0.1069\n",
      "Epoch: 7/20... Training loss: 0.1056\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1103\n",
      "Epoch: 7/20... Training loss: 0.1042\n",
      "Epoch: 7/20... Training loss: 0.1060\n",
      "Epoch: 7/20... Training loss: 0.1070\n",
      "Epoch: 7/20... Training loss: 0.1108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20... Training loss: 0.1092\n",
      "Epoch: 7/20... Training loss: 0.1070\n",
      "Epoch: 7/20... Training loss: 0.1078\n",
      "Epoch: 7/20... Training loss: 0.1075\n",
      "Epoch: 7/20... Training loss: 0.1047\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1136\n",
      "Epoch: 7/20... Training loss: 0.1070\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1092\n",
      "Epoch: 7/20... Training loss: 0.1079\n",
      "Epoch: 7/20... Training loss: 0.1089\n",
      "Epoch: 7/20... Training loss: 0.1021\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1051\n",
      "Epoch: 7/20... Training loss: 0.1058\n",
      "Epoch: 7/20... Training loss: 0.1080\n",
      "Epoch: 7/20... Training loss: 0.1068\n",
      "Epoch: 7/20... Training loss: 0.1042\n",
      "Epoch: 7/20... Training loss: 0.1081\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1075\n",
      "Epoch: 7/20... Training loss: 0.1081\n",
      "Epoch: 7/20... Training loss: 0.1059\n",
      "Epoch: 7/20... Training loss: 0.1083\n",
      "Epoch: 7/20... Training loss: 0.1039\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1060\n",
      "Epoch: 7/20... Training loss: 0.1052\n",
      "Epoch: 7/20... Training loss: 0.1076\n",
      "Epoch: 7/20... Training loss: 0.1079\n",
      "Epoch: 7/20... Training loss: 0.1060\n",
      "Epoch: 7/20... Training loss: 0.1033\n",
      "Epoch: 7/20... Training loss: 0.1064\n",
      "Epoch: 7/20... Training loss: 0.1066\n",
      "Epoch: 7/20... Training loss: 0.1085\n",
      "Epoch: 7/20... Training loss: 0.1104\n",
      "Epoch: 7/20... Training loss: 0.1058\n",
      "Epoch: 7/20... Training loss: 0.1103\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1082\n",
      "Epoch: 7/20... Training loss: 0.1019\n",
      "Epoch: 7/20... Training loss: 0.1022\n",
      "Epoch: 7/20... Training loss: 0.1074\n",
      "Epoch: 7/20... Training loss: 0.1042\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1079\n",
      "Epoch: 7/20... Training loss: 0.1046\n",
      "Epoch: 7/20... Training loss: 0.1030\n",
      "Epoch: 7/20... Training loss: 0.1044\n",
      "Epoch: 7/20... Training loss: 0.1053\n",
      "Epoch: 7/20... Training loss: 0.1064\n",
      "Epoch: 7/20... Training loss: 0.1089\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1091\n",
      "Epoch: 7/20... Training loss: 0.1077\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1056\n",
      "Epoch: 7/20... Training loss: 0.1073\n",
      "Epoch: 7/20... Training loss: 0.1085\n",
      "Epoch: 7/20... Training loss: 0.1065\n",
      "Epoch: 7/20... Training loss: 0.1091\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1055\n",
      "Epoch: 7/20... Training loss: 0.1073\n",
      "Epoch: 7/20... Training loss: 0.1092\n",
      "Epoch: 7/20... Training loss: 0.1085\n",
      "Epoch: 7/20... Training loss: 0.1051\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1096\n",
      "Epoch: 7/20... Training loss: 0.1049\n",
      "Epoch: 7/20... Training loss: 0.1054\n",
      "Epoch: 7/20... Training loss: 0.1028\n",
      "Epoch: 7/20... Training loss: 0.1049\n",
      "Epoch: 7/20... Training loss: 0.1056\n",
      "Epoch: 7/20... Training loss: 0.1071\n",
      "Epoch: 7/20... Training loss: 0.1037\n",
      "Epoch: 7/20... Training loss: 0.1071\n",
      "Epoch: 7/20... Training loss: 0.1050\n",
      "Epoch: 7/20... Training loss: 0.1088\n",
      "Epoch: 7/20... Training loss: 0.1072\n",
      "Epoch: 7/20... Training loss: 0.1065\n",
      "Epoch: 7/20... Training loss: 0.1073\n",
      "Epoch: 7/20... Training loss: 0.1047\n",
      "Epoch: 7/20... Training loss: 0.1087\n",
      "Epoch: 7/20... Training loss: 0.1022\n",
      "Epoch: 7/20... Training loss: 0.1053\n",
      "Epoch: 7/20... Training loss: 0.1035\n",
      "Epoch: 7/20... Training loss: 0.1045\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1051\n",
      "Epoch: 7/20... Training loss: 0.1092\n",
      "Epoch: 7/20... Training loss: 0.1073\n",
      "Epoch: 8/20... Training loss: 0.1051\n",
      "Epoch: 8/20... Training loss: 0.1058\n",
      "Epoch: 8/20... Training loss: 0.1058\n",
      "Epoch: 8/20... Training loss: 0.1080\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1053\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1067\n",
      "Epoch: 8/20... Training loss: 0.1046\n",
      "Epoch: 8/20... Training loss: 0.1062\n",
      "Epoch: 8/20... Training loss: 0.1033\n",
      "Epoch: 8/20... Training loss: 0.1017\n",
      "Epoch: 8/20... Training loss: 0.1059\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1046\n",
      "Epoch: 8/20... Training loss: 0.1041\n",
      "Epoch: 8/20... Training loss: 0.1053\n",
      "Epoch: 8/20... Training loss: 0.1065\n",
      "Epoch: 8/20... Training loss: 0.1037\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1079\n",
      "Epoch: 8/20... Training loss: 0.1077\n",
      "Epoch: 8/20... Training loss: 0.1040\n",
      "Epoch: 8/20... Training loss: 0.1040\n",
      "Epoch: 8/20... Training loss: 0.1044\n",
      "Epoch: 8/20... Training loss: 0.1042\n",
      "Epoch: 8/20... Training loss: 0.1054\n",
      "Epoch: 8/20... Training loss: 0.1018\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1067\n",
      "Epoch: 8/20... Training loss: 0.0999\n",
      "Epoch: 8/20... Training loss: 0.1033\n",
      "Epoch: 8/20... Training loss: 0.1072\n",
      "Epoch: 8/20... Training loss: 0.1057\n",
      "Epoch: 8/20... Training loss: 0.1044\n",
      "Epoch: 8/20... Training loss: 0.1060\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1028\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1013\n",
      "Epoch: 8/20... Training loss: 0.1077\n",
      "Epoch: 8/20... Training loss: 0.1023\n",
      "Epoch: 8/20... Training loss: 0.1055\n",
      "Epoch: 8/20... Training loss: 0.1059\n",
      "Epoch: 8/20... Training loss: 0.1061\n",
      "Epoch: 8/20... Training loss: 0.1037\n",
      "Epoch: 8/20... Training loss: 0.1034\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1060\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1054\n",
      "Epoch: 8/20... Training loss: 0.1006\n",
      "Epoch: 8/20... Training loss: 0.1055\n",
      "Epoch: 8/20... Training loss: 0.1059\n",
      "Epoch: 8/20... Training loss: 0.1033\n",
      "Epoch: 8/20... Training loss: 0.1043\n",
      "Epoch: 8/20... Training loss: 0.1034\n",
      "Epoch: 8/20... Training loss: 0.1021\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1061\n",
      "Epoch: 8/20... Training loss: 0.1058\n",
      "Epoch: 8/20... Training loss: 0.1055\n",
      "Epoch: 8/20... Training loss: 0.1096\n",
      "Epoch: 8/20... Training loss: 0.1070\n",
      "Epoch: 8/20... Training loss: 0.1072\n",
      "Epoch: 8/20... Training loss: 0.1062\n",
      "Epoch: 8/20... Training loss: 0.1052\n",
      "Epoch: 8/20... Training loss: 0.1057\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1077\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1066\n",
      "Epoch: 8/20... Training loss: 0.1060\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1057\n",
      "Epoch: 8/20... Training loss: 0.1045\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1047\n",
      "Epoch: 8/20... Training loss: 0.1043\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1106\n",
      "Epoch: 8/20... Training loss: 0.1018\n",
      "Epoch: 8/20... Training loss: 0.1074\n",
      "Epoch: 8/20... Training loss: 0.1005\n",
      "Epoch: 8/20... Training loss: 0.1036\n",
      "Epoch: 8/20... Training loss: 0.1087\n",
      "Epoch: 8/20... Training loss: 0.1091\n",
      "Epoch: 8/20... Training loss: 0.1041\n",
      "Epoch: 8/20... Training loss: 0.1038\n",
      "Epoch: 8/20... Training loss: 0.1054\n",
      "Epoch: 8/20... Training loss: 0.1049\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1043\n",
      "Epoch: 8/20... Training loss: 0.1054\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1062\n",
      "Epoch: 8/20... Training loss: 0.1046\n",
      "Epoch: 8/20... Training loss: 0.1039\n",
      "Epoch: 8/20... Training loss: 0.1069\n",
      "Epoch: 8/20... Training loss: 0.1050\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1041\n",
      "Epoch: 8/20... Training loss: 0.1051\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1090\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1048\n",
      "Epoch: 8/20... Training loss: 0.1083\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1019\n",
      "Epoch: 8/20... Training loss: 0.1048\n",
      "Epoch: 8/20... Training loss: 0.1040\n",
      "Epoch: 8/20... Training loss: 0.1059\n",
      "Epoch: 8/20... Training loss: 0.1058\n",
      "Epoch: 8/20... Training loss: 0.1067\n",
      "Epoch: 8/20... Training loss: 0.1048\n",
      "Epoch: 8/20... Training loss: 0.1042\n",
      "Epoch: 8/20... Training loss: 0.1044\n",
      "Epoch: 8/20... Training loss: 0.1044\n",
      "Epoch: 8/20... Training loss: 0.1030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1072\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1012\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1086\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1086\n",
      "Epoch: 8/20... Training loss: 0.1019\n",
      "Epoch: 8/20... Training loss: 0.1047\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1070\n",
      "Epoch: 8/20... Training loss: 0.1032\n",
      "Epoch: 8/20... Training loss: 0.1035\n",
      "Epoch: 8/20... Training loss: 0.1004\n",
      "Epoch: 8/20... Training loss: 0.1056\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1025\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1045\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1037\n",
      "Epoch: 8/20... Training loss: 0.1032\n",
      "Epoch: 8/20... Training loss: 0.1044\n",
      "Epoch: 8/20... Training loss: 0.1047\n",
      "Epoch: 8/20... Training loss: 0.1040\n",
      "Epoch: 8/20... Training loss: 0.1091\n",
      "Epoch: 8/20... Training loss: 0.1025\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1096\n",
      "Epoch: 8/20... Training loss: 0.1004\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1013\n",
      "Epoch: 8/20... Training loss: 0.1074\n",
      "Epoch: 8/20... Training loss: 0.1023\n",
      "Epoch: 8/20... Training loss: 0.1036\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1080\n",
      "Epoch: 8/20... Training loss: 0.1051\n",
      "Epoch: 8/20... Training loss: 0.1022\n",
      "Epoch: 8/20... Training loss: 0.1023\n",
      "Epoch: 8/20... Training loss: 0.1050\n",
      "Epoch: 8/20... Training loss: 0.1055\n",
      "Epoch: 8/20... Training loss: 0.1066\n",
      "Epoch: 8/20... Training loss: 0.1074\n",
      "Epoch: 8/20... Training loss: 0.1051\n",
      "Epoch: 8/20... Training loss: 0.1045\n",
      "Epoch: 8/20... Training loss: 0.1041\n",
      "Epoch: 8/20... Training loss: 0.1062\n",
      "Epoch: 8/20... Training loss: 0.1045\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1036\n",
      "Epoch: 8/20... Training loss: 0.1033\n",
      "Epoch: 8/20... Training loss: 0.1057\n",
      "Epoch: 8/20... Training loss: 0.1073\n",
      "Epoch: 8/20... Training loss: 0.1069\n",
      "Epoch: 8/20... Training loss: 0.1044\n",
      "Epoch: 8/20... Training loss: 0.1069\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1019\n",
      "Epoch: 8/20... Training loss: 0.1057\n",
      "Epoch: 8/20... Training loss: 0.1048\n",
      "Epoch: 8/20... Training loss: 0.1069\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1087\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1034\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1046\n",
      "Epoch: 8/20... Training loss: 0.1040\n",
      "Epoch: 8/20... Training loss: 0.1029\n",
      "Epoch: 8/20... Training loss: 0.1040\n",
      "Epoch: 8/20... Training loss: 0.1059\n",
      "Epoch: 8/20... Training loss: 0.1053\n",
      "Epoch: 8/20... Training loss: 0.1026\n",
      "Epoch: 8/20... Training loss: 0.1119\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1052\n",
      "Epoch: 8/20... Training loss: 0.1044\n",
      "Epoch: 8/20... Training loss: 0.1064\n",
      "Epoch: 8/20... Training loss: 0.1047\n",
      "Epoch: 8/20... Training loss: 0.1059\n",
      "Epoch: 8/20... Training loss: 0.1060\n",
      "Epoch: 8/20... Training loss: 0.1085\n",
      "Epoch: 8/20... Training loss: 0.1031\n",
      "Epoch: 8/20... Training loss: 0.1009\n",
      "Epoch: 8/20... Training loss: 0.1087\n",
      "Epoch: 8/20... Training loss: 0.1033\n",
      "Epoch: 8/20... Training loss: 0.1052\n",
      "Epoch: 8/20... Training loss: 0.1048\n",
      "Epoch: 8/20... Training loss: 0.1020\n",
      "Epoch: 8/20... Training loss: 0.1066\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1072\n",
      "Epoch: 8/20... Training loss: 0.1052\n",
      "Epoch: 8/20... Training loss: 0.1056\n",
      "Epoch: 8/20... Training loss: 0.1060\n",
      "Epoch: 8/20... Training loss: 0.1035\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1037\n",
      "Epoch: 8/20... Training loss: 0.1058\n",
      "Epoch: 8/20... Training loss: 0.1028\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.0981\n",
      "Epoch: 8/20... Training loss: 0.1069\n",
      "Epoch: 8/20... Training loss: 0.1079\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1050\n",
      "Epoch: 8/20... Training loss: 0.1072\n",
      "Epoch: 8/20... Training loss: 0.1044\n",
      "Epoch: 8/20... Training loss: 0.1065\n",
      "Epoch: 8/20... Training loss: 0.1051\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1049\n",
      "Epoch: 8/20... Training loss: 0.1057\n",
      "Epoch: 8/20... Training loss: 0.1007\n",
      "Epoch: 8/20... Training loss: 0.1063\n",
      "Epoch: 8/20... Training loss: 0.1070\n",
      "Epoch: 8/20... Training loss: 0.1069\n",
      "Epoch: 8/20... Training loss: 0.1049\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1049\n",
      "Epoch: 8/20... Training loss: 0.1063\n",
      "Epoch: 8/20... Training loss: 0.1014\n",
      "Epoch: 8/20... Training loss: 0.1061\n",
      "Epoch: 8/20... Training loss: 0.1040\n",
      "Epoch: 8/20... Training loss: 0.1038\n",
      "Epoch: 8/20... Training loss: 0.1018\n",
      "Epoch: 8/20... Training loss: 0.1057\n",
      "Epoch: 8/20... Training loss: 0.1061\n",
      "Epoch: 8/20... Training loss: 0.1070\n",
      "Epoch: 8/20... Training loss: 0.1080\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1042\n",
      "Epoch: 8/20... Training loss: 0.1022\n",
      "Epoch: 8/20... Training loss: 0.1046\n",
      "Epoch: 8/20... Training loss: 0.1036\n",
      "Epoch: 8/20... Training loss: 0.1048\n",
      "Epoch: 8/20... Training loss: 0.1043\n",
      "Epoch: 8/20... Training loss: 0.1061\n",
      "Epoch: 8/20... Training loss: 0.1048\n",
      "Epoch: 8/20... Training loss: 0.1052\n",
      "Epoch: 8/20... Training loss: 0.1038\n",
      "Epoch: 8/20... Training loss: 0.1077\n",
      "Epoch: 8/20... Training loss: 0.1074\n",
      "Epoch: 8/20... Training loss: 0.1072\n",
      "Epoch: 8/20... Training loss: 0.1043\n",
      "Epoch: 8/20... Training loss: 0.1048\n",
      "Epoch: 8/20... Training loss: 0.1030\n",
      "Epoch: 8/20... Training loss: 0.1040\n",
      "Epoch: 8/20... Training loss: 0.1032\n",
      "Epoch: 8/20... Training loss: 0.1024\n",
      "Epoch: 8/20... Training loss: 0.1054\n",
      "Epoch: 8/20... Training loss: 0.1027\n",
      "Epoch: 8/20... Training loss: 0.1043\n",
      "Epoch: 8/20... Training loss: 0.0998\n",
      "Epoch: 8/20... Training loss: 0.1061\n",
      "Epoch: 8/20... Training loss: 0.1060\n",
      "Epoch: 8/20... Training loss: 0.1057\n",
      "Epoch: 8/20... Training loss: 0.1052\n",
      "Epoch: 8/20... Training loss: 0.1018\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1039\n",
      "Epoch: 8/20... Training loss: 0.1014\n",
      "Epoch: 8/20... Training loss: 0.1017\n",
      "Epoch: 9/20... Training loss: 0.1055\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1038\n",
      "Epoch: 9/20... Training loss: 0.1046\n",
      "Epoch: 9/20... Training loss: 0.1040\n",
      "Epoch: 9/20... Training loss: 0.1012\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1062\n",
      "Epoch: 9/20... Training loss: 0.1084\n",
      "Epoch: 9/20... Training loss: 0.1048\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1062\n",
      "Epoch: 9/20... Training loss: 0.1069\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1024\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1080\n",
      "Epoch: 9/20... Training loss: 0.1049\n",
      "Epoch: 9/20... Training loss: 0.1067\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1039\n",
      "Epoch: 9/20... Training loss: 0.1055\n",
      "Epoch: 9/20... Training loss: 0.1039\n",
      "Epoch: 9/20... Training loss: 0.1036\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1041\n",
      "Epoch: 9/20... Training loss: 0.1117\n",
      "Epoch: 9/20... Training loss: 0.1055\n",
      "Epoch: 9/20... Training loss: 0.1023\n",
      "Epoch: 9/20... Training loss: 0.1051\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1005\n",
      "Epoch: 9/20... Training loss: 0.1037\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1006\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1048\n",
      "Epoch: 9/20... Training loss: 0.1042\n",
      "Epoch: 9/20... Training loss: 0.1057\n",
      "Epoch: 9/20... Training loss: 0.1042\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1033\n",
      "Epoch: 9/20... Training loss: 0.1034\n",
      "Epoch: 9/20... Training loss: 0.1056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20... Training loss: 0.1034\n",
      "Epoch: 9/20... Training loss: 0.1061\n",
      "Epoch: 9/20... Training loss: 0.1039\n",
      "Epoch: 9/20... Training loss: 0.1049\n",
      "Epoch: 9/20... Training loss: 0.1031\n",
      "Epoch: 9/20... Training loss: 0.1061\n",
      "Epoch: 9/20... Training loss: 0.1034\n",
      "Epoch: 9/20... Training loss: 0.1044\n",
      "Epoch: 9/20... Training loss: 0.1027\n",
      "Epoch: 9/20... Training loss: 0.1067\n",
      "Epoch: 9/20... Training loss: 0.1014\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1024\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1045\n",
      "Epoch: 9/20... Training loss: 0.1046\n",
      "Epoch: 9/20... Training loss: 0.1046\n",
      "Epoch: 9/20... Training loss: 0.1025\n",
      "Epoch: 9/20... Training loss: 0.1007\n",
      "Epoch: 9/20... Training loss: 0.1031\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1060\n",
      "Epoch: 9/20... Training loss: 0.1046\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1038\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1006\n",
      "Epoch: 9/20... Training loss: 0.1022\n",
      "Epoch: 9/20... Training loss: 0.1080\n",
      "Epoch: 9/20... Training loss: 0.1014\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1036\n",
      "Epoch: 9/20... Training loss: 0.1023\n",
      "Epoch: 9/20... Training loss: 0.1028\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1016\n",
      "Epoch: 9/20... Training loss: 0.1040\n",
      "Epoch: 9/20... Training loss: 0.1058\n",
      "Epoch: 9/20... Training loss: 0.1023\n",
      "Epoch: 9/20... Training loss: 0.1027\n",
      "Epoch: 9/20... Training loss: 0.1024\n",
      "Epoch: 9/20... Training loss: 0.1069\n",
      "Epoch: 9/20... Training loss: 0.1072\n",
      "Epoch: 9/20... Training loss: 0.1028\n",
      "Epoch: 9/20... Training loss: 0.0974\n",
      "Epoch: 9/20... Training loss: 0.1050\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.0992\n",
      "Epoch: 9/20... Training loss: 0.1026\n",
      "Epoch: 9/20... Training loss: 0.1004\n",
      "Epoch: 9/20... Training loss: 0.1057\n",
      "Epoch: 9/20... Training loss: 0.1049\n",
      "Epoch: 9/20... Training loss: 0.1052\n",
      "Epoch: 9/20... Training loss: 0.1037\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1018\n",
      "Epoch: 9/20... Training loss: 0.1046\n",
      "Epoch: 9/20... Training loss: 0.1026\n",
      "Epoch: 9/20... Training loss: 0.0992\n",
      "Epoch: 9/20... Training loss: 0.1039\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1072\n",
      "Epoch: 9/20... Training loss: 0.1025\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1017\n",
      "Epoch: 9/20... Training loss: 0.1072\n",
      "Epoch: 9/20... Training loss: 0.1034\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1026\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1020\n",
      "Epoch: 9/20... Training loss: 0.0987\n",
      "Epoch: 9/20... Training loss: 0.1028\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1000\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1043\n",
      "Epoch: 9/20... Training loss: 0.1042\n",
      "Epoch: 9/20... Training loss: 0.1034\n",
      "Epoch: 9/20... Training loss: 0.1061\n",
      "Epoch: 9/20... Training loss: 0.1054\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1014\n",
      "Epoch: 9/20... Training loss: 0.1024\n",
      "Epoch: 9/20... Training loss: 0.1049\n",
      "Epoch: 9/20... Training loss: 0.1031\n",
      "Epoch: 9/20... Training loss: 0.0994\n",
      "Epoch: 9/20... Training loss: 0.1033\n",
      "Epoch: 9/20... Training loss: 0.1048\n",
      "Epoch: 9/20... Training loss: 0.1065\n",
      "Epoch: 9/20... Training loss: 0.1035\n",
      "Epoch: 9/20... Training loss: 0.1041\n",
      "Epoch: 9/20... Training loss: 0.0968\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1051\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1031\n",
      "Epoch: 9/20... Training loss: 0.1051\n",
      "Epoch: 9/20... Training loss: 0.1048\n",
      "Epoch: 9/20... Training loss: 0.1028\n",
      "Epoch: 9/20... Training loss: 0.1014\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1041\n",
      "Epoch: 9/20... Training loss: 0.1058\n",
      "Epoch: 9/20... Training loss: 0.1053\n",
      "Epoch: 9/20... Training loss: 0.1042\n",
      "Epoch: 9/20... Training loss: 0.1044\n",
      "Epoch: 9/20... Training loss: 0.1036\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1039\n",
      "Epoch: 9/20... Training loss: 0.1029\n",
      "Epoch: 9/20... Training loss: 0.0993\n",
      "Epoch: 9/20... Training loss: 0.1084\n",
      "Epoch: 9/20... Training loss: 0.1026\n",
      "Epoch: 9/20... Training loss: 0.0981\n",
      "Epoch: 9/20... Training loss: 0.1052\n",
      "Epoch: 9/20... Training loss: 0.1046\n",
      "Epoch: 9/20... Training loss: 0.0991\n",
      "Epoch: 9/20... Training loss: 0.1070\n",
      "Epoch: 9/20... Training loss: 0.1009\n",
      "Epoch: 9/20... Training loss: 0.1052\n",
      "Epoch: 9/20... Training loss: 0.1071\n",
      "Epoch: 9/20... Training loss: 0.1038\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1013\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1031\n",
      "Epoch: 9/20... Training loss: 0.1025\n",
      "Epoch: 9/20... Training loss: 0.1035\n",
      "Epoch: 9/20... Training loss: 0.1008\n",
      "Epoch: 9/20... Training loss: 0.1037\n",
      "Epoch: 9/20... Training loss: 0.1034\n",
      "Epoch: 9/20... Training loss: 0.0993\n",
      "Epoch: 9/20... Training loss: 0.1028\n",
      "Epoch: 9/20... Training loss: 0.1044\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1046\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1013\n",
      "Epoch: 9/20... Training loss: 0.1016\n",
      "Epoch: 9/20... Training loss: 0.1072\n",
      "Epoch: 9/20... Training loss: 0.1035\n",
      "Epoch: 9/20... Training loss: 0.1039\n",
      "Epoch: 9/20... Training loss: 0.1039\n",
      "Epoch: 9/20... Training loss: 0.1015\n",
      "Epoch: 9/20... Training loss: 0.1072\n",
      "Epoch: 9/20... Training loss: 0.1003\n",
      "Epoch: 9/20... Training loss: 0.1038\n",
      "Epoch: 9/20... Training loss: 0.0992\n",
      "Epoch: 9/20... Training loss: 0.1040\n",
      "Epoch: 9/20... Training loss: 0.1110\n",
      "Epoch: 9/20... Training loss: 0.1025\n",
      "Epoch: 9/20... Training loss: 0.1069\n",
      "Epoch: 9/20... Training loss: 0.1050\n",
      "Epoch: 9/20... Training loss: 0.1045\n",
      "Epoch: 9/20... Training loss: 0.1038\n",
      "Epoch: 9/20... Training loss: 0.1040\n",
      "Epoch: 9/20... Training loss: 0.1023\n",
      "Epoch: 9/20... Training loss: 0.1065\n",
      "Epoch: 9/20... Training loss: 0.0982\n",
      "Epoch: 9/20... Training loss: 0.1032\n",
      "Epoch: 9/20... Training loss: 0.1024\n",
      "Epoch: 9/20... Training loss: 0.1035\n",
      "Epoch: 9/20... Training loss: 0.1057\n",
      "Epoch: 9/20... Training loss: 0.1041\n",
      "Epoch: 9/20... Training loss: 0.1025\n",
      "Epoch: 9/20... Training loss: 0.1038\n",
      "Epoch: 9/20... Training loss: 0.0968\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1019\n",
      "Epoch: 9/20... Training loss: 0.1025\n",
      "Epoch: 9/20... Training loss: 0.1052\n",
      "Epoch: 9/20... Training loss: 0.1013\n",
      "Epoch: 9/20... Training loss: 0.1031\n",
      "Epoch: 9/20... Training loss: 0.1034\n",
      "Epoch: 9/20... Training loss: 0.1019\n",
      "Epoch: 9/20... Training loss: 0.0999\n",
      "Epoch: 9/20... Training loss: 0.1032\n",
      "Epoch: 9/20... Training loss: 0.1039\n",
      "Epoch: 9/20... Training loss: 0.1012\n",
      "Epoch: 9/20... Training loss: 0.1045\n",
      "Epoch: 9/20... Training loss: 0.1019\n",
      "Epoch: 9/20... Training loss: 0.1003\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1042\n",
      "Epoch: 9/20... Training loss: 0.1036\n",
      "Epoch: 9/20... Training loss: 0.1042\n",
      "Epoch: 9/20... Training loss: 0.1033\n",
      "Epoch: 9/20... Training loss: 0.0995\n",
      "Epoch: 9/20... Training loss: 0.1049\n",
      "Epoch: 9/20... Training loss: 0.0994\n",
      "Epoch: 9/20... Training loss: 0.1036\n",
      "Epoch: 9/20... Training loss: 0.1055\n",
      "Epoch: 9/20... Training loss: 0.1033\n",
      "Epoch: 9/20... Training loss: 0.1032\n",
      "Epoch: 9/20... Training loss: 0.1043\n",
      "Epoch: 9/20... Training loss: 0.1015\n",
      "Epoch: 9/20... Training loss: 0.1000\n",
      "Epoch: 9/20... Training loss: 0.1026\n",
      "Epoch: 9/20... Training loss: 0.1021\n",
      "Epoch: 9/20... Training loss: 0.1004\n",
      "Epoch: 9/20... Training loss: 0.1046\n",
      "Epoch: 9/20... Training loss: 0.1070\n",
      "Epoch: 9/20... Training loss: 0.1027\n",
      "Epoch: 9/20... Training loss: 0.1042\n",
      "Epoch: 9/20... Training loss: 0.1026\n",
      "Epoch: 9/20... Training loss: 0.1004\n",
      "Epoch: 9/20... Training loss: 0.1029\n",
      "Epoch: 9/20... Training loss: 0.1025\n",
      "Epoch: 9/20... Training loss: 0.1015\n",
      "Epoch: 9/20... Training loss: 0.1050\n",
      "Epoch: 9/20... Training loss: 0.1052\n",
      "Epoch: 9/20... Training loss: 0.1040\n",
      "Epoch: 9/20... Training loss: 0.1008\n",
      "Epoch: 9/20... Training loss: 0.1041\n",
      "Epoch: 9/20... Training loss: 0.1018\n",
      "Epoch: 9/20... Training loss: 0.1057\n",
      "Epoch: 9/20... Training loss: 0.1036\n",
      "Epoch: 9/20... Training loss: 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20... Training loss: 0.1060\n",
      "Epoch: 9/20... Training loss: 0.1040\n",
      "Epoch: 9/20... Training loss: 0.1031\n",
      "Epoch: 9/20... Training loss: 0.0995\n",
      "Epoch: 9/20... Training loss: 0.1034\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1027\n",
      "Epoch: 9/20... Training loss: 0.1038\n",
      "Epoch: 9/20... Training loss: 0.1067\n",
      "Epoch: 9/20... Training loss: 0.1019\n",
      "Epoch: 9/20... Training loss: 0.1038\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1045\n",
      "Epoch: 9/20... Training loss: 0.1014\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1032\n",
      "Epoch: 9/20... Training loss: 0.1012\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1044\n",
      "Epoch: 9/20... Training loss: 0.1044\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1036\n",
      "Epoch: 9/20... Training loss: 0.0998\n",
      "Epoch: 9/20... Training loss: 0.1030\n",
      "Epoch: 9/20... Training loss: 0.1014\n",
      "Epoch: 9/20... Training loss: 0.1065\n",
      "Epoch: 9/20... Training loss: 0.1016\n",
      "Epoch: 9/20... Training loss: 0.1033\n",
      "Epoch: 10/20... Training loss: 0.1034\n",
      "Epoch: 10/20... Training loss: 0.1037\n",
      "Epoch: 10/20... Training loss: 0.1046\n",
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1029\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.0995\n",
      "Epoch: 10/20... Training loss: 0.1015\n",
      "Epoch: 10/20... Training loss: 0.1035\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1014\n",
      "Epoch: 10/20... Training loss: 0.1000\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1114\n",
      "Epoch: 10/20... Training loss: 0.1036\n",
      "Epoch: 10/20... Training loss: 0.1024\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1021\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1024\n",
      "Epoch: 10/20... Training loss: 0.1036\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.1032\n",
      "Epoch: 10/20... Training loss: 0.1010\n",
      "Epoch: 10/20... Training loss: 0.1013\n",
      "Epoch: 10/20... Training loss: 0.1029\n",
      "Epoch: 10/20... Training loss: 0.1036\n",
      "Epoch: 10/20... Training loss: 0.1001\n",
      "Epoch: 10/20... Training loss: 0.1029\n",
      "Epoch: 10/20... Training loss: 0.1026\n",
      "Epoch: 10/20... Training loss: 0.1013\n",
      "Epoch: 10/20... Training loss: 0.1037\n",
      "Epoch: 10/20... Training loss: 0.1013\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1064\n",
      "Epoch: 10/20... Training loss: 0.1030\n",
      "Epoch: 10/20... Training loss: 0.0992\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1070\n",
      "Epoch: 10/20... Training loss: 0.1004\n",
      "Epoch: 10/20... Training loss: 0.1018\n",
      "Epoch: 10/20... Training loss: 0.1020\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.1022\n",
      "Epoch: 10/20... Training loss: 0.1014\n",
      "Epoch: 10/20... Training loss: 0.1035\n",
      "Epoch: 10/20... Training loss: 0.1019\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.0989\n",
      "Epoch: 10/20... Training loss: 0.0998\n",
      "Epoch: 10/20... Training loss: 0.1002\n",
      "Epoch: 10/20... Training loss: 0.1030\n",
      "Epoch: 10/20... Training loss: 0.1012\n",
      "Epoch: 10/20... Training loss: 0.1023\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1024\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1037\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.0997\n",
      "Epoch: 10/20... Training loss: 0.1046\n",
      "Epoch: 10/20... Training loss: 0.1006\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1021\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1021\n",
      "Epoch: 10/20... Training loss: 0.0999\n",
      "Epoch: 10/20... Training loss: 0.1033\n",
      "Epoch: 10/20... Training loss: 0.1032\n",
      "Epoch: 10/20... Training loss: 0.0976\n",
      "Epoch: 10/20... Training loss: 0.1006\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.0999\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1036\n",
      "Epoch: 10/20... Training loss: 0.1052\n",
      "Epoch: 10/20... Training loss: 0.1006\n",
      "Epoch: 10/20... Training loss: 0.1052\n",
      "Epoch: 10/20... Training loss: 0.1057\n",
      "Epoch: 10/20... Training loss: 0.1018\n",
      "Epoch: 10/20... Training loss: 0.1029\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1079\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1003\n",
      "Epoch: 10/20... Training loss: 0.0999\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.1030\n",
      "Epoch: 10/20... Training loss: 0.1036\n",
      "Epoch: 10/20... Training loss: 0.1018\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1002\n",
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1020\n",
      "Epoch: 10/20... Training loss: 0.1023\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.1065\n",
      "Epoch: 10/20... Training loss: 0.0999\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.1036\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.0995\n",
      "Epoch: 10/20... Training loss: 0.1045\n",
      "Epoch: 10/20... Training loss: 0.1022\n",
      "Epoch: 10/20... Training loss: 0.1005\n",
      "Epoch: 10/20... Training loss: 0.1058\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.0994\n",
      "Epoch: 10/20... Training loss: 0.0998\n",
      "Epoch: 10/20... Training loss: 0.1009\n",
      "Epoch: 10/20... Training loss: 0.1046\n",
      "Epoch: 10/20... Training loss: 0.1031\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1014\n",
      "Epoch: 10/20... Training loss: 0.1052\n",
      "Epoch: 10/20... Training loss: 0.1060\n",
      "Epoch: 10/20... Training loss: 0.1023\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.1053\n",
      "Epoch: 10/20... Training loss: 0.1029\n",
      "Epoch: 10/20... Training loss: 0.1067\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1019\n",
      "Epoch: 10/20... Training loss: 0.1032\n",
      "Epoch: 10/20... Training loss: 0.1024\n",
      "Epoch: 10/20... Training loss: 0.0997\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.1022\n",
      "Epoch: 10/20... Training loss: 0.1008\n",
      "Epoch: 10/20... Training loss: 0.0999\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1032\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.1035\n",
      "Epoch: 10/20... Training loss: 0.1011\n",
      "Epoch: 10/20... Training loss: 0.0988\n",
      "Epoch: 10/20... Training loss: 0.1023\n",
      "Epoch: 10/20... Training loss: 0.1012\n",
      "Epoch: 10/20... Training loss: 0.1021\n",
      "Epoch: 10/20... Training loss: 0.1065\n",
      "Epoch: 10/20... Training loss: 0.1037\n",
      "Epoch: 10/20... Training loss: 0.1017\n",
      "Epoch: 10/20... Training loss: 0.1014\n",
      "Epoch: 10/20... Training loss: 0.1038\n",
      "Epoch: 10/20... Training loss: 0.1023\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.0992\n",
      "Epoch: 10/20... Training loss: 0.1019\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.0998\n",
      "Epoch: 10/20... Training loss: 0.1036\n",
      "Epoch: 10/20... Training loss: 0.1030\n",
      "Epoch: 10/20... Training loss: 0.1024\n",
      "Epoch: 10/20... Training loss: 0.1010\n",
      "Epoch: 10/20... Training loss: 0.1027\n",
      "Epoch: 10/20... Training loss: 0.1014\n",
      "Epoch: 10/20... Training loss: 0.1037\n",
      "Epoch: 10/20... Training loss: 0.1005\n",
      "Epoch: 10/20... Training loss: 0.1057\n",
      "Epoch: 10/20... Training loss: 0.0986\n",
      "Epoch: 10/20... Training loss: 0.1016\n",
      "Epoch: 10/20... Training loss: 0.0976\n",
      "Epoch: 10/20... Training loss: 0.1027\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.1018\n",
      "Epoch: 10/20... Training loss: 0.1045\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.1057\n",
      "Epoch: 10/20... Training loss: 0.1030\n",
      "Epoch: 10/20... Training loss: 0.1019\n",
      "Epoch: 10/20... Training loss: 0.1012\n",
      "Epoch: 10/20... Training loss: 0.1038\n",
      "Epoch: 10/20... Training loss: 0.1020\n",
      "Epoch: 10/20... Training loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20... Training loss: 0.1035\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1005\n",
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1034\n",
      "Epoch: 10/20... Training loss: 0.1046\n",
      "Epoch: 10/20... Training loss: 0.1019\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.1067\n",
      "Epoch: 10/20... Training loss: 0.1020\n",
      "Epoch: 10/20... Training loss: 0.1031\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1009\n",
      "Epoch: 10/20... Training loss: 0.1045\n",
      "Epoch: 10/20... Training loss: 0.0999\n",
      "Epoch: 10/20... Training loss: 0.1018\n",
      "Epoch: 10/20... Training loss: 0.1076\n",
      "Epoch: 10/20... Training loss: 0.1003\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1009\n",
      "Epoch: 10/20... Training loss: 0.1039\n",
      "Epoch: 10/20... Training loss: 0.1001\n",
      "Epoch: 10/20... Training loss: 0.1064\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.1034\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1022\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.1013\n",
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1057\n",
      "Epoch: 10/20... Training loss: 0.1029\n",
      "Epoch: 10/20... Training loss: 0.1012\n",
      "Epoch: 10/20... Training loss: 0.1001\n",
      "Epoch: 10/20... Training loss: 0.0987\n",
      "Epoch: 10/20... Training loss: 0.1075\n",
      "Epoch: 10/20... Training loss: 0.1067\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1015\n",
      "Epoch: 10/20... Training loss: 0.0989\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.1033\n",
      "Epoch: 10/20... Training loss: 0.1009\n",
      "Epoch: 10/20... Training loss: 0.0992\n",
      "Epoch: 10/20... Training loss: 0.1014\n",
      "Epoch: 10/20... Training loss: 0.1017\n",
      "Epoch: 10/20... Training loss: 0.1034\n",
      "Epoch: 10/20... Training loss: 0.1055\n",
      "Epoch: 10/20... Training loss: 0.1011\n",
      "Epoch: 10/20... Training loss: 0.1052\n",
      "Epoch: 10/20... Training loss: 0.1000\n",
      "Epoch: 10/20... Training loss: 0.1004\n",
      "Epoch: 10/20... Training loss: 0.1010\n",
      "Epoch: 10/20... Training loss: 0.1001\n",
      "Epoch: 10/20... Training loss: 0.0995\n",
      "Epoch: 10/20... Training loss: 0.1004\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1019\n",
      "Epoch: 10/20... Training loss: 0.1012\n",
      "Epoch: 10/20... Training loss: 0.1025\n",
      "Epoch: 10/20... Training loss: 0.1037\n",
      "Epoch: 10/20... Training loss: 0.0995\n",
      "Epoch: 10/20... Training loss: 0.1019\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.0993\n",
      "Epoch: 10/20... Training loss: 0.1035\n",
      "Epoch: 10/20... Training loss: 0.1045\n",
      "Epoch: 10/20... Training loss: 0.0979\n",
      "Epoch: 10/20... Training loss: 0.1025\n",
      "Epoch: 10/20... Training loss: 0.1012\n",
      "Epoch: 10/20... Training loss: 0.1006\n",
      "Epoch: 10/20... Training loss: 0.1018\n",
      "Epoch: 10/20... Training loss: 0.1075\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1027\n",
      "Epoch: 10/20... Training loss: 0.1013\n",
      "Epoch: 10/20... Training loss: 0.1021\n",
      "Epoch: 10/20... Training loss: 0.1031\n",
      "Epoch: 10/20... Training loss: 0.1026\n",
      "Epoch: 10/20... Training loss: 0.0990\n",
      "Epoch: 10/20... Training loss: 0.1010\n",
      "Epoch: 10/20... Training loss: 0.1026\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1020\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1026\n",
      "Epoch: 10/20... Training loss: 0.0986\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1014\n",
      "Epoch: 10/20... Training loss: 0.0956\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.0999\n",
      "Epoch: 10/20... Training loss: 0.1073\n",
      "Epoch: 10/20... Training loss: 0.1016\n",
      "Epoch: 10/20... Training loss: 0.1030\n",
      "Epoch: 10/20... Training loss: 0.1012\n",
      "Epoch: 10/20... Training loss: 0.0978\n",
      "Epoch: 10/20... Training loss: 0.1017\n",
      "Epoch: 10/20... Training loss: 0.1030\n",
      "Epoch: 10/20... Training loss: 0.1038\n",
      "Epoch: 10/20... Training loss: 0.1012\n",
      "Epoch: 10/20... Training loss: 0.1018\n",
      "Epoch: 10/20... Training loss: 0.1045\n",
      "Epoch: 10/20... Training loss: 0.0998\n",
      "Epoch: 10/20... Training loss: 0.1026\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1010\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1028\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.0993\n",
      "Epoch: 11/20... Training loss: 0.1038\n",
      "Epoch: 11/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1014\n",
      "Epoch: 11/20... Training loss: 0.1011\n",
      "Epoch: 11/20... Training loss: 0.1025\n",
      "Epoch: 11/20... Training loss: 0.1025\n",
      "Epoch: 11/20... Training loss: 0.1024\n",
      "Epoch: 11/20... Training loss: 0.1005\n",
      "Epoch: 11/20... Training loss: 0.1001\n",
      "Epoch: 11/20... Training loss: 0.1035\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1028\n",
      "Epoch: 11/20... Training loss: 0.1022\n",
      "Epoch: 11/20... Training loss: 0.1055\n",
      "Epoch: 11/20... Training loss: 0.0998\n",
      "Epoch: 11/20... Training loss: 0.1052\n",
      "Epoch: 11/20... Training loss: 0.1023\n",
      "Epoch: 11/20... Training loss: 0.0997\n",
      "Epoch: 11/20... Training loss: 0.0969\n",
      "Epoch: 11/20... Training loss: 0.1021\n",
      "Epoch: 11/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1035\n",
      "Epoch: 11/20... Training loss: 0.1028\n",
      "Epoch: 11/20... Training loss: 0.0973\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1010\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.0993\n",
      "Epoch: 11/20... Training loss: 0.1020\n",
      "Epoch: 11/20... Training loss: 0.1005\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.0981\n",
      "Epoch: 11/20... Training loss: 0.1022\n",
      "Epoch: 11/20... Training loss: 0.1045\n",
      "Epoch: 11/20... Training loss: 0.1004\n",
      "Epoch: 11/20... Training loss: 0.0981\n",
      "Epoch: 11/20... Training loss: 0.0998\n",
      "Epoch: 11/20... Training loss: 0.1038\n",
      "Epoch: 11/20... Training loss: 0.0994\n",
      "Epoch: 11/20... Training loss: 0.1018\n",
      "Epoch: 11/20... Training loss: 0.1018\n",
      "Epoch: 11/20... Training loss: 0.1028\n",
      "Epoch: 11/20... Training loss: 0.1045\n",
      "Epoch: 11/20... Training loss: 0.0979\n",
      "Epoch: 11/20... Training loss: 0.1007\n",
      "Epoch: 11/20... Training loss: 0.1031\n",
      "Epoch: 11/20... Training loss: 0.1025\n",
      "Epoch: 11/20... Training loss: 0.1027\n",
      "Epoch: 11/20... Training loss: 0.0987\n",
      "Epoch: 11/20... Training loss: 0.1028\n",
      "Epoch: 11/20... Training loss: 0.1042\n",
      "Epoch: 11/20... Training loss: 0.1014\n",
      "Epoch: 11/20... Training loss: 0.1000\n",
      "Epoch: 11/20... Training loss: 0.1015\n",
      "Epoch: 11/20... Training loss: 0.0964\n",
      "Epoch: 11/20... Training loss: 0.1000\n",
      "Epoch: 11/20... Training loss: 0.1021\n",
      "Epoch: 11/20... Training loss: 0.0997\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1002\n",
      "Epoch: 11/20... Training loss: 0.1007\n",
      "Epoch: 11/20... Training loss: 0.1033\n",
      "Epoch: 11/20... Training loss: 0.1048\n",
      "Epoch: 11/20... Training loss: 0.0989\n",
      "Epoch: 11/20... Training loss: 0.1025\n",
      "Epoch: 11/20... Training loss: 0.1033\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1025\n",
      "Epoch: 11/20... Training loss: 0.1068\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1020\n",
      "Epoch: 11/20... Training loss: 0.1033\n",
      "Epoch: 11/20... Training loss: 0.0988\n",
      "Epoch: 11/20... Training loss: 0.1020\n",
      "Epoch: 11/20... Training loss: 0.1024\n",
      "Epoch: 11/20... Training loss: 0.1000\n",
      "Epoch: 11/20... Training loss: 0.0996\n",
      "Epoch: 11/20... Training loss: 0.1011\n",
      "Epoch: 11/20... Training loss: 0.1028\n",
      "Epoch: 11/20... Training loss: 0.1024\n",
      "Epoch: 11/20... Training loss: 0.1043\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1013\n",
      "Epoch: 11/20... Training loss: 0.1011\n",
      "Epoch: 11/20... Training loss: 0.1028\n",
      "Epoch: 11/20... Training loss: 0.1038\n",
      "Epoch: 11/20... Training loss: 0.0948\n",
      "Epoch: 11/20... Training loss: 0.1008\n",
      "Epoch: 11/20... Training loss: 0.1018\n",
      "Epoch: 11/20... Training loss: 0.1025\n",
      "Epoch: 11/20... Training loss: 0.0995\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.1005\n",
      "Epoch: 11/20... Training loss: 0.1008\n",
      "Epoch: 11/20... Training loss: 0.1027\n",
      "Epoch: 11/20... Training loss: 0.1014\n",
      "Epoch: 11/20... Training loss: 0.1044\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/20... Training loss: 0.1017\n",
      "Epoch: 11/20... Training loss: 0.1009\n",
      "Epoch: 11/20... Training loss: 0.1020\n",
      "Epoch: 11/20... Training loss: 0.1011\n",
      "Epoch: 11/20... Training loss: 0.0984\n",
      "Epoch: 11/20... Training loss: 0.1005\n",
      "Epoch: 11/20... Training loss: 0.1011\n",
      "Epoch: 11/20... Training loss: 0.1036\n",
      "Epoch: 11/20... Training loss: 0.1045\n",
      "Epoch: 11/20... Training loss: 0.1010\n",
      "Epoch: 11/20... Training loss: 0.1036\n",
      "Epoch: 11/20... Training loss: 0.1001\n",
      "Epoch: 11/20... Training loss: 0.1017\n",
      "Epoch: 11/20... Training loss: 0.1038\n",
      "Epoch: 11/20... Training loss: 0.1010\n",
      "Epoch: 11/20... Training loss: 0.1000\n",
      "Epoch: 11/20... Training loss: 0.0998\n",
      "Epoch: 11/20... Training loss: 0.1021\n",
      "Epoch: 11/20... Training loss: 0.1018\n",
      "Epoch: 11/20... Training loss: 0.1009\n",
      "Epoch: 11/20... Training loss: 0.1052\n",
      "Epoch: 11/20... Training loss: 0.1021\n",
      "Epoch: 11/20... Training loss: 0.0985\n",
      "Epoch: 11/20... Training loss: 0.1003\n",
      "Epoch: 11/20... Training loss: 0.1017\n",
      "Epoch: 11/20... Training loss: 0.1022\n",
      "Epoch: 11/20... Training loss: 0.1027\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1055\n",
      "Epoch: 11/20... Training loss: 0.1017\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1014\n",
      "Epoch: 11/20... Training loss: 0.1033\n",
      "Epoch: 11/20... Training loss: 0.1000\n",
      "Epoch: 11/20... Training loss: 0.1012\n",
      "Epoch: 11/20... Training loss: 0.0998\n",
      "Epoch: 11/20... Training loss: 0.0991\n",
      "Epoch: 11/20... Training loss: 0.1014\n",
      "Epoch: 11/20... Training loss: 0.1052\n",
      "Epoch: 11/20... Training loss: 0.1014\n",
      "Epoch: 11/20... Training loss: 0.0989\n",
      "Epoch: 11/20... Training loss: 0.1025\n",
      "Epoch: 11/20... Training loss: 0.0986\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.0980\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1008\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1005\n",
      "Epoch: 11/20... Training loss: 0.0991\n",
      "Epoch: 11/20... Training loss: 0.1015\n",
      "Epoch: 11/20... Training loss: 0.1020\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1011\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1021\n",
      "Epoch: 11/20... Training loss: 0.0989\n",
      "Epoch: 11/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.0987\n",
      "Epoch: 11/20... Training loss: 0.1020\n",
      "Epoch: 11/20... Training loss: 0.1033\n",
      "Epoch: 11/20... Training loss: 0.0988\n",
      "Epoch: 11/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1000\n",
      "Epoch: 11/20... Training loss: 0.1020\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.0986\n",
      "Epoch: 11/20... Training loss: 0.0995\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.1008\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.1016\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1001\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1017\n",
      "Epoch: 11/20... Training loss: 0.1007\n",
      "Epoch: 11/20... Training loss: 0.1019\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.0983\n",
      "Epoch: 11/20... Training loss: 0.1023\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.0986\n",
      "Epoch: 11/20... Training loss: 0.1018\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.1006\n",
      "Epoch: 11/20... Training loss: 0.1010\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1007\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.1048\n",
      "Epoch: 11/20... Training loss: 0.1021\n",
      "Epoch: 11/20... Training loss: 0.1043\n",
      "Epoch: 11/20... Training loss: 0.1035\n",
      "Epoch: 11/20... Training loss: 0.0964\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.1017\n",
      "Epoch: 11/20... Training loss: 0.1020\n",
      "Epoch: 11/20... Training loss: 0.1044\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1027\n",
      "Epoch: 11/20... Training loss: 0.0981\n",
      "Epoch: 11/20... Training loss: 0.0988\n",
      "Epoch: 11/20... Training loss: 0.0981\n",
      "Epoch: 11/20... Training loss: 0.1008\n",
      "Epoch: 11/20... Training loss: 0.1010\n",
      "Epoch: 11/20... Training loss: 0.0980\n",
      "Epoch: 11/20... Training loss: 0.1014\n",
      "Epoch: 11/20... Training loss: 0.1016\n",
      "Epoch: 11/20... Training loss: 0.1045\n",
      "Epoch: 11/20... Training loss: 0.1018\n",
      "Epoch: 11/20... Training loss: 0.1019\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1018\n",
      "Epoch: 11/20... Training loss: 0.1010\n",
      "Epoch: 11/20... Training loss: 0.1031\n",
      "Epoch: 11/20... Training loss: 0.1005\n",
      "Epoch: 11/20... Training loss: 0.1009\n",
      "Epoch: 11/20... Training loss: 0.0989\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1022\n",
      "Epoch: 11/20... Training loss: 0.1031\n",
      "Epoch: 11/20... Training loss: 0.1036\n",
      "Epoch: 11/20... Training loss: 0.0977\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1017\n",
      "Epoch: 11/20... Training loss: 0.1022\n",
      "Epoch: 11/20... Training loss: 0.1005\n",
      "Epoch: 11/20... Training loss: 0.0999\n",
      "Epoch: 11/20... Training loss: 0.0975\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.1011\n",
      "Epoch: 11/20... Training loss: 0.1010\n",
      "Epoch: 11/20... Training loss: 0.1008\n",
      "Epoch: 11/20... Training loss: 0.0998\n",
      "Epoch: 11/20... Training loss: 0.1003\n",
      "Epoch: 11/20... Training loss: 0.1022\n",
      "Epoch: 11/20... Training loss: 0.0980\n",
      "Epoch: 11/20... Training loss: 0.1028\n",
      "Epoch: 11/20... Training loss: 0.1019\n",
      "Epoch: 11/20... Training loss: 0.0959\n",
      "Epoch: 11/20... Training loss: 0.0993\n",
      "Epoch: 11/20... Training loss: 0.1015\n",
      "Epoch: 11/20... Training loss: 0.1017\n",
      "Epoch: 11/20... Training loss: 0.0976\n",
      "Epoch: 11/20... Training loss: 0.1024\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1023\n",
      "Epoch: 11/20... Training loss: 0.1002\n",
      "Epoch: 11/20... Training loss: 0.1022\n",
      "Epoch: 11/20... Training loss: 0.0988\n",
      "Epoch: 11/20... Training loss: 0.0982\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.0994\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1000\n",
      "Epoch: 11/20... Training loss: 0.0998\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1016\n",
      "Epoch: 11/20... Training loss: 0.1025\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.0990\n",
      "Epoch: 11/20... Training loss: 0.1001\n",
      "Epoch: 11/20... Training loss: 0.0992\n",
      "Epoch: 11/20... Training loss: 0.1016\n",
      "Epoch: 11/20... Training loss: 0.1015\n",
      "Epoch: 11/20... Training loss: 0.1021\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.0969\n",
      "Epoch: 11/20... Training loss: 0.1016\n",
      "Epoch: 11/20... Training loss: 0.0982\n",
      "Epoch: 11/20... Training loss: 0.1021\n",
      "Epoch: 11/20... Training loss: 0.0994\n",
      "Epoch: 11/20... Training loss: 0.1038\n",
      "Epoch: 11/20... Training loss: 0.1015\n",
      "Epoch: 12/20... Training loss: 0.1007\n",
      "Epoch: 12/20... Training loss: 0.1011\n",
      "Epoch: 12/20... Training loss: 0.1033\n",
      "Epoch: 12/20... Training loss: 0.1009\n",
      "Epoch: 12/20... Training loss: 0.0995\n",
      "Epoch: 12/20... Training loss: 0.0980\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1001\n",
      "Epoch: 12/20... Training loss: 0.0989\n",
      "Epoch: 12/20... Training loss: 0.1028\n",
      "Epoch: 12/20... Training loss: 0.1029\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1001\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.0988\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.1001\n",
      "Epoch: 12/20... Training loss: 0.1016\n",
      "Epoch: 12/20... Training loss: 0.0992\n",
      "Epoch: 12/20... Training loss: 0.0994\n",
      "Epoch: 12/20... Training loss: 0.0984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.0949\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.0995\n",
      "Epoch: 12/20... Training loss: 0.1014\n",
      "Epoch: 12/20... Training loss: 0.1009\n",
      "Epoch: 12/20... Training loss: 0.1029\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1017\n",
      "Epoch: 12/20... Training loss: 0.1007\n",
      "Epoch: 12/20... Training loss: 0.1005\n",
      "Epoch: 12/20... Training loss: 0.1010\n",
      "Epoch: 12/20... Training loss: 0.1035\n",
      "Epoch: 12/20... Training loss: 0.1010\n",
      "Epoch: 12/20... Training loss: 0.1015\n",
      "Epoch: 12/20... Training loss: 0.0977\n",
      "Epoch: 12/20... Training loss: 0.0996\n",
      "Epoch: 12/20... Training loss: 0.1009\n",
      "Epoch: 12/20... Training loss: 0.1004\n",
      "Epoch: 12/20... Training loss: 0.0962\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.0992\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.0962\n",
      "Epoch: 12/20... Training loss: 0.0998\n",
      "Epoch: 12/20... Training loss: 0.0998\n",
      "Epoch: 12/20... Training loss: 0.0988\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.0987\n",
      "Epoch: 12/20... Training loss: 0.1004\n",
      "Epoch: 12/20... Training loss: 0.1016\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.0948\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.0993\n",
      "Epoch: 12/20... Training loss: 0.1004\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.0998\n",
      "Epoch: 12/20... Training loss: 0.1002\n",
      "Epoch: 12/20... Training loss: 0.1073\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1011\n",
      "Epoch: 12/20... Training loss: 0.1000\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.0998\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1034\n",
      "Epoch: 12/20... Training loss: 0.0986\n",
      "Epoch: 12/20... Training loss: 0.1008\n",
      "Epoch: 12/20... Training loss: 0.1000\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.1014\n",
      "Epoch: 12/20... Training loss: 0.1015\n",
      "Epoch: 12/20... Training loss: 0.1019\n",
      "Epoch: 12/20... Training loss: 0.0992\n",
      "Epoch: 12/20... Training loss: 0.1002\n",
      "Epoch: 12/20... Training loss: 0.0997\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.1011\n",
      "Epoch: 12/20... Training loss: 0.1005\n",
      "Epoch: 12/20... Training loss: 0.0961\n",
      "Epoch: 12/20... Training loss: 0.0967\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.1003\n",
      "Epoch: 12/20... Training loss: 0.1027\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.0996\n",
      "Epoch: 12/20... Training loss: 0.1027\n",
      "Epoch: 12/20... Training loss: 0.0985\n",
      "Epoch: 12/20... Training loss: 0.1018\n",
      "Epoch: 12/20... Training loss: 0.0999\n",
      "Epoch: 12/20... Training loss: 0.0998\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.0981\n",
      "Epoch: 12/20... Training loss: 0.0961\n",
      "Epoch: 12/20... Training loss: 0.1007\n",
      "Epoch: 12/20... Training loss: 0.1029\n",
      "Epoch: 12/20... Training loss: 0.1015\n",
      "Epoch: 12/20... Training loss: 0.1001\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.0990\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.1003\n",
      "Epoch: 12/20... Training loss: 0.1001\n",
      "Epoch: 12/20... Training loss: 0.1011\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1016\n",
      "Epoch: 12/20... Training loss: 0.1004\n",
      "Epoch: 12/20... Training loss: 0.0997\n",
      "Epoch: 12/20... Training loss: 0.0980\n",
      "Epoch: 12/20... Training loss: 0.0988\n",
      "Epoch: 12/20... Training loss: 0.1033\n",
      "Epoch: 12/20... Training loss: 0.0990\n",
      "Epoch: 12/20... Training loss: 0.1006\n",
      "Epoch: 12/20... Training loss: 0.1034\n",
      "Epoch: 12/20... Training loss: 0.0985\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1009\n",
      "Epoch: 12/20... Training loss: 0.1007\n",
      "Epoch: 12/20... Training loss: 0.0973\n",
      "Epoch: 12/20... Training loss: 0.0994\n",
      "Epoch: 12/20... Training loss: 0.0996\n",
      "Epoch: 12/20... Training loss: 0.0990\n",
      "Epoch: 12/20... Training loss: 0.1019\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.0972\n",
      "Epoch: 12/20... Training loss: 0.0976\n",
      "Epoch: 12/20... Training loss: 0.0990\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.0991\n",
      "Epoch: 12/20... Training loss: 0.0992\n",
      "Epoch: 12/20... Training loss: 0.1001\n",
      "Epoch: 12/20... Training loss: 0.0995\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.0992\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1005\n",
      "Epoch: 12/20... Training loss: 0.1028\n",
      "Epoch: 12/20... Training loss: 0.1017\n",
      "Epoch: 12/20... Training loss: 0.1009\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1008\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.0991\n",
      "Epoch: 12/20... Training loss: 0.0994\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.1019\n",
      "Epoch: 12/20... Training loss: 0.1002\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1005\n",
      "Epoch: 12/20... Training loss: 0.0970\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1033\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.1029\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.0970\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.0974\n",
      "Epoch: 12/20... Training loss: 0.1019\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.1006\n",
      "Epoch: 12/20... Training loss: 0.0997\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.0992\n",
      "Epoch: 12/20... Training loss: 0.1014\n",
      "Epoch: 12/20... Training loss: 0.1005\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.0984\n",
      "Epoch: 12/20... Training loss: 0.1002\n",
      "Epoch: 12/20... Training loss: 0.0994\n",
      "Epoch: 12/20... Training loss: 0.1022\n",
      "Epoch: 12/20... Training loss: 0.0962\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.0983\n",
      "Epoch: 12/20... Training loss: 0.1019\n",
      "Epoch: 12/20... Training loss: 0.1032\n",
      "Epoch: 12/20... Training loss: 0.1014\n",
      "Epoch: 12/20... Training loss: 0.1022\n",
      "Epoch: 12/20... Training loss: 0.0999\n",
      "Epoch: 12/20... Training loss: 0.0969\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1017\n",
      "Epoch: 12/20... Training loss: 0.1005\n",
      "Epoch: 12/20... Training loss: 0.1015\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.0963\n",
      "Epoch: 12/20... Training loss: 0.1028\n",
      "Epoch: 12/20... Training loss: 0.1016\n",
      "Epoch: 12/20... Training loss: 0.0987\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1019\n",
      "Epoch: 12/20... Training loss: 0.1027\n",
      "Epoch: 12/20... Training loss: 0.1015\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1011\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1004\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.0995\n",
      "Epoch: 12/20... Training loss: 0.1016\n",
      "Epoch: 12/20... Training loss: 0.0981\n",
      "Epoch: 12/20... Training loss: 0.0990\n",
      "Epoch: 12/20... Training loss: 0.1008\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1006\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1018\n",
      "Epoch: 12/20... Training loss: 0.1010\n",
      "Epoch: 12/20... Training loss: 0.0995\n",
      "Epoch: 12/20... Training loss: 0.0999\n",
      "Epoch: 12/20... Training loss: 0.1014\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.0979\n",
      "Epoch: 12/20... Training loss: 0.0998\n",
      "Epoch: 12/20... Training loss: 0.1002\n",
      "Epoch: 12/20... Training loss: 0.0993\n",
      "Epoch: 12/20... Training loss: 0.1015\n",
      "Epoch: 12/20... Training loss: 0.0998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20... Training loss: 0.0986\n",
      "Epoch: 12/20... Training loss: 0.1017\n",
      "Epoch: 12/20... Training loss: 0.1007\n",
      "Epoch: 12/20... Training loss: 0.0996\n",
      "Epoch: 12/20... Training loss: 0.0992\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.1014\n",
      "Epoch: 12/20... Training loss: 0.1002\n",
      "Epoch: 12/20... Training loss: 0.0998\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1022\n",
      "Epoch: 12/20... Training loss: 0.1001\n",
      "Epoch: 12/20... Training loss: 0.1035\n",
      "Epoch: 12/20... Training loss: 0.1001\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.0979\n",
      "Epoch: 12/20... Training loss: 0.0984\n",
      "Epoch: 12/20... Training loss: 0.0999\n",
      "Epoch: 12/20... Training loss: 0.1011\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1014\n",
      "Epoch: 12/20... Training loss: 0.1001\n",
      "Epoch: 12/20... Training loss: 0.1007\n",
      "Epoch: 12/20... Training loss: 0.1000\n",
      "Epoch: 12/20... Training loss: 0.1002\n",
      "Epoch: 12/20... Training loss: 0.1027\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1032\n",
      "Epoch: 12/20... Training loss: 0.1010\n",
      "Epoch: 12/20... Training loss: 0.0984\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.1017\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1000\n",
      "Epoch: 12/20... Training loss: 0.0989\n",
      "Epoch: 12/20... Training loss: 0.1049\n",
      "Epoch: 12/20... Training loss: 0.1008\n",
      "Epoch: 12/20... Training loss: 0.0976\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.0975\n",
      "Epoch: 12/20... Training loss: 0.1035\n",
      "Epoch: 12/20... Training loss: 0.1005\n",
      "Epoch: 12/20... Training loss: 0.0993\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.1000\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.0967\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.0993\n",
      "Epoch: 12/20... Training loss: 0.0997\n",
      "Epoch: 12/20... Training loss: 0.0993\n",
      "Epoch: 12/20... Training loss: 0.1000\n",
      "Epoch: 12/20... Training loss: 0.1003\n",
      "Epoch: 12/20... Training loss: 0.1011\n",
      "Epoch: 12/20... Training loss: 0.0989\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1008\n",
      "Epoch: 13/20... Training loss: 0.0995\n",
      "Epoch: 13/20... Training loss: 0.1009\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1000\n",
      "Epoch: 13/20... Training loss: 0.0995\n",
      "Epoch: 13/20... Training loss: 0.1019\n",
      "Epoch: 13/20... Training loss: 0.1002\n",
      "Epoch: 13/20... Training loss: 0.0997\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1001\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1009\n",
      "Epoch: 13/20... Training loss: 0.1004\n",
      "Epoch: 13/20... Training loss: 0.1006\n",
      "Epoch: 13/20... Training loss: 0.1015\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.0994\n",
      "Epoch: 13/20... Training loss: 0.1016\n",
      "Epoch: 13/20... Training loss: 0.1005\n",
      "Epoch: 13/20... Training loss: 0.0999\n",
      "Epoch: 13/20... Training loss: 0.1012\n",
      "Epoch: 13/20... Training loss: 0.1001\n",
      "Epoch: 13/20... Training loss: 0.1060\n",
      "Epoch: 13/20... Training loss: 0.0997\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.0969\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.0992\n",
      "Epoch: 13/20... Training loss: 0.1002\n",
      "Epoch: 13/20... Training loss: 0.0998\n",
      "Epoch: 13/20... Training loss: 0.0988\n",
      "Epoch: 13/20... Training loss: 0.0972\n",
      "Epoch: 13/20... Training loss: 0.1006\n",
      "Epoch: 13/20... Training loss: 0.1030\n",
      "Epoch: 13/20... Training loss: 0.1007\n",
      "Epoch: 13/20... Training loss: 0.1012\n",
      "Epoch: 13/20... Training loss: 0.0982\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.0994\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.1008\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.1022\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.0998\n",
      "Epoch: 13/20... Training loss: 0.0985\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1003\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.0981\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.0972\n",
      "Epoch: 13/20... Training loss: 0.0994\n",
      "Epoch: 13/20... Training loss: 0.1000\n",
      "Epoch: 13/20... Training loss: 0.0972\n",
      "Epoch: 13/20... Training loss: 0.0987\n",
      "Epoch: 13/20... Training loss: 0.0989\n",
      "Epoch: 13/20... Training loss: 0.0981\n",
      "Epoch: 13/20... Training loss: 0.0984\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.0996\n",
      "Epoch: 13/20... Training loss: 0.1011\n",
      "Epoch: 13/20... Training loss: 0.0981\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.0987\n",
      "Epoch: 13/20... Training loss: 0.0995\n",
      "Epoch: 13/20... Training loss: 0.1022\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1010\n",
      "Epoch: 13/20... Training loss: 0.0981\n",
      "Epoch: 13/20... Training loss: 0.1012\n",
      "Epoch: 13/20... Training loss: 0.0992\n",
      "Epoch: 13/20... Training loss: 0.0966\n",
      "Epoch: 13/20... Training loss: 0.1008\n",
      "Epoch: 13/20... Training loss: 0.0999\n",
      "Epoch: 13/20... Training loss: 0.0998\n",
      "Epoch: 13/20... Training loss: 0.1004\n",
      "Epoch: 13/20... Training loss: 0.1008\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1042\n",
      "Epoch: 13/20... Training loss: 0.0965\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.0981\n",
      "Epoch: 13/20... Training loss: 0.0999\n",
      "Epoch: 13/20... Training loss: 0.1015\n",
      "Epoch: 13/20... Training loss: 0.0986\n",
      "Epoch: 13/20... Training loss: 0.0986\n",
      "Epoch: 13/20... Training loss: 0.0980\n",
      "Epoch: 13/20... Training loss: 0.0986\n",
      "Epoch: 13/20... Training loss: 0.1016\n",
      "Epoch: 13/20... Training loss: 0.1007\n",
      "Epoch: 13/20... Training loss: 0.0983\n",
      "Epoch: 13/20... Training loss: 0.0991\n",
      "Epoch: 13/20... Training loss: 0.0989\n",
      "Epoch: 13/20... Training loss: 0.1008\n",
      "Epoch: 13/20... Training loss: 0.0987\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1022\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.0960\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.0966\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.1005\n",
      "Epoch: 13/20... Training loss: 0.0995\n",
      "Epoch: 13/20... Training loss: 0.1008\n",
      "Epoch: 13/20... Training loss: 0.0978\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1006\n",
      "Epoch: 13/20... Training loss: 0.0992\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1002\n",
      "Epoch: 13/20... Training loss: 0.1006\n",
      "Epoch: 13/20... Training loss: 0.0998\n",
      "Epoch: 13/20... Training loss: 0.0970\n",
      "Epoch: 13/20... Training loss: 0.0992\n",
      "Epoch: 13/20... Training loss: 0.1012\n",
      "Epoch: 13/20... Training loss: 0.0984\n",
      "Epoch: 13/20... Training loss: 0.1088\n",
      "Epoch: 13/20... Training loss: 0.0990\n",
      "Epoch: 13/20... Training loss: 0.1012\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.0996\n",
      "Epoch: 13/20... Training loss: 0.1002\n",
      "Epoch: 13/20... Training loss: 0.1008\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1002\n",
      "Epoch: 13/20... Training loss: 0.1011\n",
      "Epoch: 13/20... Training loss: 0.1009\n",
      "Epoch: 13/20... Training loss: 0.1010\n",
      "Epoch: 13/20... Training loss: 0.0968\n",
      "Epoch: 13/20... Training loss: 0.0998\n",
      "Epoch: 13/20... Training loss: 0.0990\n",
      "Epoch: 13/20... Training loss: 0.0996\n",
      "Epoch: 13/20... Training loss: 0.0953\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.0973\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.0998\n",
      "Epoch: 13/20... Training loss: 0.0973\n",
      "Epoch: 13/20... Training loss: 0.0971\n",
      "Epoch: 13/20... Training loss: 0.0991\n",
      "Epoch: 13/20... Training loss: 0.1020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20... Training loss: 0.0989\n",
      "Epoch: 13/20... Training loss: 0.0988\n",
      "Epoch: 13/20... Training loss: 0.1003\n",
      "Epoch: 13/20... Training loss: 0.0985\n",
      "Epoch: 13/20... Training loss: 0.0992\n",
      "Epoch: 13/20... Training loss: 0.1015\n",
      "Epoch: 13/20... Training loss: 0.0982\n",
      "Epoch: 13/20... Training loss: 0.0982\n",
      "Epoch: 13/20... Training loss: 0.0997\n",
      "Epoch: 13/20... Training loss: 0.1003\n",
      "Epoch: 13/20... Training loss: 0.0983\n",
      "Epoch: 13/20... Training loss: 0.1001\n",
      "Epoch: 13/20... Training loss: 0.1004\n",
      "Epoch: 13/20... Training loss: 0.0968\n",
      "Epoch: 13/20... Training loss: 0.0982\n",
      "Epoch: 13/20... Training loss: 0.0975\n",
      "Epoch: 13/20... Training loss: 0.0983\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.0999\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1012\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1011\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1042\n",
      "Epoch: 13/20... Training loss: 0.1003\n",
      "Epoch: 13/20... Training loss: 0.1004\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1007\n",
      "Epoch: 13/20... Training loss: 0.0976\n",
      "Epoch: 13/20... Training loss: 0.0996\n",
      "Epoch: 13/20... Training loss: 0.0992\n",
      "Epoch: 13/20... Training loss: 0.0975\n",
      "Epoch: 13/20... Training loss: 0.0987\n",
      "Epoch: 13/20... Training loss: 0.1000\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.0976\n",
      "Epoch: 13/20... Training loss: 0.0984\n",
      "Epoch: 13/20... Training loss: 0.0998\n",
      "Epoch: 13/20... Training loss: 0.0999\n",
      "Epoch: 13/20... Training loss: 0.0939\n",
      "Epoch: 13/20... Training loss: 0.0983\n",
      "Epoch: 13/20... Training loss: 0.0995\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.0996\n",
      "Epoch: 13/20... Training loss: 0.0989\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.0960\n",
      "Epoch: 13/20... Training loss: 0.0984\n",
      "Epoch: 13/20... Training loss: 0.0979\n",
      "Epoch: 13/20... Training loss: 0.0989\n",
      "Epoch: 13/20... Training loss: 0.1015\n",
      "Epoch: 13/20... Training loss: 0.1008\n",
      "Epoch: 13/20... Training loss: 0.1003\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1046\n",
      "Epoch: 13/20... Training loss: 0.0974\n",
      "Epoch: 13/20... Training loss: 0.0987\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.0969\n",
      "Epoch: 13/20... Training loss: 0.0981\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.0973\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.0978\n",
      "Epoch: 13/20... Training loss: 0.1006\n",
      "Epoch: 13/20... Training loss: 0.1009\n",
      "Epoch: 13/20... Training loss: 0.1005\n",
      "Epoch: 13/20... Training loss: 0.0996\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1018\n",
      "Epoch: 13/20... Training loss: 0.1009\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.0991\n",
      "Epoch: 13/20... Training loss: 0.0997\n",
      "Epoch: 13/20... Training loss: 0.0985\n",
      "Epoch: 13/20... Training loss: 0.0997\n",
      "Epoch: 13/20... Training loss: 0.0995\n",
      "Epoch: 13/20... Training loss: 0.0986\n",
      "Epoch: 13/20... Training loss: 0.1003\n",
      "Epoch: 13/20... Training loss: 0.0980\n",
      "Epoch: 13/20... Training loss: 0.1003\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.0971\n",
      "Epoch: 13/20... Training loss: 0.0995\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1008\n",
      "Epoch: 13/20... Training loss: 0.0960\n",
      "Epoch: 13/20... Training loss: 0.0986\n",
      "Epoch: 13/20... Training loss: 0.0994\n",
      "Epoch: 13/20... Training loss: 0.1019\n",
      "Epoch: 13/20... Training loss: 0.0991\n",
      "Epoch: 13/20... Training loss: 0.1063\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.0977\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.0994\n",
      "Epoch: 13/20... Training loss: 0.1000\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.0950\n",
      "Epoch: 13/20... Training loss: 0.0978\n",
      "Epoch: 13/20... Training loss: 0.0986\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.0945\n",
      "Epoch: 13/20... Training loss: 0.0999\n",
      "Epoch: 13/20... Training loss: 0.0978\n",
      "Epoch: 13/20... Training loss: 0.0991\n",
      "Epoch: 13/20... Training loss: 0.0991\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.0980\n",
      "Epoch: 13/20... Training loss: 0.0991\n",
      "Epoch: 13/20... Training loss: 0.0996\n",
      "Epoch: 13/20... Training loss: 0.0960\n",
      "Epoch: 13/20... Training loss: 0.0984\n",
      "Epoch: 13/20... Training loss: 0.0984\n",
      "Epoch: 13/20... Training loss: 0.0992\n",
      "Epoch: 13/20... Training loss: 0.0998\n",
      "Epoch: 13/20... Training loss: 0.1019\n",
      "Epoch: 13/20... Training loss: 0.1000\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.0983\n",
      "Epoch: 13/20... Training loss: 0.0924\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.0983\n",
      "Epoch: 13/20... Training loss: 0.0999\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.0988\n",
      "Epoch: 13/20... Training loss: 0.0989\n",
      "Epoch: 13/20... Training loss: 0.1009\n",
      "Epoch: 13/20... Training loss: 0.0989\n",
      "Epoch: 13/20... Training loss: 0.1011\n",
      "Epoch: 13/20... Training loss: 0.0995\n",
      "Epoch: 13/20... Training loss: 0.0958\n",
      "Epoch: 13/20... Training loss: 0.0990\n",
      "Epoch: 13/20... Training loss: 0.1003\n",
      "Epoch: 13/20... Training loss: 0.1005\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.1000\n",
      "Epoch: 13/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.0980\n",
      "Epoch: 14/20... Training loss: 0.0965\n",
      "Epoch: 14/20... Training loss: 0.1020\n",
      "Epoch: 14/20... Training loss: 0.0998\n",
      "Epoch: 14/20... Training loss: 0.0977\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.0996\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.0984\n",
      "Epoch: 14/20... Training loss: 0.0974\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.0982\n",
      "Epoch: 14/20... Training loss: 0.0980\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.0979\n",
      "Epoch: 14/20... Training loss: 0.0985\n",
      "Epoch: 14/20... Training loss: 0.1012\n",
      "Epoch: 14/20... Training loss: 0.0997\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.0961\n",
      "Epoch: 14/20... Training loss: 0.0997\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.0986\n",
      "Epoch: 14/20... Training loss: 0.0991\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.0964\n",
      "Epoch: 14/20... Training loss: 0.1012\n",
      "Epoch: 14/20... Training loss: 0.0958\n",
      "Epoch: 14/20... Training loss: 0.1005\n",
      "Epoch: 14/20... Training loss: 0.0981\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.0993\n",
      "Epoch: 14/20... Training loss: 0.1025\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.0977\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.1006\n",
      "Epoch: 14/20... Training loss: 0.0983\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.1000\n",
      "Epoch: 14/20... Training loss: 0.0990\n",
      "Epoch: 14/20... Training loss: 0.0990\n",
      "Epoch: 14/20... Training loss: 0.0980\n",
      "Epoch: 14/20... Training loss: 0.0987\n",
      "Epoch: 14/20... Training loss: 0.0993\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.0981\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.0984\n",
      "Epoch: 14/20... Training loss: 0.1000\n",
      "Epoch: 14/20... Training loss: 0.0996\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1002\n",
      "Epoch: 14/20... Training loss: 0.1005\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.1027\n",
      "Epoch: 14/20... Training loss: 0.1013\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.0971\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.1000\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.0987\n",
      "Epoch: 14/20... Training loss: 0.0977\n",
      "Epoch: 14/20... Training loss: 0.0993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20... Training loss: 0.0992\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 14/20... Training loss: 0.0985\n",
      "Epoch: 14/20... Training loss: 0.0985\n",
      "Epoch: 14/20... Training loss: 0.0983\n",
      "Epoch: 14/20... Training loss: 0.0982\n",
      "Epoch: 14/20... Training loss: 0.0987\n",
      "Epoch: 14/20... Training loss: 0.0997\n",
      "Epoch: 14/20... Training loss: 0.0997\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.0992\n",
      "Epoch: 14/20... Training loss: 0.0974\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 14/20... Training loss: 0.0963\n",
      "Epoch: 14/20... Training loss: 0.0977\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 14/20... Training loss: 0.0983\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.0984\n",
      "Epoch: 14/20... Training loss: 0.0998\n",
      "Epoch: 14/20... Training loss: 0.0988\n",
      "Epoch: 14/20... Training loss: 0.1012\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.0976\n",
      "Epoch: 14/20... Training loss: 0.1015\n",
      "Epoch: 14/20... Training loss: 0.0971\n",
      "Epoch: 14/20... Training loss: 0.0997\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.0981\n",
      "Epoch: 14/20... Training loss: 0.0938\n",
      "Epoch: 14/20... Training loss: 0.0990\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.0998\n",
      "Epoch: 14/20... Training loss: 0.0986\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.0979\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.0992\n",
      "Epoch: 14/20... Training loss: 0.1009\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.0971\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.0969\n",
      "Epoch: 14/20... Training loss: 0.0966\n",
      "Epoch: 14/20... Training loss: 0.0973\n",
      "Epoch: 14/20... Training loss: 0.0976\n",
      "Epoch: 14/20... Training loss: 0.0992\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.1009\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1012\n",
      "Epoch: 14/20... Training loss: 0.1002\n",
      "Epoch: 14/20... Training loss: 0.0989\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.0935\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.0984\n",
      "Epoch: 14/20... Training loss: 0.0961\n",
      "Epoch: 14/20... Training loss: 0.0960\n",
      "Epoch: 14/20... Training loss: 0.0984\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.1001\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1006\n",
      "Epoch: 14/20... Training loss: 0.0949\n",
      "Epoch: 14/20... Training loss: 0.0987\n",
      "Epoch: 14/20... Training loss: 0.0962\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.1006\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.0991\n",
      "Epoch: 14/20... Training loss: 0.0966\n",
      "Epoch: 14/20... Training loss: 0.0963\n",
      "Epoch: 14/20... Training loss: 0.1001\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.0979\n",
      "Epoch: 14/20... Training loss: 0.0980\n",
      "Epoch: 14/20... Training loss: 0.0993\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.0934\n",
      "Epoch: 14/20... Training loss: 0.0969\n",
      "Epoch: 14/20... Training loss: 0.1012\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.0996\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.0998\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.0962\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.1002\n",
      "Epoch: 14/20... Training loss: 0.0935\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 14/20... Training loss: 0.1012\n",
      "Epoch: 14/20... Training loss: 0.0987\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.0977\n",
      "Epoch: 14/20... Training loss: 0.0985\n",
      "Epoch: 14/20... Training loss: 0.0985\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.0992\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.0972\n",
      "Epoch: 14/20... Training loss: 0.0951\n",
      "Epoch: 14/20... Training loss: 0.1009\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.0984\n",
      "Epoch: 14/20... Training loss: 0.0972\n",
      "Epoch: 14/20... Training loss: 0.1002\n",
      "Epoch: 14/20... Training loss: 0.0988\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.0987\n",
      "Epoch: 14/20... Training loss: 0.0991\n",
      "Epoch: 14/20... Training loss: 0.0993\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.0987\n",
      "Epoch: 14/20... Training loss: 0.0929\n",
      "Epoch: 14/20... Training loss: 0.1001\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.1043\n",
      "Epoch: 14/20... Training loss: 0.1000\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.0967\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.0974\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.0963\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.0949\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.0969\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 14/20... Training loss: 0.0983\n",
      "Epoch: 14/20... Training loss: 0.0975\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.0986\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1020\n",
      "Epoch: 14/20... Training loss: 0.1002\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.0959\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.0967\n",
      "Epoch: 14/20... Training loss: 0.0985\n",
      "Epoch: 14/20... Training loss: 0.0987\n",
      "Epoch: 14/20... Training loss: 0.0997\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.1013\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 14/20... Training loss: 0.1005\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.0973\n",
      "Epoch: 14/20... Training loss: 0.0962\n",
      "Epoch: 14/20... Training loss: 0.1020\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.0974\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.1039\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1027\n",
      "Epoch: 14/20... Training loss: 0.1015\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 14/20... Training loss: 0.0965\n",
      "Epoch: 14/20... Training loss: 0.0958\n",
      "Epoch: 14/20... Training loss: 0.0961\n",
      "Epoch: 14/20... Training loss: 0.1012\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.0990\n",
      "Epoch: 14/20... Training loss: 0.0997\n",
      "Epoch: 14/20... Training loss: 0.0977\n",
      "Epoch: 14/20... Training loss: 0.0970\n",
      "Epoch: 14/20... Training loss: 0.0967\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.1055\n",
      "Epoch: 14/20... Training loss: 0.1000\n",
      "Epoch: 14/20... Training loss: 0.0968\n",
      "Epoch: 14/20... Training loss: 0.0979\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.0955\n",
      "Epoch: 14/20... Training loss: 0.0973\n",
      "Epoch: 14/20... Training loss: 0.0978\n",
      "Epoch: 14/20... Training loss: 0.0996\n",
      "Epoch: 14/20... Training loss: 0.0993\n",
      "Epoch: 14/20... Training loss: 0.0975\n",
      "Epoch: 14/20... Training loss: 0.0965\n",
      "Epoch: 14/20... Training loss: 0.0984\n",
      "Epoch: 14/20... Training loss: 0.0964\n",
      "Epoch: 14/20... Training loss: 0.0989\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.0986\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.0990\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.0986\n",
      "Epoch: 14/20... Training loss: 0.1000\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.0965\n",
      "Epoch: 14/20... Training loss: 0.0966\n",
      "Epoch: 14/20... Training loss: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20... Training loss: 0.0998\n",
      "Epoch: 14/20... Training loss: 0.0978\n",
      "Epoch: 14/20... Training loss: 0.1000\n",
      "Epoch: 14/20... Training loss: 0.0923\n",
      "Epoch: 14/20... Training loss: 0.0947\n",
      "Epoch: 14/20... Training loss: 0.1002\n",
      "Epoch: 14/20... Training loss: 0.0951\n",
      "Epoch: 14/20... Training loss: 0.1013\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.0981\n",
      "Epoch: 15/20... Training loss: 0.0980\n",
      "Epoch: 15/20... Training loss: 0.0948\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.0952\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.0972\n",
      "Epoch: 15/20... Training loss: 0.0972\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1004\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.0958\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.0995\n",
      "Epoch: 15/20... Training loss: 0.0979\n",
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.0990\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.0985\n",
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.0978\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.0985\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.0990\n",
      "Epoch: 15/20... Training loss: 0.1049\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.0960\n",
      "Epoch: 15/20... Training loss: 0.0941\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.0958\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.0990\n",
      "Epoch: 15/20... Training loss: 0.0976\n",
      "Epoch: 15/20... Training loss: 0.1034\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1056\n",
      "Epoch: 15/20... Training loss: 0.0982\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.0961\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0945\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.0979\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.0963\n",
      "Epoch: 15/20... Training loss: 0.0978\n",
      "Epoch: 15/20... Training loss: 0.0982\n",
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.0977\n",
      "Epoch: 15/20... Training loss: 0.0982\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.0987\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.0984\n",
      "Epoch: 15/20... Training loss: 0.0984\n",
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.1000\n",
      "Epoch: 15/20... Training loss: 0.0984\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.0960\n",
      "Epoch: 15/20... Training loss: 0.0971\n",
      "Epoch: 15/20... Training loss: 0.0979\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.0975\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.0976\n",
      "Epoch: 15/20... Training loss: 0.0981\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.0973\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.0978\n",
      "Epoch: 15/20... Training loss: 0.0955\n",
      "Epoch: 15/20... Training loss: 0.0977\n",
      "Epoch: 15/20... Training loss: 0.0958\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1000\n",
      "Epoch: 15/20... Training loss: 0.0981\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.0949\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.0956\n",
      "Epoch: 15/20... Training loss: 0.1006\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1004\n",
      "Epoch: 15/20... Training loss: 0.0950\n",
      "Epoch: 15/20... Training loss: 0.0959\n",
      "Epoch: 15/20... Training loss: 0.1006\n",
      "Epoch: 15/20... Training loss: 0.0979\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1000\n",
      "Epoch: 15/20... Training loss: 0.0965\n",
      "Epoch: 15/20... Training loss: 0.0985\n",
      "Epoch: 15/20... Training loss: 0.0971\n",
      "Epoch: 15/20... Training loss: 0.0979\n",
      "Epoch: 15/20... Training loss: 0.0985\n",
      "Epoch: 15/20... Training loss: 0.0984\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.0972\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.0996\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.0973\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.0988\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.0974\n",
      "Epoch: 15/20... Training loss: 0.0979\n",
      "Epoch: 15/20... Training loss: 0.0981\n",
      "Epoch: 15/20... Training loss: 0.0988\n",
      "Epoch: 15/20... Training loss: 0.0966\n",
      "Epoch: 15/20... Training loss: 0.0987\n",
      "Epoch: 15/20... Training loss: 0.1006\n",
      "Epoch: 15/20... Training loss: 0.0982\n",
      "Epoch: 15/20... Training loss: 0.1000\n",
      "Epoch: 15/20... Training loss: 0.0995\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.0984\n",
      "Epoch: 15/20... Training loss: 0.1013\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.0951\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.0994\n",
      "Epoch: 15/20... Training loss: 0.0974\n",
      "Epoch: 15/20... Training loss: 0.0990\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.0981\n",
      "Epoch: 15/20... Training loss: 0.1006\n",
      "Epoch: 15/20... Training loss: 0.0949\n",
      "Epoch: 15/20... Training loss: 0.0972\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.0969\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.0969\n",
      "Epoch: 15/20... Training loss: 0.0977\n",
      "Epoch: 15/20... Training loss: 0.0964\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.0962\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.0987\n",
      "Epoch: 15/20... Training loss: 0.0964\n",
      "Epoch: 15/20... Training loss: 0.0955\n",
      "Epoch: 15/20... Training loss: 0.0980\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.0974\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.0954\n",
      "Epoch: 15/20... Training loss: 0.0995\n",
      "Epoch: 15/20... Training loss: 0.0983\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.0948\n",
      "Epoch: 15/20... Training loss: 0.0959\n",
      "Epoch: 15/20... Training loss: 0.0972\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.0992\n",
      "Epoch: 15/20... Training loss: 0.0976\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.0969\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.0978\n",
      "Epoch: 15/20... Training loss: 0.0992\n",
      "Epoch: 15/20... Training loss: 0.0960\n",
      "Epoch: 15/20... Training loss: 0.0979\n",
      "Epoch: 15/20... Training loss: 0.0974\n",
      "Epoch: 15/20... Training loss: 0.0972\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.0997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/20... Training loss: 0.0949\n",
      "Epoch: 15/20... Training loss: 0.0956\n",
      "Epoch: 15/20... Training loss: 0.0990\n",
      "Epoch: 15/20... Training loss: 0.1006\n",
      "Epoch: 15/20... Training loss: 0.0974\n",
      "Epoch: 15/20... Training loss: 0.0972\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.0984\n",
      "Epoch: 15/20... Training loss: 0.0982\n",
      "Epoch: 15/20... Training loss: 0.0982\n",
      "Epoch: 15/20... Training loss: 0.1000\n",
      "Epoch: 15/20... Training loss: 0.0978\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.0979\n",
      "Epoch: 15/20... Training loss: 0.0994\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.0934\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.0968\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.0971\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0982\n",
      "Epoch: 15/20... Training loss: 0.0980\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.0992\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.0953\n",
      "Epoch: 15/20... Training loss: 0.0993\n",
      "Epoch: 15/20... Training loss: 0.0992\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.0981\n",
      "Epoch: 15/20... Training loss: 0.0949\n",
      "Epoch: 15/20... Training loss: 0.0990\n",
      "Epoch: 15/20... Training loss: 0.0991\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.0957\n",
      "Epoch: 15/20... Training loss: 0.0973\n",
      "Epoch: 15/20... Training loss: 0.0979\n",
      "Epoch: 15/20... Training loss: 0.0939\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.0980\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.0972\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.0970\n",
      "Epoch: 15/20... Training loss: 0.0977\n",
      "Epoch: 15/20... Training loss: 0.0978\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.0982\n",
      "Epoch: 15/20... Training loss: 0.0961\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.0978\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.0974\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.0981\n",
      "Epoch: 15/20... Training loss: 0.1013\n",
      "Epoch: 15/20... Training loss: 0.0981\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.0996\n",
      "Epoch: 15/20... Training loss: 0.0933\n",
      "Epoch: 15/20... Training loss: 0.0996\n",
      "Epoch: 15/20... Training loss: 0.0978\n",
      "Epoch: 15/20... Training loss: 0.0952\n",
      "Epoch: 15/20... Training loss: 0.0985\n",
      "Epoch: 15/20... Training loss: 0.0973\n",
      "Epoch: 15/20... Training loss: 0.0981\n",
      "Epoch: 15/20... Training loss: 0.0956\n",
      "Epoch: 15/20... Training loss: 0.0974\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.0961\n",
      "Epoch: 15/20... Training loss: 0.0968\n",
      "Epoch: 15/20... Training loss: 0.0957\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.0991\n",
      "Epoch: 15/20... Training loss: 0.0972\n",
      "Epoch: 15/20... Training loss: 0.0992\n",
      "Epoch: 15/20... Training loss: 0.0982\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.0957\n",
      "Epoch: 15/20... Training loss: 0.0971\n",
      "Epoch: 16/20... Training loss: 0.0993\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.0955\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.0925\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.0992\n",
      "Epoch: 16/20... Training loss: 0.0973\n",
      "Epoch: 16/20... Training loss: 0.0992\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.0987\n",
      "Epoch: 16/20... Training loss: 0.0975\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.0992\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.0965\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.0983\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.0966\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.0983\n",
      "Epoch: 16/20... Training loss: 0.0968\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.0950\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.0973\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.0967\n",
      "Epoch: 16/20... Training loss: 0.0957\n",
      "Epoch: 16/20... Training loss: 0.0975\n",
      "Epoch: 16/20... Training loss: 0.0972\n",
      "Epoch: 16/20... Training loss: 0.0938\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.0957\n",
      "Epoch: 16/20... Training loss: 0.1019\n",
      "Epoch: 16/20... Training loss: 0.0942\n",
      "Epoch: 16/20... Training loss: 0.0950\n",
      "Epoch: 16/20... Training loss: 0.0973\n",
      "Epoch: 16/20... Training loss: 0.0987\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.0928\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.1008\n",
      "Epoch: 16/20... Training loss: 0.0978\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.0976\n",
      "Epoch: 16/20... Training loss: 0.0976\n",
      "Epoch: 16/20... Training loss: 0.0973\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.0987\n",
      "Epoch: 16/20... Training loss: 0.0964\n",
      "Epoch: 16/20... Training loss: 0.0981\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.1001\n",
      "Epoch: 16/20... Training loss: 0.0969\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.0961\n",
      "Epoch: 16/20... Training loss: 0.0974\n",
      "Epoch: 16/20... Training loss: 0.0969\n",
      "Epoch: 16/20... Training loss: 0.0919\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.1019\n",
      "Epoch: 16/20... Training loss: 0.0965\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.0953\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.0975\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.0969\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.0969\n",
      "Epoch: 16/20... Training loss: 0.0984\n",
      "Epoch: 16/20... Training loss: 0.0974\n",
      "Epoch: 16/20... Training loss: 0.0958\n",
      "Epoch: 16/20... Training loss: 0.0996\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.0986\n",
      "Epoch: 16/20... Training loss: 0.0970\n",
      "Epoch: 16/20... Training loss: 0.0968\n",
      "Epoch: 16/20... Training loss: 0.0961\n",
      "Epoch: 16/20... Training loss: 0.0964\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.0965\n",
      "Epoch: 16/20... Training loss: 0.0968\n",
      "Epoch: 16/20... Training loss: 0.0935\n",
      "Epoch: 16/20... Training loss: 0.0971\n",
      "Epoch: 16/20... Training loss: 0.0964\n",
      "Epoch: 16/20... Training loss: 0.0983\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.0954\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.0965\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1017\n",
      "Epoch: 16/20... Training loss: 0.0992\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.0965\n",
      "Epoch: 16/20... Training loss: 0.0958\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.0980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/20... Training loss: 0.1001\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.0992\n",
      "Epoch: 16/20... Training loss: 0.1001\n",
      "Epoch: 16/20... Training loss: 0.0958\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.1004\n",
      "Epoch: 16/20... Training loss: 0.0972\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.0992\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.0948\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.0964\n",
      "Epoch: 16/20... Training loss: 0.1004\n",
      "Epoch: 16/20... Training loss: 0.0969\n",
      "Epoch: 16/20... Training loss: 0.0972\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.0978\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1017\n",
      "Epoch: 16/20... Training loss: 0.1001\n",
      "Epoch: 16/20... Training loss: 0.0992\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.0993\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.0965\n",
      "Epoch: 16/20... Training loss: 0.0973\n",
      "Epoch: 16/20... Training loss: 0.0996\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 16/20... Training loss: 0.0944\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.0972\n",
      "Epoch: 16/20... Training loss: 0.0985\n",
      "Epoch: 16/20... Training loss: 0.0957\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.0986\n",
      "Epoch: 16/20... Training loss: 0.0965\n",
      "Epoch: 16/20... Training loss: 0.0968\n",
      "Epoch: 16/20... Training loss: 0.0974\n",
      "Epoch: 16/20... Training loss: 0.0951\n",
      "Epoch: 16/20... Training loss: 0.0957\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.0985\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.0966\n",
      "Epoch: 16/20... Training loss: 0.0970\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.0920\n",
      "Epoch: 16/20... Training loss: 0.0991\n",
      "Epoch: 16/20... Training loss: 0.0971\n",
      "Epoch: 16/20... Training loss: 0.0952\n",
      "Epoch: 16/20... Training loss: 0.0964\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.0971\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.0968\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.0968\n",
      "Epoch: 16/20... Training loss: 0.0974\n",
      "Epoch: 16/20... Training loss: 0.1001\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.0969\n",
      "Epoch: 16/20... Training loss: 0.1009\n",
      "Epoch: 16/20... Training loss: 0.0967\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 16/20... Training loss: 0.0969\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.0972\n",
      "Epoch: 16/20... Training loss: 0.0976\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.0960\n",
      "Epoch: 16/20... Training loss: 0.0960\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.0967\n",
      "Epoch: 16/20... Training loss: 0.0985\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.0993\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.1011\n",
      "Epoch: 16/20... Training loss: 0.1001\n",
      "Epoch: 16/20... Training loss: 0.0972\n",
      "Epoch: 16/20... Training loss: 0.0954\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.0978\n",
      "Epoch: 16/20... Training loss: 0.0966\n",
      "Epoch: 16/20... Training loss: 0.0975\n",
      "Epoch: 16/20... Training loss: 0.1017\n",
      "Epoch: 16/20... Training loss: 0.0992\n",
      "Epoch: 16/20... Training loss: 0.0974\n",
      "Epoch: 16/20... Training loss: 0.0984\n",
      "Epoch: 16/20... Training loss: 0.0978\n",
      "Epoch: 16/20... Training loss: 0.0978\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.1009\n",
      "Epoch: 16/20... Training loss: 0.0961\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.0939\n",
      "Epoch: 16/20... Training loss: 0.0973\n",
      "Epoch: 16/20... Training loss: 0.0962\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.0965\n",
      "Epoch: 16/20... Training loss: 0.0975\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.0984\n",
      "Epoch: 16/20... Training loss: 0.0945\n",
      "Epoch: 16/20... Training loss: 0.0971\n",
      "Epoch: 16/20... Training loss: 0.0996\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.0955\n",
      "Epoch: 16/20... Training loss: 0.0986\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.0943\n",
      "Epoch: 16/20... Training loss: 0.0976\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.0975\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.0951\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.0946\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.0987\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.0983\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.0971\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.1004\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.0970\n",
      "Epoch: 16/20... Training loss: 0.0966\n",
      "Epoch: 16/20... Training loss: 0.0971\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.0976\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.0963\n",
      "Epoch: 16/20... Training loss: 0.0963\n",
      "Epoch: 16/20... Training loss: 0.0978\n",
      "Epoch: 16/20... Training loss: 0.0972\n",
      "Epoch: 16/20... Training loss: 0.0987\n",
      "Epoch: 16/20... Training loss: 0.0961\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.1009\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 16/20... Training loss: 0.0962\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.0960\n",
      "Epoch: 17/20... Training loss: 0.0980\n",
      "Epoch: 17/20... Training loss: 0.0972\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.0989\n",
      "Epoch: 17/20... Training loss: 0.0970\n",
      "Epoch: 17/20... Training loss: 0.1050\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.0953\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.0963\n",
      "Epoch: 17/20... Training loss: 0.0987\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.0955\n",
      "Epoch: 17/20... Training loss: 0.0935\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.0986\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.0937\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.0953\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.0978\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.0970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.0967\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0980\n",
      "Epoch: 17/20... Training loss: 0.0975\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.0961\n",
      "Epoch: 17/20... Training loss: 0.0949\n",
      "Epoch: 17/20... Training loss: 0.0989\n",
      "Epoch: 17/20... Training loss: 0.0959\n",
      "Epoch: 17/20... Training loss: 0.0964\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.0964\n",
      "Epoch: 17/20... Training loss: 0.0984\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.0984\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.0961\n",
      "Epoch: 17/20... Training loss: 0.0973\n",
      "Epoch: 17/20... Training loss: 0.0959\n",
      "Epoch: 17/20... Training loss: 0.0995\n",
      "Epoch: 17/20... Training loss: 0.0963\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.0967\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.0962\n",
      "Epoch: 17/20... Training loss: 0.0972\n",
      "Epoch: 17/20... Training loss: 0.0952\n",
      "Epoch: 17/20... Training loss: 0.0969\n",
      "Epoch: 17/20... Training loss: 0.0981\n",
      "Epoch: 17/20... Training loss: 0.0966\n",
      "Epoch: 17/20... Training loss: 0.0938\n",
      "Epoch: 17/20... Training loss: 0.0979\n",
      "Epoch: 17/20... Training loss: 0.0995\n",
      "Epoch: 17/20... Training loss: 0.0969\n",
      "Epoch: 17/20... Training loss: 0.0984\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.0938\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.0995\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.0940\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.0968\n",
      "Epoch: 17/20... Training loss: 0.0950\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.0958\n",
      "Epoch: 17/20... Training loss: 0.0981\n",
      "Epoch: 17/20... Training loss: 0.0965\n",
      "Epoch: 17/20... Training loss: 0.0963\n",
      "Epoch: 17/20... Training loss: 0.0947\n",
      "Epoch: 17/20... Training loss: 0.0966\n",
      "Epoch: 17/20... Training loss: 0.0965\n",
      "Epoch: 17/20... Training loss: 0.0953\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0955\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0973\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.0950\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.0984\n",
      "Epoch: 17/20... Training loss: 0.0955\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0968\n",
      "Epoch: 17/20... Training loss: 0.0961\n",
      "Epoch: 17/20... Training loss: 0.0946\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.0952\n",
      "Epoch: 17/20... Training loss: 0.0987\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.0967\n",
      "Epoch: 17/20... Training loss: 0.0968\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.0989\n",
      "Epoch: 17/20... Training loss: 0.0972\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.0971\n",
      "Epoch: 17/20... Training loss: 0.0969\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.0951\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0973\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.0957\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.0979\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.0958\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.0944\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.1023\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.0979\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0970\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.0972\n",
      "Epoch: 17/20... Training loss: 0.0972\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.0987\n",
      "Epoch: 17/20... Training loss: 0.0965\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.0980\n",
      "Epoch: 17/20... Training loss: 0.0936\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0954\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.0954\n",
      "Epoch: 17/20... Training loss: 0.0963\n",
      "Epoch: 17/20... Training loss: 0.0995\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.0945\n",
      "Epoch: 17/20... Training loss: 0.1028\n",
      "Epoch: 17/20... Training loss: 0.0959\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.0964\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0975\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.0971\n",
      "Epoch: 17/20... Training loss: 0.0959\n",
      "Epoch: 17/20... Training loss: 0.0991\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.0980\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.0944\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.0987\n",
      "Epoch: 17/20... Training loss: 0.0987\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.0971\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.0989\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.0964\n",
      "Epoch: 17/20... Training loss: 0.0967\n",
      "Epoch: 17/20... Training loss: 0.0965\n",
      "Epoch: 17/20... Training loss: 0.0956\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.0940\n",
      "Epoch: 17/20... Training loss: 0.0949\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.0970\n",
      "Epoch: 17/20... Training loss: 0.0986\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.0966\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.0936\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.0969\n",
      "Epoch: 17/20... Training loss: 0.0986\n",
      "Epoch: 17/20... Training loss: 0.0984\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.0986\n",
      "Epoch: 17/20... Training loss: 0.0986\n",
      "Epoch: 17/20... Training loss: 0.0968\n",
      "Epoch: 17/20... Training loss: 0.0987\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.0963\n",
      "Epoch: 17/20... Training loss: 0.0960\n",
      "Epoch: 17/20... Training loss: 0.0952\n",
      "Epoch: 17/20... Training loss: 0.0951\n",
      "Epoch: 17/20... Training loss: 0.1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20... Training loss: 0.0940\n",
      "Epoch: 17/20... Training loss: 0.0963\n",
      "Epoch: 17/20... Training loss: 0.0973\n",
      "Epoch: 17/20... Training loss: 0.0960\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.0995\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0949\n",
      "Epoch: 17/20... Training loss: 0.0948\n",
      "Epoch: 17/20... Training loss: 0.0962\n",
      "Epoch: 17/20... Training loss: 0.0965\n",
      "Epoch: 17/20... Training loss: 0.0933\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.0963\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.0969\n",
      "Epoch: 17/20... Training loss: 0.1039\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.0986\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.0962\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.0979\n",
      "Epoch: 17/20... Training loss: 0.0970\n",
      "Epoch: 17/20... Training loss: 0.0969\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.0987\n",
      "Epoch: 17/20... Training loss: 0.0989\n",
      "Epoch: 17/20... Training loss: 0.0991\n",
      "Epoch: 17/20... Training loss: 0.0967\n",
      "Epoch: 17/20... Training loss: 0.0967\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0980\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.0952\n",
      "Epoch: 17/20... Training loss: 0.0978\n",
      "Epoch: 17/20... Training loss: 0.0971\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.0963\n",
      "Epoch: 17/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.0974\n",
      "Epoch: 18/20... Training loss: 0.1007\n",
      "Epoch: 18/20... Training loss: 0.0961\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.0967\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.1000\n",
      "Epoch: 18/20... Training loss: 0.1000\n",
      "Epoch: 18/20... Training loss: 0.0989\n",
      "Epoch: 18/20... Training loss: 0.0967\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.0987\n",
      "Epoch: 18/20... Training loss: 0.0970\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.0965\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.0993\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.0959\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.0976\n",
      "Epoch: 18/20... Training loss: 0.0955\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.0974\n",
      "Epoch: 18/20... Training loss: 0.0975\n",
      "Epoch: 18/20... Training loss: 0.0961\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.0970\n",
      "Epoch: 18/20... Training loss: 0.0979\n",
      "Epoch: 18/20... Training loss: 0.0976\n",
      "Epoch: 18/20... Training loss: 0.0975\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.0962\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.0976\n",
      "Epoch: 18/20... Training loss: 0.0971\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0932\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.1003\n",
      "Epoch: 18/20... Training loss: 0.0953\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0997\n",
      "Epoch: 18/20... Training loss: 0.0961\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0967\n",
      "Epoch: 18/20... Training loss: 0.0986\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.1024\n",
      "Epoch: 18/20... Training loss: 0.0975\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.0968\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0962\n",
      "Epoch: 18/20... Training loss: 0.0956\n",
      "Epoch: 18/20... Training loss: 0.0967\n",
      "Epoch: 18/20... Training loss: 0.0960\n",
      "Epoch: 18/20... Training loss: 0.0968\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0963\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.0962\n",
      "Epoch: 18/20... Training loss: 0.0949\n",
      "Epoch: 18/20... Training loss: 0.1023\n",
      "Epoch: 18/20... Training loss: 0.0990\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.0989\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.0948\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.0976\n",
      "Epoch: 18/20... Training loss: 0.0954\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.0949\n",
      "Epoch: 18/20... Training loss: 0.0946\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.1007\n",
      "Epoch: 18/20... Training loss: 0.0974\n",
      "Epoch: 18/20... Training loss: 0.1016\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.0983\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.0993\n",
      "Epoch: 18/20... Training loss: 0.0956\n",
      "Epoch: 18/20... Training loss: 0.0979\n",
      "Epoch: 18/20... Training loss: 0.0962\n",
      "Epoch: 18/20... Training loss: 0.0963\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0997\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.0965\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.0971\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.0923\n",
      "Epoch: 18/20... Training loss: 0.0974\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.0918\n",
      "Epoch: 18/20... Training loss: 0.0955\n",
      "Epoch: 18/20... Training loss: 0.0981\n",
      "Epoch: 18/20... Training loss: 0.0967\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.0956\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.0960\n",
      "Epoch: 18/20... Training loss: 0.0964\n",
      "Epoch: 18/20... Training loss: 0.0976\n",
      "Epoch: 18/20... Training loss: 0.0962\n",
      "Epoch: 18/20... Training loss: 0.0964\n",
      "Epoch: 18/20... Training loss: 0.0968\n",
      "Epoch: 18/20... Training loss: 0.0946\n",
      "Epoch: 18/20... Training loss: 0.0964\n",
      "Epoch: 18/20... Training loss: 0.0960\n",
      "Epoch: 18/20... Training loss: 0.0953\n",
      "Epoch: 18/20... Training loss: 0.0975\n",
      "Epoch: 18/20... Training loss: 0.0963\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.0968\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.0957\n",
      "Epoch: 18/20... Training loss: 0.0964\n",
      "Epoch: 18/20... Training loss: 0.0965\n",
      "Epoch: 18/20... Training loss: 0.0964\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.0987\n",
      "Epoch: 18/20... Training loss: 0.0953\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0976\n",
      "Epoch: 18/20... Training loss: 0.0968\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0941\n",
      "Epoch: 18/20... Training loss: 0.0949\n",
      "Epoch: 18/20... Training loss: 0.0960\n",
      "Epoch: 18/20... Training loss: 0.0981\n",
      "Epoch: 18/20... Training loss: 0.0967\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.0993\n",
      "Epoch: 18/20... Training loss: 0.0985\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.0975\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.0934\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0987\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.0965\n",
      "Epoch: 18/20... Training loss: 0.0956\n",
      "Epoch: 18/20... Training loss: 0.0953\n",
      "Epoch: 18/20... Training loss: 0.0930\n",
      "Epoch: 18/20... Training loss: 0.0955\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0929\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.0974\n",
      "Epoch: 18/20... Training loss: 0.0957\n",
      "Epoch: 18/20... Training loss: 0.0961\n",
      "Epoch: 18/20... Training loss: 0.0987\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0965\n",
      "Epoch: 18/20... Training loss: 0.0960\n",
      "Epoch: 18/20... Training loss: 0.0982\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0974\n",
      "Epoch: 18/20... Training loss: 0.0983\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0982\n",
      "Epoch: 18/20... Training loss: 0.0970\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0932\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0960\n",
      "Epoch: 18/20... Training loss: 0.0993\n",
      "Epoch: 18/20... Training loss: 0.0954\n",
      "Epoch: 18/20... Training loss: 0.0993\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.0930\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.0957\n",
      "Epoch: 18/20... Training loss: 0.0914\n",
      "Epoch: 18/20... Training loss: 0.0974\n",
      "Epoch: 18/20... Training loss: 0.0993\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0971\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.0985\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.0955\n",
      "Epoch: 18/20... Training loss: 0.0966\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0927\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.0947\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.0979\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.0976\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0959\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0963\n",
      "Epoch: 18/20... Training loss: 0.0970\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.0935\n",
      "Epoch: 18/20... Training loss: 0.0947\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.0982\n",
      "Epoch: 18/20... Training loss: 0.0986\n",
      "Epoch: 18/20... Training loss: 0.0982\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.1007\n",
      "Epoch: 18/20... Training loss: 0.0993\n",
      "Epoch: 18/20... Training loss: 0.0981\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.1027\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.0966\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.0958\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.0959\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.0962\n",
      "Epoch: 18/20... Training loss: 0.0963\n",
      "Epoch: 18/20... Training loss: 0.0981\n",
      "Epoch: 18/20... Training loss: 0.0931\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.0987\n",
      "Epoch: 18/20... Training loss: 0.0965\n",
      "Epoch: 18/20... Training loss: 0.0944\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.0967\n",
      "Epoch: 18/20... Training loss: 0.0963\n",
      "Epoch: 18/20... Training loss: 0.0982\n",
      "Epoch: 18/20... Training loss: 0.0965\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.0952\n",
      "Epoch: 18/20... Training loss: 0.0950\n",
      "Epoch: 18/20... Training loss: 0.0965\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.0976\n",
      "Epoch: 19/20... Training loss: 0.0947\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0994\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.0959\n",
      "Epoch: 19/20... Training loss: 0.0950\n",
      "Epoch: 19/20... Training loss: 0.0954\n",
      "Epoch: 19/20... Training loss: 0.0994\n",
      "Epoch: 19/20... Training loss: 0.1006\n",
      "Epoch: 19/20... Training loss: 0.0952\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.0957\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.0964\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0959\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.0982\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.0964\n",
      "Epoch: 19/20... Training loss: 0.0952\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0957\n",
      "Epoch: 19/20... Training loss: 0.1008\n",
      "Epoch: 19/20... Training loss: 0.0945\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.0967\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.0959\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.0978\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.0982\n",
      "Epoch: 19/20... Training loss: 0.0964\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.1023\n",
      "Epoch: 19/20... Training loss: 0.0949\n",
      "Epoch: 19/20... Training loss: 0.0954\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0951\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0937\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0955\n",
      "Epoch: 19/20... Training loss: 0.1031\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.0941\n",
      "Epoch: 19/20... Training loss: 0.0953\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.0920\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.1016\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0973\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 19/20... Training loss: 0.0961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/20... Training loss: 0.0941\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.0993\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.0954\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0928\n",
      "Epoch: 19/20... Training loss: 0.0961\n",
      "Epoch: 19/20... Training loss: 0.0993\n",
      "Epoch: 19/20... Training loss: 0.0964\n",
      "Epoch: 19/20... Training loss: 0.0957\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.0951\n",
      "Epoch: 19/20... Training loss: 0.0952\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0967\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.0951\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.0967\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0939\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.0984\n",
      "Epoch: 19/20... Training loss: 0.0967\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0943\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.0978\n",
      "Epoch: 19/20... Training loss: 0.0942\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.0949\n",
      "Epoch: 19/20... Training loss: 0.0948\n",
      "Epoch: 19/20... Training loss: 0.0950\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0952\n",
      "Epoch: 19/20... Training loss: 0.0972\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.0957\n",
      "Epoch: 19/20... Training loss: 0.0973\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.0967\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0964\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.0966\n",
      "Epoch: 19/20... Training loss: 0.0950\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0959\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.0964\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.0943\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0963\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0959\n",
      "Epoch: 19/20... Training loss: 0.0943\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.0966\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0948\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.0994\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0957\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.1032\n",
      "Epoch: 19/20... Training loss: 0.0929\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.0938\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0959\n",
      "Epoch: 19/20... Training loss: 0.0961\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.0947\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.0912\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.0951\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.0978\n",
      "Epoch: 19/20... Training loss: 0.0966\n",
      "Epoch: 19/20... Training loss: 0.0955\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0954\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.0992\n",
      "Epoch: 19/20... Training loss: 0.0944\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.0955\n",
      "Epoch: 19/20... Training loss: 0.0951\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0972\n",
      "Epoch: 19/20... Training loss: 0.0984\n",
      "Epoch: 19/20... Training loss: 0.0978\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.0929\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.0938\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.0921\n",
      "Epoch: 19/20... Training loss: 0.0961\n",
      "Epoch: 19/20... Training loss: 0.0952\n",
      "Epoch: 19/20... Training loss: 0.0964\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.0972\n",
      "Epoch: 19/20... Training loss: 0.0948\n",
      "Epoch: 19/20... Training loss: 0.0959\n",
      "Epoch: 19/20... Training loss: 0.0946\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0982\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0957\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0954\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0963\n",
      "Epoch: 19/20... Training loss: 0.0954\n",
      "Epoch: 19/20... Training loss: 0.0982\n",
      "Epoch: 19/20... Training loss: 0.0972\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.1006\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.0944\n",
      "Epoch: 19/20... Training loss: 0.0967\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0951\n",
      "Epoch: 19/20... Training loss: 0.0955\n",
      "Epoch: 19/20... Training loss: 0.0967\n",
      "Epoch: 19/20... Training loss: 0.0948\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0951\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0982\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.0963\n",
      "Epoch: 19/20... Training loss: 0.0952\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.0950\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.0957\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.0972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0935\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0960\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0951\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0991\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0949\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.0952\n",
      "Epoch: 20/20... Training loss: 0.0946\n",
      "Epoch: 20/20... Training loss: 0.0960\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.0953\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.0991\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0934\n",
      "Epoch: 20/20... Training loss: 0.0954\n",
      "Epoch: 20/20... Training loss: 0.0947\n",
      "Epoch: 20/20... Training loss: 0.0949\n",
      "Epoch: 20/20... Training loss: 0.0963\n",
      "Epoch: 20/20... Training loss: 0.0957\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.0963\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.0974\n",
      "Epoch: 20/20... Training loss: 0.0960\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.1000\n",
      "Epoch: 20/20... Training loss: 0.0965\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0969\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.0953\n",
      "Epoch: 20/20... Training loss: 0.0969\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.0955\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.0931\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.0954\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0953\n",
      "Epoch: 20/20... Training loss: 0.0961\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0965\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.0979\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0951\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.0948\n",
      "Epoch: 20/20... Training loss: 0.0950\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.0969\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0910\n",
      "Epoch: 20/20... Training loss: 0.0935\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0944\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0940\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.0936\n",
      "Epoch: 20/20... Training loss: 0.0975\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0950\n",
      "Epoch: 20/20... Training loss: 0.0934\n",
      "Epoch: 20/20... Training loss: 0.1003\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.0948\n",
      "Epoch: 20/20... Training loss: 0.1018\n",
      "Epoch: 20/20... Training loss: 0.0950\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0945\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0991\n",
      "Epoch: 20/20... Training loss: 0.0991\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.0935\n",
      "Epoch: 20/20... Training loss: 0.0943\n",
      "Epoch: 20/20... Training loss: 0.0932\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0980\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0949\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.0975\n",
      "Epoch: 20/20... Training loss: 0.1000\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.0991\n",
      "Epoch: 20/20... Training loss: 0.0925\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0983\n",
      "Epoch: 20/20... Training loss: 0.0946\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.0983\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.0963\n",
      "Epoch: 20/20... Training loss: 0.0948\n",
      "Epoch: 20/20... Training loss: 0.0923\n",
      "Epoch: 20/20... Training loss: 0.0974\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0935\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0966\n",
      "Epoch: 20/20... Training loss: 0.0928\n",
      "Epoch: 20/20... Training loss: 0.0957\n",
      "Epoch: 20/20... Training loss: 0.0942\n",
      "Epoch: 20/20... Training loss: 0.0901\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.0950\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0945\n",
      "Epoch: 20/20... Training loss: 0.0945\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.0961\n",
      "Epoch: 20/20... Training loss: 0.0947\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.0935\n",
      "Epoch: 20/20... Training loss: 0.0947\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0955\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0955\n",
      "Epoch: 20/20... Training loss: 0.0939\n",
      "Epoch: 20/20... Training loss: 0.0983\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1034\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.0960\n",
      "Epoch: 20/20... Training loss: 0.0927\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0952\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0933\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.0974\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.0950\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.0966\n",
      "Epoch: 20/20... Training loss: 0.0957\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0969\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.0953\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0961\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.0953\n",
      "Epoch: 20/20... Training loss: 0.0979\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0960\n",
      "Epoch: 20/20... Training loss: 0.0966\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.0952\n",
      "Epoch: 20/20... Training loss: 0.0970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20... Training loss: 0.0966\n",
      "Epoch: 20/20... Training loss: 0.0942\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0966\n",
      "Epoch: 20/20... Training loss: 0.0974\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.0980\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.0907\n",
      "Epoch: 20/20... Training loss: 0.0991\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.0947\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.0943\n",
      "Epoch: 20/20... Training loss: 0.0950\n",
      "Epoch: 20/20... Training loss: 0.0952\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.0975\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0983\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0955\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.0960\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.0966\n",
      "Epoch: 20/20... Training loss: 0.0954\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.0906\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0965\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0952\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.0942\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.0961\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0974\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0950\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0952\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0931\n",
      "Epoch: 20/20... Training loss: 0.0946\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0960\n",
      "Epoch: 20/20... Training loss: 0.0944\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0990\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 200\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAEsCAYAAAAvofT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBxeByjGgk6x3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24be4226898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: in_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([in_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising 去噪\n",
    "\n",
    "As I've mentioned before, autoencoders like the ones you've built so far aren't too useful in practive. However, they can be used to denoise images quite successfully just by training the network on noisy images. We can create the noisy images ourselves by adding Gaussian noise to the training images, then clipping the values to be between 0 and 1. We'll use noisy images as input and the original, clean images as targets. Here's an example of the noisy images I generated and the denoised images.\n",
    "\n",
    "如前所述，自动编码器如你所建造的那样，在实践中并不太有用。 然而，它们可以用于通过在嘈杂的图像上训练网络来非常成功地去噪图像。 我们可以通过将高斯噪声添加到训练图像中，然后将值剪切在0和1之间来创建嘈杂的图像。我们将使用嘈杂的图像作为输入，将原始的干净图像作为目标。 以下是我生成的嘈杂图像和去噪图像的示例。\n",
    "\n",
    "![Denoising autoencoder](assets/denoising.png)\n",
    "\n",
    "Since this is a harder problem for the network, we'll want to use deeper convolutional layers here, more feature maps. I suggest something like 32-32-16 for the depths of the convolutional layers in the encoder, and the same depths going backward through the decoder. Otherwise the architecture is the same as before.\n",
    "\n",
    "由于这对于网络来说是一个更难的问题，所以我们需要在这里使用更深的卷积层，更多的功能图。 对于编码器中卷积层的深度，我建议像32-32-16这样的深度，并且通过解码器向后的相同深度。 否则，架构与以前相同。\n",
    "\n",
    "> **Exercise:** Build the network for the denoising autoencoder. It's the same as before, but with deeper layers. I suggest 32-32-16 for the depths, but you can play with these numbers, or add more layers.\n",
    "\n",
    "> **练习：**构建去噪自动编码器的网络。 与以前相同，但层次更深。 我建议32-32-16的深度，但你可以玩这些数字，或添加更多的图层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 32, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding=\"same\")\n",
    "# Now 14x14x32\n",
    "conv2 = tf.layers.conv2d(maxpool1, 32, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now conv2\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding=\"same\")\n",
    "# Now 7x7x32\n",
    "conv3 = tf.layers.conv2d(maxpool2, 16, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding=\"same\")\n",
    "# Now 4x4x16\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "# Now 7x7x16\n",
    "conv4 = tf.layers.conv2d(upsample1, 16, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "# Now 14x14x16\n",
    "conv5 = tf.layers.conv2d(upsample2, 32, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "# Now 28x28x32\n",
    "conv6 = tf.layers.conv2d(upsample3, 32, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "\n",
    "logits =  tf.layers.conv2d(conv6, 1, (3,3), padding=\"same\", activation=tf.nn.relu)\n",
    "#Now 28x28x1\n",
    "\n",
    "# Pass logits through sigmoid to get reconstructed image\n",
    "decoded =  tf.nn.sigmoid(logits, name='output')\n",
    "\n",
    "# Pass logits through sigmoid and calculate the cross-entropy loss\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "\n",
    "# Get cost and define the optimizer\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.6948\n",
      "Epoch: 1/20... Training loss: 0.6932\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 1/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 2/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 3/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 4/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 5/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 6/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 7/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 8/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 9/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 10/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 11/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 12/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 13/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n",
      "Epoch: 14/20... Training loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20... Training loss: 0.6931\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a5efd8534365>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Noisy images as inputs, original images as targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: noisy_imgs,\n\u001b[1;32m---> 19\u001b[1;33m                                                          targets_: imgs})\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "\u001b[1;32mC:\\Users\\elnin\\Anaconda2\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\elnin\\Anaconda2\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\elnin\\Anaconda2\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\elnin\\Anaconda2\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\elnin\\Anaconda2\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 200\n",
    "# Set's how much noise we're adding to the MNIST images\n",
    "noise_factor = 0.5\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        # Get images from the batch\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        \n",
    "        # Add random noise to the input images\n",
    "        noisy_imgs = imgs + noise_factor * np.random.randn(*imgs.shape)\n",
    "        # Clip the images to be between 0 and 1\n",
    "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "        \n",
    "        # Noisy images as inputs, original images as targets\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: noisy_imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out the performance 检查性能\n",
    "\n",
    "Here I'm adding noise to the test images and passing them through the autoencoder. It does a suprisingly great job of removing the noise, even though it's sometimes difficult to tell what the original number is.\n",
    "\n",
    "在这里，我添加了噪音到测试图像并传递他们通过自动编码器。 尽管有时难以判断原始号码是什么，但它除了噪音外，还是一个非常好的工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "noisy_imgs = in_imgs + noise_factor * np.random.randn(*in_imgs.shape)\n",
    "noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: noisy_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([noisy_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
